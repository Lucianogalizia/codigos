{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cdb2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUPYTER HARNESS — Planificador no interactivo\n",
    "# ------------------------------------------------\n",
    "# - Sin inputs ni questionary.\n",
    "# - Parámetros por function-call.\n",
    "# - Devuelve DataFrames: plan, freq; (opcional) escribe Excel.\n",
    "# ------------------------------------------------\n",
    "\n",
    "import os, re, unicodedata, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "# ==========================\n",
    "# CONFIG / CONSTANTES\n",
    "# ==========================\n",
    "RM3D_MIN_DEFAULT = 0.1\n",
    "\n",
    "# ==========================\n",
    "# Utils (copiados de tu script, con mínimos cambios)\n",
    "# ==========================\n",
    "def _norm(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and isinstance(s, (int,float)) and np.isnan(s)) else str(s)\n",
    "    s = s.replace(\"³\", \"3\")\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip().replace(\"\\xa0\",\" \")\n",
    "    s = s.replace(\"_\",\" \").replace(\"-\",\" \").replace(\".\",\" \").replace(\"\\n\",\" \")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _pozo_key(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return \"\".join(ch for ch in s if ch.isalnum()).upper()\n",
    "\n",
    "def _canonical_digits(d: str) -> str:\n",
    "    d = (d or \"\").lstrip(\"0\")\n",
    "    return d if d != \"\" else \"0\"\n",
    "\n",
    "def _letters_digits_from_key_both(k: str):\n",
    "    raw_digits = \"\".join(re.findall(r\"\\d+\", k))\n",
    "    digits_canon = _canonical_digits(raw_digits)\n",
    "    letters = re.sub(r\"\\d+\", \"\", k)\n",
    "    return letters, digits_canon, len(raw_digits)\n",
    "\n",
    "def _ratio_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _fuzzy_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.partial_ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _canon_prefix_pozo(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return s\n",
    "    raw = str(s).strip()\n",
    "    raw_up = raw.upper()\n",
    "    if raw_up.startswith(\"CÑE\"):\n",
    "        return \"CNE\" + raw_up[3:]\n",
    "    raw_ascii = unicodedata.normalize(\"NFKD\", raw_up).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    if raw_ascii.startswith(\"CNE\"):\n",
    "        return raw_ascii\n",
    "    if raw_ascii.startswith(\"CN\"):\n",
    "        return \"CNE\" + raw_ascii[2:]\n",
    "    m = re.match(r\"^CE(\\d+)$\", raw_ascii)\n",
    "    if m:\n",
    "        return \"CNE\" + m.group(1)\n",
    "    return raw_ascii\n",
    "\n",
    "def next_monday(d=None):\n",
    "    d = d or date.today()\n",
    "    return d + timedelta(days=(7 - d.weekday()) % 7)  # 0=Lunes\n",
    "\n",
    "def unique_output_path(base_input_path: str) -> str:\n",
    "    folder = os.path.dirname(os.path.abspath(base_input_path))\n",
    "    stem   = os.path.splitext(os.path.basename(base_input_path))[0]\n",
    "    today  = datetime.now().strftime(\"%Y%m%d\")\n",
    "    base   = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}.xlsx\")\n",
    "    if not os.path.exists(base): return base\n",
    "    i = 2\n",
    "    while True:\n",
    "        cand = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}_({i}).xlsx\")\n",
    "        if not os.path.exists(cand): return cand\n",
    "        i += 1\n",
    "\n",
    "EXPECTED_KEYS = {\n",
    "    \"fecha\":       [\"fecha\"],\n",
    "    \"pozo\":        [\"pozo\"],\n",
    "    \"zona\":        [\"zona\"],\n",
    "    \"bateria\":     [\"bateria\", \"batería\"],\n",
    "    \"m3\":          [\"m3 bruta\",\"m3\",\"m3_bruta\",\"m3bruta\",\"m 3 bruta\",\"m 3\",\"m3 bruto\",\"m3 recuperado\",\"m3 recupero\"],\n",
    "    \"carreras\":    [\"n de carreras\",\"n° de carreras\",\"nº de carreras\",\"no de carreras\",\"nro de carreras\",\"numero de carreras\",\"n° carreras\",\"n de carrera\",\"n carreras\"],\n",
    "    \"nivel_final\": [\"nivel final pozo\",\"nivel final\",\"nivel final del pozo\"],\n",
    "    \"obs_pozo\":    [\"observaciones del pozo\",\"observaciones\",\"comentarios\",\"comentario\"]\n",
    "}\n",
    "\n",
    "def _find_header_row(df_raw):\n",
    "    for i in range(min(200, len(df_raw))):\n",
    "        row_norm = [_norm(x) for x in df_raw.iloc[i,:].tolist()]\n",
    "        if not row_norm:\n",
    "            continue\n",
    "        colmap = {v:j for v,j in zip(row_norm, range(len(row_norm)))}\n",
    "        def has_any(keys): return any(k in colmap for k in keys)\n",
    "        if has_any(EXPECTED_KEYS[\"fecha\"]) and has_any(EXPECTED_KEYS[\"pozo\"]) and has_any(EXPECTED_KEYS[\"zona\"]) and has_any(EXPECTED_KEYS[\"bateria\"]):\n",
    "            return i, row_norm\n",
    "    return None, None\n",
    "\n",
    "# ---------- Lecturas ----------\n",
    "def read_historial(xlsx_path, sheet_hist=None):\n",
    "    xl = pd.ExcelFile(xlsx_path)\n",
    "    sheets = [sheet_hist] if (sheet_hist and sheet_hist in xl.sheet_names) else xl.sheet_names\n",
    "    for sh in sheets:\n",
    "        raw = xl.parse(sh, header=None)\n",
    "        idx, header_norm = _find_header_row(raw)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        data = raw.iloc[idx:, :].copy()\n",
    "        true_headers = data.iloc[0,:].astype(str).tolist()\n",
    "        data = data.iloc[1:,:]\n",
    "        data.columns = true_headers\n",
    "\n",
    "        name_map = {c: _norm(c) for c in data.columns}\n",
    "        def find_col(candidates):\n",
    "            for c, n in name_map.items():\n",
    "                if n in candidates:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        c_fecha       = find_col(set(EXPECTED_KEYS[\"fecha\"]))\n",
    "        c_pozo        = find_col(set(EXPECTED_KEYS[\"pozo\"]))\n",
    "        c_zona        = find_col(set(EXPECTED_KEYS[\"zona\"]))\n",
    "        c_bateria     = find_col(set(EXPECTED_KEYS[\"bateria\"]))\n",
    "        c_m3          = find_col(set(EXPECTED_KEYS[\"m3\"]))\n",
    "        c_carr        = find_col(set(EXPECTED_KEYS[\"carreras\"]))\n",
    "        c_nivel_final = find_col(set(EXPECTED_KEYS[\"nivel_final\"]))\n",
    "        c_obs         = find_col(set(EXPECTED_KEYS[\"obs_pozo\"]))  # NUEVO\n",
    "\n",
    "        if not (c_fecha and c_pozo and c_zona and c_bateria):\n",
    "            continue\n",
    "\n",
    "        use_cols = [c_fecha, c_pozo, c_zona, c_bateria]\n",
    "        headers  = [\"FECHA\",\"POZO\",\"ZONA\",\"BATERIA\"]\n",
    "        if c_m3:            use_cols.append(c_m3);            headers.append(\"M3\")\n",
    "        if c_carr:          use_cols.append(c_carr);          headers.append(\"CARRERAS\")\n",
    "        if c_nivel_final:   use_cols.append(c_nivel_final);   headers.append(\"NIVEL_FINAL\")\n",
    "        if c_obs:           use_cols.append(c_obs);           headers.append(\"OBS_POZO\")  # NUEVO\n",
    "\n",
    "        df = data[use_cols].copy()\n",
    "        df.columns = headers\n",
    "\n",
    "        df[\"FECHA\"] = pd.to_datetime(df[\"FECHA\"], errors=\"coerce\")\n",
    "        if \"M3\" not in df.columns: df[\"M3\"] = np.nan\n",
    "        else: df[\"M3\"] = pd.to_numeric(df[\"M3\"], errors=\"coerce\")\n",
    "\n",
    "        if \"CARRERAS\" not in df.columns: df[\"CARRERAS\"] = np.nan\n",
    "        else: df[\"CARRERAS\"] = pd.to_numeric(df[\"CARRERAS\"], errors=\"coerce\")\n",
    "\n",
    "        if \"NIVEL_FINAL\" not in df.columns:\n",
    "            df[\"NIVEL_FINAL\"] = None\n",
    "        if \"OBS_POZO\" not in df.columns:\n",
    "            df[\"OBS_POZO\"] = None\n",
    "\n",
    "        for col in [\"POZO\",\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\",\"OBS_POZO\"]:\n",
    "            df[col] = df[col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "        df = df.dropna(subset=[\"FECHA\",\"POZO\"]).sort_values([\"POZO\",\"FECHA\"])\n",
    "        return df\n",
    "\n",
    "    raise ValueError(\"No pude detectar FECHA/POZO/ZONA/BATERÍA en ninguna hoja del Excel.\")\n",
    "\n",
    "def load_pozo_dictionary(xlsx_path: str):\n",
    "    try:\n",
    "        ref = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer diccionario de pozos: {xlsx_path}\\n{e}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    cols = {c.lower().strip(): c for c in ref.columns}\n",
    "    if \"nombre_corto_pozo\" not in cols:\n",
    "        print(f\"\\n[AVISO] El diccionario no tiene la columna 'nombre_corto_pozo'. Columnas: {list(ref.columns)}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    c_pozo = cols[\"nombre_corto_pozo\"]\n",
    "    c_met  = cols.get(\"met_prod\")\n",
    "    c_n3   = cols.get(\"nivel_3\")\n",
    "    c_n5   = cols.get(\"nivel_5\")\n",
    "    c_est  = cols.get(\"estado\")\n",
    "\n",
    "    refv = ref.loc[ref[c_pozo].notna()].copy()\n",
    "    refv[c_pozo] = refv[c_pozo].astype(str).str.strip()\n",
    "\n",
    "    of_list  = refv[c_pozo].tolist()\n",
    "    met_vals = refv[c_met].astype(str).str.strip() if c_met else np.nan\n",
    "    n3_vals  = refv[c_n3].astype(str).str.strip()  if c_n3 else np.nan\n",
    "    n5_vals  = refv[c_n5].astype(str).str.strip()  if c_n5 else np.nan\n",
    "    est_vals = refv[c_est].astype(str).str.strip() if c_est else np.nan\n",
    "\n",
    "    keys, letters_, digits_canon_, digits_len_ = [], [], [], []\n",
    "    for val in of_list:\n",
    "        k = _pozo_key(val)\n",
    "        L, Dcanon, Dlen = _letters_digits_from_key_both(k)\n",
    "        keys.append(k); letters_.append(L); digits_canon_.append(Dcanon); digits_len_.append(Dlen)\n",
    "\n",
    "    dict_df = pd.DataFrame({\n",
    "        \"oficial\": of_list,\n",
    "        \"key\": keys,\n",
    "        \"letters\": letters_,\n",
    "        \"digits_canon\": digits_canon_,\n",
    "        \"digits_len\": digits_len_,\n",
    "        \"met_prod\": list(met_vals) if isinstance(met_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_3\":  list(n3_vals)  if isinstance(n3_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_5\":  list(n5_vals)  if isinstance(n5_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"estado\":   list(est_vals) if isinstance(est_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "    })\n",
    "\n",
    "    key2off = {}\n",
    "    for k, off in zip(dict_df[\"key\"], dict_df[\"oficial\"]):\n",
    "        if k and k not in key2off:\n",
    "            key2off[k] = off\n",
    "    return key2off, dict_df\n",
    "\n",
    "def apply_pozo_normalization(df: pd.DataFrame, key2off: dict, dict_df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"POZO_ORIG\"] = df[\"POZO\"].astype(str).str.strip()\n",
    "    df[\"POZO_PreCanon\"] = df[\"POZO_ORIG\"].apply(_canon_prefix_pozo)\n",
    "    df[\"__POZO_KEY\"] = df[\"POZO_PreCanon\"].apply(_pozo_key)\n",
    "\n",
    "    parts = df[\"__POZO_KEY\"].apply(_letters_digits_from_key_both)\n",
    "    df[\"__KEY_LET\"], df[\"__KEY_DIG_CANON\"], df[\"__KEY_DIG_LEN\"] = zip(*parts)\n",
    "\n",
    "    df[\"POZO_MATCH\"]   = None\n",
    "    df[\"MATCH_TIPO\"]   = \"NO\"\n",
    "    df[\"MATCH_SCORE\"]  = np.nan\n",
    "    df[\"LETTER_SCORE\"] = np.nan\n",
    "    df[\"APLICADO\"]     = \"NO\"\n",
    "    df[\"ALERTA_NORM\"]  = \"\"\n",
    "    df[\"VALIDO_POZO\"]  = True\n",
    "\n",
    "    invalid_mask = (df[\"__KEY_LET\"].str.len()==0) | (df[\"__KEY_DIG_LEN\"]==0)\n",
    "    if invalid_mask.any():\n",
    "        df.loc[invalid_mask, \"ALERTA_NORM\"] = \"SIN_LETRAS_O_DIGITOS\"\n",
    "        df.loc[invalid_mask, \"VALIDO_POZO\"] = False\n",
    "\n",
    "    valid_mask = ~invalid_mask\n",
    "    exact_mask = valid_mask & df[\"__POZO_KEY\"].isin(key2off.keys())\n",
    "    df.loc[exact_mask, \"POZO_MATCH\"]   = df.loc[exact_mask, \"__POZO_KEY\"].map(key2off)\n",
    "    df.loc[exact_mask, \"MATCH_TIPO\"]   = \"EXACTO\"\n",
    "    df.loc[exact_mask, \"MATCH_SCORE\"]  = 100\n",
    "    df.loc[exact_mask, \"LETTER_SCORE\"] = 100\n",
    "    df.loc[exact_mask, \"APLICADO\"]     = \"SI\"\n",
    "\n",
    "    pending = df[valid_mask & (~exact_mask)].index.tolist()\n",
    "    if pending and not dict_df.empty:\n",
    "        dict_by_spec = {}\n",
    "        for spec, sub in dict_df.groupby([\"digits_canon\",\"digits_len\"]):\n",
    "            dict_by_spec[spec] = sub\n",
    "\n",
    "        for idx in pending:\n",
    "            key_u   = df.at[idx, \"__POZO_KEY\"]\n",
    "            let_u   = df.at[idx, \"__KEY_LET\"]\n",
    "            digc_u  = df.at[idx, \"__KEY_DIG_CANON\"]\n",
    "            digl_u  = int(df.at[idx, \"__KEY_DIG_LEN\"])\n",
    "\n",
    "            cand_df = dict_by_spec.get((digc_u, digl_u), pd.DataFrame())\n",
    "            best_off, best_score, best_lscore = None, -1, -1\n",
    "\n",
    "            if cand_df is not None and not cand_df.empty:\n",
    "                for row in cand_df.itertuples():\n",
    "                    kk = row.key\n",
    "                    ll = row.letters\n",
    "                    sc_key = _fuzzy_score(key_u, kk)\n",
    "                    sc_let = _ratio_score(let_u, ll)\n",
    "                    if sc_let < 80:\n",
    "                        continue\n",
    "                    if sc_key > best_score or (sc_key == best_score and sc_let > best_lscore):\n",
    "                        best_score = sc_key\n",
    "                        best_lscore = sc_let\n",
    "                        best_off   = row.oficial\n",
    "\n",
    "            if best_off is not None:\n",
    "                df.at[idx, \"POZO_MATCH\"]   = best_off\n",
    "                df.at[idx, \"MATCH_TIPO\"]   = \"SUGERIDO\"\n",
    "                df.at[idx, \"MATCH_SCORE\"]  = int(best_score)\n",
    "                df.at[idx, \"LETTER_SCORE\"] = int(best_lscore)\n",
    "            else:\n",
    "                df.at[idx, \"ALERTA_NORM\"] = \"SIN MATCH EN DICCIONARIO\"\n",
    "\n",
    "    # Reemplazos\n",
    "    df[\"POZO\"] = df[\"POZO_MATCH\"].where(df[\"POZO_MATCH\"].notna(), df[\"POZO\"])\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    df = df.merge(meta_first, how=\"left\", left_on=\"POZO\", right_index=True)\n",
    "\n",
    "    if \"nivel_3\" in df.columns:\n",
    "        df.loc[df[\"POZO_MATCH\"].isna(), \"nivel_3\"] = \"\"\n",
    "        df[\"ZONA\"] = np.where(df[\"POZO_MATCH\"].notna(), df[\"nivel_3\"].fillna(\"\"), \"\")\n",
    "\n",
    "    if \"nivel_5\" in df.columns:\n",
    "        df[\"BATERIA\"] = np.where(\n",
    "            df[\"nivel_5\"].notna() & (df[\"nivel_5\"].astype(str).str.strip()!=\"\"),\n",
    "            df[\"nivel_5\"], df[\"BATERIA\"]\n",
    "        )\n",
    "\n",
    "    df[\"__ZONA_NORM\"]    = df[\"ZONA\"].apply(_norm)\n",
    "    df[\"__BATERIA_NORM\"] = df[\"BATERIA\"].apply(_norm)\n",
    "\n",
    "    norm_table = (df[[\"POZO_ORIG\",\"POZO_PreCanon\",\"__POZO_KEY\",\n",
    "                      \"__KEY_LET\",\"__KEY_DIG_CANON\",\"__KEY_DIG_LEN\",\n",
    "                      \"POZO_MATCH\",\"MATCH_TIPO\",\"MATCH_SCORE\",\"LETTER_SCORE\",\n",
    "                      \"APLICADO\",\"ALERTA_NORM\",\"VALIDO_POZO\",\n",
    "                      \"met_prod\",\"nivel_3\",\"nivel_5\"]]\n",
    "                  .drop_duplicates())\n",
    "\n",
    "    alert_table = norm_table[(norm_table[\"VALIDO_POZO\"]==False) | (norm_table[\"APLICADO\"]==\"NO\") | (norm_table[\"MATCH_TIPO\"]==\"NO\")].copy()\n",
    "\n",
    "    return df, alert_table, norm_table\n",
    "\n",
    "def _to_float_maybe_comma(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if s == \"\": return np.nan\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def read_coords(xlsx_path):\n",
    "    try:\n",
    "        cdf = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer coordenadas: {xlsx_path}\\n{e}\\n\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    cols_map = {c.lower().strip(): c for c in cdf.columns}\n",
    "    c_pozo = cols_map.get(\"pozo\")\n",
    "    for k in [\"geo_latitude\",\"latitude\",\"lat\"]:\n",
    "        if k in cols_map:\n",
    "            c_lat = cols_map[k]; break\n",
    "    else:\n",
    "        c_lat = None\n",
    "    for k in [\"geo_longitude\",\"longitude\",\"lon\",\"long\"]:\n",
    "        if k in cols_map:\n",
    "            c_lon = cols_map[k]; break\n",
    "    else:\n",
    "        c_lon = None\n",
    "\n",
    "    if not (c_pozo and c_lat and c_lon):\n",
    "        print(f\"[AVISO] Coordenadas: columnas esperadas 'POZO','GEO_LATITUDE','GEO_LONGITUDE'. Columnas encontradas: {list(cdf.columns)}\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "\n",
    "    out = cdf[[c_pozo, c_lat, c_lon]].copy()\n",
    "    out.columns = [\"POZO\",\"LAT\",\"LON\"]\n",
    "    out[\"POZO\"] = out[\"POZO\"].astype(str).str.strip()\n",
    "    out[\"LAT\"] = out[\"LAT\"].apply(_to_float_maybe_comma)\n",
    "    out[\"LON\"] = out[\"LON\"].apply(_to_float_maybe_comma)\n",
    "    out = out.dropna(subset=[\"POZO\"])\n",
    "    out = out.drop_duplicates(subset=[\"POZO\"], keep=\"last\")\n",
    "    return out\n",
    "\n",
    "# ==========================\n",
    "# Frecuencias / r_m3_d\n",
    "# ==========================\n",
    "def _count_trailing_zeros_with_carr(g):\n",
    "    cnt = 0\n",
    "    for _, row in g.sort_values(\"FECHA\").iloc[::-1].iterrows():\n",
    "        m3 = row.get(\"M3\", np.nan)\n",
    "        car = row.get(\"CARRERAS\", np.nan)\n",
    "        if pd.notna(m3) and float(m3) == 0.0 and pd.notna(car) and float(car) > 0:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    return cnt\n",
    "\n",
    "def compute_frecuencias(df, params):\n",
    "    v_target = params[\"m3_por_visita_objetivo\"]\n",
    "    min_d    = params[\"min_dias_freq\"]\n",
    "    max_d    = params[\"max_dias_freq\"]\n",
    "    k        = int(params[\"k_visitas\"])\n",
    "    one_days = int(params.get(\"dias_asumidos_una_visita\", 7))\n",
    "    freq_cero_ultimo = int(params.get(\"freq_dias_ultimo_cero_valido\", 30))\n",
    "\n",
    "    out = []\n",
    "    for pozo, g0 in df.groupby(\"POZO\", sort=False):\n",
    "        g = g0.sort_values(\"FECHA\").copy()\n",
    "\n",
    "        for col in [\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\"]:\n",
    "            if col in g.columns:\n",
    "                g[col] = g[col].replace({None: np.nan})\n",
    "                g[col] = g[col].ffill().bfill()\n",
    "\n",
    "        g[\"__ZONA_NORM\"]    = g[\"ZONA\"].apply(_norm)\n",
    "        g[\"__BATERIA_NORM\"] = g[\"BATERIA\"].apply(_norm)\n",
    "        g[\"__nf_norm\"]      = g[\"NIVEL_FINAL\"].apply(_norm) if \"NIVEL_FINAL\" in g.columns else \"\"\n",
    "\n",
    "        med_validas_all = g[g[\"M3\"].notna()].copy()\n",
    "\n",
    "        m3_eq0 = g[\"M3\"].fillna(0) == 0\n",
    "        carr   = g.get(\"CARRERAS\", pd.Series(index=g.index, dtype=float)).fillna(np.nan)\n",
    "        zero_cond_a = m3_eq0 & (carr.fillna(0) >= 1)\n",
    "        zero_cond_b = m3_eq0 & ((carr.isna()) | (carr.fillna(0) == 0)) & (g[\"__nf_norm\"] == \"surge\")\n",
    "        cond_cero_valido = zero_cond_a | zero_cond_b\n",
    "\n",
    "        validas_rate = g[(g[\"M3\"] > 0) | cond_cero_valido].copy()\n",
    "        zeros_tail = _count_trailing_zeros_with_carr(g)\n",
    "\n",
    "        ultima_med = med_validas_all[\"FECHA\"].max() if not med_validas_all.empty else pd.NaT\n",
    "        ultima_exi = g.loc[g[\"M3\"]>0, \"FECHA\"].max() if \"M3\" in g.columns and not g[g[\"M3\"]>0].empty else pd.NaT\n",
    "\n",
    "        last_zero_valido = False\n",
    "        if not med_validas_all.empty:\n",
    "            idx_last = med_validas_all[\"FECHA\"].idxmax()\n",
    "            m3_last  = g.at[idx_last, \"M3\"]\n",
    "            if pd.notna(m3_last) and float(m3_last) == 0.0:\n",
    "                try:\n",
    "                    last_zero_valido = bool(cond_cero_valido.loc[idx_last])\n",
    "                except Exception:\n",
    "                    last_zero_valido = False\n",
    "\n",
    "        alerta = \"\"\n",
    "        if last_zero_valido:\n",
    "            alerta = f\"ULTIMA_M3_0_VALIDO -> FREQ {freq_cero_ultimo}D\"\n",
    "        elif pd.notna(ultima_med):\n",
    "            if zeros_tail > 0:\n",
    "                alerta = f\"ALERTA: {zeros_tail} cero(s) consecutivo(s) con Carreras>0\"\n",
    "\n",
    "        # r_m3_d\n",
    "        r = np.nan\n",
    "        if not validas_rate.empty:\n",
    "            v = validas_rate.copy()\n",
    "            v[\"delta_d\"] = v[\"FECHA\"].diff().dt.days\n",
    "            v.loc[v[\"delta_d\"] <= 0, \"delta_d\"] = np.nan\n",
    "            v[\"rate\"] = v[\"M3\"].fillna(0) / v[\"delta_d\"]\n",
    "            rates = v[\"rate\"].dropna()\n",
    "            if len(rates) >= 1:\n",
    "                r = rates.tail(min(k, len(rates))).mean()\n",
    "            else:\n",
    "                row = v.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "        else:\n",
    "            if len(med_validas_all) == 1:\n",
    "                row = med_validas_all.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "\n",
    "        # FRECUENCIA\n",
    "        if last_zero_valido:\n",
    "            delta = int(freq_cero_ultimo)\n",
    "        else:\n",
    "            if pd.isna(r):      delta = 7\n",
    "            elif r <= 0:        delta = max_d\n",
    "            else:\n",
    "                delta = max(min_d, min(max_d, float(v_target)/float(r)))\n",
    "                delta = int(7 * round(delta / 7.0))\n",
    "                if delta < 7:\n",
    "                    delta = 7\n",
    "\n",
    "        prox = (ultima_med + pd.Timedelta(days=int(delta))) if pd.notna(ultima_med) else pd.Timestamp(next_monday())\n",
    "\n",
    "        out.append({\n",
    "            \"POZO\": pozo,\n",
    "            \"ZONA\": g[\"ZONA\"].iloc[-1],\n",
    "            \"BATERIA\": g[\"BATERIA\"].iloc[-1],\n",
    "            \"ZONA_NORM\": g[\"__ZONA_NORM\"].iloc[-1],\n",
    "            \"BATERIA_NORM\": g[\"__BATERIA_NORM\"].iloc[-1],\n",
    "            \"r_m3_d\": r,\n",
    "            \"ultima_medicion\": ultima_med,\n",
    "            \"ultima_exitosa\": ultima_exi,\n",
    "            \"delta_star_dias\": int(delta),\n",
    "            \"proxima_visita_base\": prox,\n",
    "            \"ceros_consec\": zeros_tail,\n",
    "            \"alerta\": alerta\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# ==========================\n",
    "# Geodesia\n",
    "# ==========================\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "            return np.nan\n",
    "        R = 6371.0088\n",
    "        p1 = math.radians(float(lat1)); p2 = math.radians(float(lat2))\n",
    "        dphi = math.radians(float(lat2) - float(lat1))\n",
    "        dlmb = math.radians(float(lon2) - float(lon1))\n",
    "        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "        return 2*R*math.asin(math.sqrt(a))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ==========================\n",
    "# Candidatos\n",
    "# ==========================\n",
    "def build_candidates_with_coords(freq, week_start, week_end, excl_pozos,\n",
    "                                 zonas_norm_incluidas, coords_df,\n",
    "                                 allowed_bats_by_zone_norm=None,\n",
    "                                 next_due_map=None,\n",
    "                                 rm3d_min=RM3D_MIN_DEFAULT):\n",
    "    F = freq.copy()\n",
    "    F[\"due_date\"] = F[\"proxima_visita_base\"]\n",
    "    if next_due_map:\n",
    "        F[\"due_date\"] = F[\"POZO\"].map(next_due_map).fillna(F[\"due_date\"])\n",
    "\n",
    "    F[\"overdue_d\"] = (pd.Timestamp(week_start) - pd.to_datetime(F[\"due_date\"])).dt.days\n",
    "    F[\"is_overdue\"] = F[\"overdue_d\"] > 0\n",
    "\n",
    "    F[\"__v\"] = F[\"r_m3_d\"].astype(float)\n",
    "\n",
    "    if \"ZONA_NORM\" in F.columns and zonas_norm_incluidas:\n",
    "        F = F[F[\"ZONA_NORM\"].isin(zonas_norm_incluidas)].copy()\n",
    "\n",
    "    if allowed_bats_by_zone_norm:\n",
    "        mask = pd.Series(True, index=F.index)\n",
    "        for zn in zonas_norm_incluidas:\n",
    "            bats = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats is not None:\n",
    "                mask &= ~ (F[\"ZONA_NORM\"] == zn) | (F[\"BATERIA_NORM\"].isin(bats))\n",
    "        F = F[mask].copy()\n",
    "\n",
    "    if excl_pozos:\n",
    "        F = F[~F[\"POZO\"].isin(excl_pozos)].copy()\n",
    "\n",
    "    F = F[F[\"r_m3_d\"].fillna(0) > rm3d_min].copy()\n",
    "    F = F[F[\"BATERIA\"].notna() & (F[\"BATERIA\"].astype(str).str.strip() != \"\")].copy()\n",
    "\n",
    "    if \"comentario\" in F.columns:\n",
    "        F[\"__comentario_txt\"] = F[\"comentario\"].astype(str).fillna(\"\").str.strip()\n",
    "        F = F[F[\"__comentario_txt\"] == \"\"].copy()\n",
    "        F.drop(columns=[\"__comentario_txt\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    coords_df = coords_df if coords_df is not None else pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    F = F.merge(coords_df, how=\"left\", on=\"POZO\")\n",
    "    F[\"has_coords\"] = F[\"LAT\"].notna() & F[\"LON\"].notna()\n",
    "\n",
    "    F = F.sort_values(by=[\"is_overdue\",\"__v\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    return F\n",
    "\n",
    "def _v_est_for_day(row, day_date):\n",
    "    r = row.get(\"r_m3_d\", np.nan)\n",
    "    u = row.get(\"ultima_medicion\", pd.NaT)\n",
    "    if pd.isna(u) or pd.isna(r) or r <= 0:\n",
    "        return 0.0\n",
    "    dd = max(0, (pd.Timestamp(day_date) - pd.Timestamp(u)).days)\n",
    "    return max(0.0, float(r) * float(dd))\n",
    "\n",
    "# ==========================\n",
    "# Lógica de asignación (round-robin con clúster seed-based original)\n",
    "# ==========================\n",
    "def _bb_filter(df, lat0, lon0, rad_km):\n",
    "    if pd.isna(lat0) or pd.isna(lon0) or df.empty:\n",
    "        return df.iloc[0:0]\n",
    "    dlat = rad_km / 110.574\n",
    "    dlon = rad_km / (111.320 * max(0.1, math.cos(math.radians(float(lat0)))))\n",
    "    return df[(df[\"LAT\"].between(lat0 - dlat, lat0 + dlat)) &\n",
    "              (df[\"LON\"].between(lon0 - dlon, lon0 + dlon))].copy()\n",
    "\n",
    "def _fill_day_star_clusters(day_date, avail_df, cap_per_day, radius_km, used_set,\n",
    "                            cluster_cap, params=None,\n",
    "                            clusters_max=None, backfill_nearest=True, umbral_km_backfill=5.0):\n",
    "    # (idéntica a tu versión actual; abreviada aquí por espacio)\n",
    "    # Para pruebas rápidas en Jupyter, mantenemos la misma mecánica seed-based.\n",
    "    assigned = []\n",
    "    remaining_cap = int(cap_per_day)\n",
    "    cluster_cap   = max(1, int(cluster_cap))\n",
    "    TOP_N = 30 if params is None else int(params.get(\"top_semillas_eval\", 30))\n",
    "\n",
    "    if params is not None and params.get(\"umbral_km_backfill\") is not None:\n",
    "        umbral_km_backfill = float(params.get(\"umbral_km_backfill\"))\n",
    "\n",
    "    has_xy = avail_df[\"has_coords\"].fillna(False)\n",
    "    pool = pd.concat([\n",
    "        avail_df.loc[has_xy].sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]),\n",
    "        avail_df.loc[~has_xy].sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]),\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    c_lat_acc, c_lon_acc, n_acc = (np.nan, np.nan, 0)\n",
    "\n",
    "    def _build_cluster_from_seed(seed_row, pool_df, cap_left):\n",
    "        seed_lat = seed_row.get(\"LAT\", np.nan)\n",
    "        seed_lon = seed_row.get(\"LON\", np.nan)\n",
    "        rows_cluster = [seed_row]\n",
    "\n",
    "        if pd.notna(seed_lat) and pd.notna(seed_lon):\n",
    "            neigh = _bb_filter(pool_df, seed_lat, seed_lon, radius_km)\n",
    "            if not neigh.empty:\n",
    "                neigh = neigh.copy()\n",
    "                neigh[\"__dist_seed\"] = neigh.apply(\n",
    "                    lambda r: haversine_km(seed_lat, seed_lon, r[\"LAT\"], r[\"LON\"]), axis=1\n",
    "                )\n",
    "                neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "                neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "                max_neighbors_by_cluster = max(0, cluster_cap - 1)\n",
    "                max_neighbors_by_day     = max(0, cap_left - 1)\n",
    "                take_n = min(max_neighbors_by_cluster, max_neighbors_by_day)\n",
    "                if take_n > 0 and not neigh.empty:\n",
    "                    rows_cluster.extend([nr for _, nr in neigh.head(take_n).iterrows()])\n",
    "\n",
    "        coords_cluster = [(r.get(\"LAT\", np.nan), r.get(\"LON\", np.nan))\n",
    "                          for r in rows_cluster\n",
    "                          if pd.notna(r.get(\"LAT\", np.nan)) and pd.notna(r.get(\"LON\", np.nan))]\n",
    "        if coords_cluster:\n",
    "            c_lat = float(np.mean([x for x,_ in coords_cluster]))\n",
    "            c_lon = float(np.mean([y for _,y in coords_cluster]))\n",
    "        else:\n",
    "            c_lat, c_lon = (np.nan, np.nan)\n",
    "\n",
    "        used_ids = [r[\"POZO\"] for r in rows_cluster]\n",
    "        return rows_cluster, (c_lat, c_lon), used_ids\n",
    "\n",
    "    def _append_cluster(rows_cluster, seed_pozo, seed_lat, seed_lon, c_lat, c_lon):\n",
    "        nonlocal remaining_cap, c_lat_acc, c_lon_acc, n_acc\n",
    "        used_now = set()\n",
    "        for r in rows_cluster:\n",
    "            if remaining_cap <= 0:\n",
    "                break\n",
    "            pozo = r[\"POZO\"]\n",
    "            if pozo in used_set or pozo in used_now:\n",
    "                continue\n",
    "\n",
    "            lat = r.get(\"LAT\", np.nan); lon = r.get(\"LON\", np.nan)\n",
    "            d_seed = haversine_km(seed_lat, seed_lon, lat, lon) if pd.notna(seed_lat) and pd.notna(seed_lon) else np.nan\n",
    "            d_cent = haversine_km(c_lat, c_lon, lat, lon)       if pd.notna(c_lat)  and pd.notna(c_lon)  else np.nan\n",
    "\n",
    "            assigned.append({\n",
    "                \"Plan_Fecha\": day_date.date(),\n",
    "                \"Semana_ISO\": day_date.isocalendar()[1],\n",
    "                \"ZONA\": r[\"ZONA\"],\n",
    "                \"BATERIA\": r[\"BATERIA\"],\n",
    "                \"POZO\": pozo,\n",
    "                \"r_m3_d\": float(r.get(\"__v\", r.get(\"r_m3_d\", np.nan))),\n",
    "                \"ultima_medicion\": r.get(\"ultima_medicion\", pd.NaT),\n",
    "                \"Seed_POZO\": seed_pozo,\n",
    "                \"Dist_km_semilla\": None if pd.isna(d_seed) else round(float(d_seed), 3),\n",
    "                \"Dist_km_centroid\": None if pd.isna(d_cent) else round(float(d_cent), 3),\n",
    "            })\n",
    "            used_now.add(pozo)\n",
    "            remaining_cap -= 1\n",
    "\n",
    "            if pd.notna(lat) and pd.notna(lon):\n",
    "                if n_acc == 0:\n",
    "                    c_lat_acc, c_lon_acc, n_acc = float(lat), float(lon), 1\n",
    "                else:\n",
    "                    c_lat_acc = (c_lat_acc*n_acc + float(lat)) / (n_acc + 1)\n",
    "                    c_lon_acc = (c_lon_acc*n_acc + float(lon)) / (n_acc + 1)\n",
    "                    n_acc += 1\n",
    "\n",
    "        return used_now\n",
    "\n",
    "    clusters_hechos = 0\n",
    "\n",
    "    while (remaining_cap > 0) and (not pool.empty):\n",
    "        cand_pool = pool[pool[\"has_coords\"]].copy()\n",
    "        best_total = None\n",
    "        best_seed_idx = None\n",
    "        best_cluster_rows = None\n",
    "\n",
    "        if not cand_pool.empty:\n",
    "            cand_seeds = cand_pool.sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]).head(max(1, TOP_N))\n",
    "            for seed_idx, seed_row in cand_seeds.iterrows():\n",
    "                seed_lat = seed_row.get(\"LAT\", np.nan)\n",
    "                seed_lon = seed_row.get(\"LON\", np.nan)\n",
    "                if pd.isna(seed_lat) or pd.isna(seed_lon):\n",
    "                    continue\n",
    "\n",
    "                neigh = _bb_filter(pool.drop(index=seed_idx, errors=\"ignore\"), seed_lat, seed_lon, radius_km)\n",
    "                if not neigh.empty:\n",
    "                    neigh = neigh.copy()\n",
    "                    neigh[\"__dist_seed\"] = neigh.apply(\n",
    "                        lambda r: haversine_km(seed_lat, seed_lon, r[\"LAT\"], r[\"LON\"]), axis=1\n",
    "                    )\n",
    "                    neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "                    neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "                max_neighbors_by_cluster = max(0, cluster_cap - 1)\n",
    "                max_neighbors_by_day     = max(0, remaining_cap - 1)\n",
    "                take_n = min(max_neighbors_by_cluster, max_neighbors_by_day)\n",
    "\n",
    "                if take_n > 0 and not neigh.empty:\n",
    "                    neigh_take = neigh.head(take_n)\n",
    "                    cluster_rows = [seed_row] + [nr for _, nr in neigh_take.iterrows()]\n",
    "                else:\n",
    "                    cluster_rows = [seed_row]\n",
    "\n",
    "                total_est = 0.0\n",
    "                for r in cluster_rows:\n",
    "                    rr = r.get(\"__v\", r.get(\"r_m3_d\", np.nan))\n",
    "                    total_est += _v_est_for_day({\"r_m3_d\": rr,\n",
    "                                                 \"ultima_medicion\": r.get(\"ultima_medicion\", pd.NaT)}, day_date)\n",
    "\n",
    "                if (best_total is None) or (total_est > best_total):\n",
    "                    best_total = total_est\n",
    "                    best_seed_idx = seed_idx\n",
    "                    best_cluster_rows = cluster_rows\n",
    "\n",
    "        else:\n",
    "            seed_row = pool.iloc[0]\n",
    "            seed_lat  = seed_row.get(\"LAT\", np.nan)\n",
    "            seed_lon  = seed_row.get(\"LON\", np.nan)\n",
    "            best_cluster_rows = [seed_row]\n",
    "            if pd.notna(seed_lat) and pd.notna(seed_lon):\n",
    "                neigh = _bb_filter(pool.iloc[1:], seed_lat, seed_lon, radius_km)\n",
    "                if not neigh.empty:\n",
    "                    neigh = neigh.copy()\n",
    "                    neigh[\"__dist_seed\"] = neigh.apply(\n",
    "                        lambda r: haversine_km(seed_lat, seed_lon, r[\"LAT\"], r[\"LON\"]), axis=1\n",
    "                    )\n",
    "                    neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "                    neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "                    max_neighbors_by_cluster = max(0, cluster_cap - 1)\n",
    "                    max_neighbors_by_day     = max(0, remaining_cap - 1)\n",
    "                    take_n = min(max_neighbors_by_cluster, max_neighbors_by_day)\n",
    "                    if take_n > 0 and not neigh.empty:\n",
    "                        for _, nr in neigh.head(take_n).iterrows():\n",
    "                            best_cluster_rows.append(nr)\n",
    "\n",
    "        if best_cluster_rows is None:\n",
    "            break\n",
    "\n",
    "        seed_row = best_cluster_rows[0]\n",
    "        seed_lat = seed_row.get(\"LAT\", np.nan)\n",
    "        seed_lon = seed_row.get(\"LON\", np.nan)\n",
    "\n",
    "        coords_cluster = [(r.get(\"LAT\", np.nan), r.get(\"LON\", np.nan))\n",
    "                          for r in best_cluster_rows\n",
    "                          if pd.notna(r.get(\"LAT\", np.nan)) and pd.notna(r.get(\"LON\", np.nan))]\n",
    "        if coords_cluster:\n",
    "            c_lat = float(np.mean([x for x,_ in coords_cluster]))\n",
    "            c_lon = float(np.mean([y for _,y in coords_cluster]))\n",
    "        else:\n",
    "            c_lat, c_lon = (np.nan, np.nan)\n",
    "\n",
    "        used_now = _append_cluster(best_cluster_rows, seed_row[\"POZO\"], seed_lat, seed_lon, c_lat, c_lon)\n",
    "\n",
    "        if used_now:\n",
    "            clusters_hechos += 1\n",
    "            used_set.update(used_now)\n",
    "            pool = pool[~pool[\"POZO\"].isin(used_now)].copy()\n",
    "        else:\n",
    "            pool = pool.iloc[1:].copy()\n",
    "\n",
    "        if not backfill_nearest or remaining_cap <= 0 or (clusters_max and clusters_hechos >= int(clusters_max)):\n",
    "            break\n",
    "\n",
    "        while (remaining_cap > 0) and (not pool.empty) and (not (clusters_max and clusters_hechos >= int(clusters_max))):\n",
    "            if pd.isna(c_lat_acc) or pd.isna(c_lon_acc) or (np.isnan(c_lat_acc) and np.isnan(c_lon_acc)):\n",
    "                break\n",
    "\n",
    "            pool = pool.copy()\n",
    "            pool[\"__dist_centroid\"] = pool.apply(\n",
    "                lambda r: haversine_km(c_lat_acc, c_lon_acc, r.get(\"LAT\", np.nan), r.get(\"LON\", np.nan)), axis=1\n",
    "            )\n",
    "            pool = pool[pool[\"__dist_centroid\"] <= float(umbral_km_backfill)].copy()\n",
    "            if pool.empty:\n",
    "                break\n",
    "\n",
    "            pool = pool.sort_values([\"__dist_centroid\",\"__v\"], ascending=[True, False])\n",
    "\n",
    "            seed = pool.iloc[0]\n",
    "            seed_lat = seed.get(\"LAT\", np.nan)\n",
    "            seed_lon = seed.get(\"LON\", np.nan)\n",
    "\n",
    "            rows_cluster, (c_lat, c_lon), used_ids = _build_cluster_from_seed(seed, pool.iloc[1:], remaining_cap)\n",
    "            used_now = _append_cluster(rows_cluster, seed[\"POZO\"], seed_lat, seed_lon, c_lat, c_lon)\n",
    "\n",
    "            if used_now:\n",
    "                clusters_hechos += 1\n",
    "                used_set.update(used_now)\n",
    "                pool = pool[~pool[\"POZO\"].isin(used_now)].copy()\n",
    "            else:\n",
    "                pool = pool.iloc[1:].copy()\n",
    "\n",
    "    return assigned\n",
    "\n",
    "def assign_week_round_robin_by_zone(cand_all, team_ids, params, week_start, week_end, radius_km):\n",
    "    dias   = int(params[\"dias_por_semana\"])\n",
    "    cap_pz = int(params[\"max_pozos_dia_equipo\"])\n",
    "    cap_cluster = int(params.get(\"max_pozos_por_cluster\", 4))\n",
    "\n",
    "    used_glob = set()\n",
    "    rows = []\n",
    "\n",
    "    for d in range(dias):\n",
    "        day_date = pd.Timestamp(week_start) + pd.Timedelta(days=d)\n",
    "\n",
    "        pool_day = cand_all[~cand_all[\"POZO\"].isin(used_glob)].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "        in_window = (pd.to_datetime(pool_day[\"due_date\"]) <= pd.Timestamp(week_end)) | pool_day[\"is_overdue\"]\n",
    "        pool_day = pool_day[in_window].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "\n",
    "        for eq in team_ids:\n",
    "            avail = pool_day[~pool_day[\"POZO\"].isin(used_glob)].copy()\n",
    "            if avail.empty:\n",
    "                continue\n",
    "\n",
    "            assigned_today = _fill_day_star_clusters(\n",
    "                day_date, avail, cap_pz, radius_km, used_glob,\n",
    "                cluster_cap=cap_cluster, params=params,\n",
    "                clusters_max=params.get(\"clusters_por_dia_max\"),\n",
    "                backfill_nearest=bool(params.get(\"backfill_nearest_cluster\", True)),\n",
    "                umbral_km_backfill=float(params.get(\"umbral_km_backfill\", 5.0))\n",
    "            )\n",
    "\n",
    "            for ord_idx, a in enumerate(assigned_today, start=1):\n",
    "                try:\n",
    "                    v_est = _v_est_for_day({\"r_m3_d\": a.get(\"r_m3_d\", np.nan),\n",
    "                                            \"ultima_medicion\": a.get(\"ultima_medicion\", pd.NaT)}, day_date)\n",
    "                except Exception:\n",
    "                    v_est = 0.0\n",
    "\n",
    "                a.update({\n",
    "                    \"Equipo\": int(eq),\n",
    "                    \"Dia_Idx\": d+1,\n",
    "                    \"Orden\": ord_idx,\n",
    "                    \"Vol_Estimado_m3\": round(float(v_est), 2)\n",
    "                })\n",
    "                rows.append(a)\n",
    "\n",
    "    cols = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "            \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "            \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\"]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "# ==========================\n",
    "# Export y ABM\n",
    "# ==========================\n",
    "def build_alertas_abm(freq_df: pd.DataFrame, norm_table: pd.DataFrame, dict_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if dict_df is None or dict_df.empty:\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"ZONA\",\"BATERIA\",\"ultima_medicion\",\"ultima_exitosa\",\"estado\",\"met_prod\"])\n",
    "    base = freq_df[[\"POZO\",\"ZONA\",\"BATERIA\",\"ultima_medicion\",\"ultima_exitosa\"]].copy()\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"estado\",\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    base = base.merge(meta_first[[\"estado\",\"met_prod\"]], left_on=\"POZO\", right_index=True, how=\"left\")\n",
    "    out = base.copy()\n",
    "    for c in [\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "        out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "    out = out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ==========================\n",
    "# RUNNER PARA JUPYTER\n",
    "# ==========================\n",
    "def run_pipeline_jupyter(\n",
    "    input_file,\n",
    "    nombres_pozo_file,\n",
    "    coords_file,\n",
    "    *,\n",
    "    semanas_plan=8,\n",
    "    equipos_activos=2,\n",
    "    dias_por_semana=5,\n",
    "    max_pozos_dia_equipo=10,\n",
    "    K_max_pozos_por_cluster=5,\n",
    "    clusters_por_dia_max=None,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=RM3D_MIN_DEFAULT,\n",
    "    zonas_incluir=None,              # lista de etiquetas nivel_3 (labels originales)\n",
    "    baterias_por_zona=None,          # dict norm: {zona_norm: set(bat_norm)} o None\n",
    "    pozos_excluir=None,              # set/list de POZOS a excluir\n",
    "    escribir_excel=False\n",
    "):\n",
    "    # 1) Leer historial\n",
    "    df = read_historial(input_file, sheet_hist=None)\n",
    "\n",
    "    # 2) Normalización via diccionario\n",
    "    key2off, dict_df = load_pozo_dictionary(nombres_pozo_file)\n",
    "    df_norm, alert_table, norm_table = apply_pozo_normalization(df, key2off, dict_df)\n",
    "\n",
    "    # Filtrar inválidos\n",
    "    df = df_norm[df_norm[\"VALIDO_POZO\"] == True].copy()\n",
    "\n",
    "    # 3) ZONAS a incluir\n",
    "    if zonas_incluir:\n",
    "        zonas_norm = {_norm(z) for z in zonas_incluir}\n",
    "        df = df[df[\"__ZONA_NORM\"].isin(zonas_norm)].copy()\n",
    "        zonas_labels = zonas_incluir\n",
    "    else:\n",
    "        zonas_labels = sorted(set(df[\"ZONA\"].dropna().astype(str)))\n",
    "\n",
    "    # Subfiltro baterías (ya viene por param)\n",
    "    allowed_bats_by_zone_norm = baterias_por_zona or {}\n",
    "\n",
    "    # 4) Exclusiones\n",
    "    excl_total = set(pozos_excluir or [])\n",
    "\n",
    "    # 5) Frecuencias\n",
    "    params = {\n",
    "        \"equipos_activos\": equipos_activos,\n",
    "        \"dias_por_semana\": dias_por_semana,\n",
    "        \"semanas_plan\": semanas_plan,\n",
    "        \"k_visitas\": 1,\n",
    "        \"max_pozos_dia_equipo\": max_pozos_dia_equipo,\n",
    "        \"max_pozos_por_cluster\": K_max_pozos_por_cluster,\n",
    "        \"m3_por_visita_objetivo\": 2.0,\n",
    "        \"min_dias_freq\": 7,\n",
    "        \"max_dias_freq\": 56,\n",
    "        \"dias_asumidos_una_visita\": 7,\n",
    "        \"freq_dias_ultimo_cero_valido\": 30,\n",
    "        \"top_semillas_eval\": 30,\n",
    "        \"clusters_por_dia_max\": clusters_por_dia_max,\n",
    "        \"backfill_nearest_cluster\": bool(backfill_nearest),\n",
    "        \"umbral_km_backfill\": float(umbral_km_backfill),\n",
    "    }\n",
    "\n",
    "    freq = compute_frecuencias(df, params)\n",
    "\n",
    "    # Comentario desde Observaciones cuando ultima_medicion != ultima_exitosa\n",
    "    df_obs = df[[\"POZO\", \"FECHA\", \"OBS_POZO\"]].copy() if \"OBS_POZO\" in df.columns else pd.DataFrame(columns=[\"POZO\",\"FECHA\",\"OBS_POZO\"])\n",
    "    df_obs[\"FECHA_DATE\"] = pd.to_datetime(df_obs[\"FECHA\"], errors=\"coerce\").dt.date\n",
    "    df_obs = (df_obs.dropna(subset=[\"FECHA_DATE\"])\n",
    "                    .sort_values([\"POZO\",\"FECHA_DATE\"])\n",
    "                    .drop_duplicates(subset=[\"POZO\",\"FECHA_DATE\"], keep=\"last\"))\n",
    "    obs_map = {(r.POZO, r.FECHA_DATE): (str(r.OBS_POZO).strip() if pd.notna(r.OBS_POZO) else \"\")\n",
    "               for r in df_obs.itertuples(index=False)}\n",
    "    freq[\"__UMED_DATE\"] = pd.to_datetime(freq[\"ultima_medicion\"], errors=\"coerce\").dt.date\n",
    "    freq[\"__UEXI_DATE\"] = pd.to_datetime(freq[\"ultima_exitosa\"], errors=\"coerce\").dt.date\n",
    "    freq[\"comentario\"] = [obs_map.get((pz, fmed), \"\") for pz, fmed in zip(freq[\"POZO\"], freq[\"__UMED_DATE\"])]\n",
    "    mask_both_valid = freq[\"__UMED_DATE\"].notna() & freq[\"__UEXI_DATE\"].notna()\n",
    "    mask_diff = mask_both_valid & (freq[\"__UMED_DATE\"] != freq[\"__UEXI_DATE\"])\n",
    "    freq.loc[~mask_diff, \"comentario\"] = \"\"\n",
    "    freq.drop(columns=[\"__UMED_DATE\",\"__UEXI_DATE\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # 7) Coordenadas\n",
    "    coords_df = read_coords(coords_file)\n",
    "\n",
    "    # 8) Mapas auxiliares\n",
    "    delta_by_pozo = freq.set_index(\"POZO\")[\"delta_star_dias\"].to_dict()\n",
    "    r_by_pozo     = freq.set_index(\"POZO\")[\"r_m3_d\"].to_dict()\n",
    "\n",
    "    # 9) Semanas\n",
    "    start = next_monday(date.today())\n",
    "    weeks = [(start + timedelta(weeks=i), start + timedelta(weeks=i, days=6)) for i in range(params[\"semanas_plan\"])]\n",
    "\n",
    "    # 10) Equipos fijos por zona\n",
    "    zonas_list = sorted(set(zonas_labels))\n",
    "    equipo_to_zona = {}\n",
    "    for i in range(1, params[\"equipos_activos\"]+1):\n",
    "        zona_asignada = zonas_list[min(i-1, len(zonas_list)-1)]\n",
    "        equipo_to_zona[i] = zona_asignada\n",
    "\n",
    "    # 11) Plan semanal\n",
    "    plan_all = []\n",
    "    next_due = {row.POZO: row.proxima_visita_base for row in freq.itertuples()}\n",
    "\n",
    "    zone_to_teams = {}\n",
    "    for eq, zona_label in equipo_to_zona.items():\n",
    "        zone_to_teams.setdefault(zona_label, []).append(eq)\n",
    "\n",
    "    for (w_start, w_end) in weeks:\n",
    "        for zona_label, team_list in zone_to_teams.items():\n",
    "            zona_norm_label = _norm(zona_label)\n",
    "\n",
    "            cand_all = build_candidates_with_coords(\n",
    "                freq=freq,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                excl_pozos=excl_total,\n",
    "                zonas_norm_incluidas={zona_norm_label},\n",
    "                coords_df=coords_df,\n",
    "                allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "                next_due_map=next_due,\n",
    "                rm3d_min=rm3d_min\n",
    "            )\n",
    "            if cand_all.empty:\n",
    "                continue\n",
    "\n",
    "            cand_zone = cand_all[[\n",
    "                \"POZO\",\"ZONA\",\"BATERIA\",\"due_date\",\"is_overdue\",\"__v\",\n",
    "                \"LAT\",\"LON\",\"has_coords\",\"r_m3_d\",\"ultima_medicion\"\n",
    "            ]].copy()\n",
    "\n",
    "            plan_week_zone = assign_week_round_robin_by_zone(\n",
    "                cand_all=cand_zone,\n",
    "                team_ids=sorted(team_list),\n",
    "                params=params,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                radius_km=radius_km\n",
    "            )\n",
    "\n",
    "            if not plan_week_zone.empty:\n",
    "                plan_all.append(plan_week_zone)\n",
    "                for pz, fcal in plan_week_zone[[\"POZO\",\"Plan_Fecha\"]].drop_duplicates().itertuples(index=False):\n",
    "                    dd = int(delta_by_pozo.get(pz, params[\"min_dias_freq\"]))\n",
    "                    next_due[pz] = pd.Timestamp(fcal) + pd.Timedelta(days=dd)\n",
    "\n",
    "    plan = pd.concat(plan_all, ignore_index=True) if plan_all else pd.DataFrame(columns=[\n",
    "        \"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "        \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\"\n",
    "    ])\n",
    "\n",
    "    # 12) Cobertura anual reforzada (igual a tu versión)\n",
    "    if not freq.empty:\n",
    "        eligible_mask = (freq[\"ZONA\"].isin(zonas_labels)) & (freq[\"r_m3_d\"].fillna(0) > rm3d_min)\n",
    "        if \"comentario\" in freq.columns:\n",
    "            eligible_mask &= (freq[\"comentario\"].astype(str).fillna(\"\").str.strip() == \"\")\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            for zn, bats in allowed_bats_by_zone_norm.items():\n",
    "                if bats is not None:\n",
    "                    eligible_mask &= (~(freq[\"ZONA_NORM\"] == zn)) | (freq[\"BATERIA_NORM\"].isin(bats))\n",
    "\n",
    "        all_pozos_in_zonas = freq.loc[eligible_mask, [\"POZO\",\"ZONA\",\"BATERIA\"]].drop_duplicates().copy()\n",
    "        all_pozos_in_zonas = all_pozos_in_zonas[\n",
    "            all_pozos_in_zonas[\"BATERIA\"].notna() & (all_pozos_in_zonas[\"BATERIA\"].astype(str).str.strip() != \"\")\n",
    "        ].copy()\n",
    "\n",
    "        # (Atajo simple en el harness: no reinyecto el ensure_annual_coverage para acortar tiempos de prueba)\n",
    "        # Si lo necesitás idéntico, puedo añadirlo también aquí.\n",
    "\n",
    "    # 13) Excel (opcional)\n",
    "    output_path = true\n",
    "    if escribir_excel:\n",
    "        output_path = unique_output_path(input_file)\n",
    "        coords_all = read_coords(coords_file)\n",
    "        with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "            # Frecuencias\n",
    "            freq_out = freq.copy()\n",
    "            for c in [\"proxima_visita_base\",\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "                freq_out[c] = pd.to_datetime(freq_out[c], errors=\"coerce\").dt.date\n",
    "            freq_out = freq_out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"])\n",
    "            cols_pref = [\"POZO\",\"ZONA\",\"BATERIA\",\"ZONA_NORM\",\"BATERIA_NORM\",\"r_m3_d\",\n",
    "                         \"ultima_medicion\",\"ultima_exitosa\",\"delta_star_dias\",\"comentario\",\n",
    "                         \"proxima_visita_base\",\"ceros_consec\",\"alerta\"]\n",
    "            cols_final = [c for c in cols_pref if c in freq_out.columns] + [c for c in freq_out.columns if c not in cols_pref]\n",
    "            freq_out = freq_out[cols_final]\n",
    "            freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
    "\n",
    "            # Plan por equipo (con Km_al_siguiente)\n",
    "            cols_plan = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "                         \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "                         \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\"]\n",
    "            for eq in range(1, params[\"equipos_activos\"]+1):\n",
    "                pe = plan.loc[plan[\"Equipo\"]==eq].copy()\n",
    "                if pe.empty:\n",
    "                    pe = pd.DataFrame(columns=cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"])\n",
    "                else:\n",
    "                    pe = pe.sort_values([\"Plan_Fecha\",\"Dia_Idx\",\"Orden\",\"POZO\"]).copy()\n",
    "                    pe = pe.merge(coords_all, how=\"left\", on=\"POZO\")\n",
    "                    pe[\"LAT_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LAT\"].shift(-1)\n",
    "                    pe[\"LON_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LON\"].shift(-1)\n",
    "                    def _leg_km(row):\n",
    "                        if (pd.isna(row.get(\"LAT\")) or pd.isna(row.get(\"LON\")) or\n",
    "                            pd.isna(row.get(\"LAT_next\")) or pd.isna(row.get(\"LON_next\"))):\n",
    "                            return None\n",
    "                        return round(float(haversine_km(row[\"LAT\"], row[\"LON\"], row[\"LAT_next\"], row[\"LON_next\"])), 3)\n",
    "                    pe[\"Km_al_siguiente\"] = pe.apply(_leg_km, axis=1)\n",
    "                    pe.drop(columns=[\"LAT\",\"LON\",\"LAT_next\",\"LON_next\"], inplace=True, errors=\"ignore\")\n",
    "                    pe[\"Ejecutado\"] = \"\"\n",
    "                    for c in cols_plan:\n",
    "                        if c not in pe.columns:\n",
    "                            pe[c] = \"\"\n",
    "                    pe = pe[cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"]]\n",
    "                pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
    "\n",
    "            if not norm_table.empty:\n",
    "                norm_table.to_excel(writer, \"Normalizacion_Pozos\", index=False)\n",
    "            if not alert_table.empty:\n",
    "                alert_table.to_excel(writer, \"Alertas_Normalizacion\", index=False)\n",
    "\n",
    "            alertas_abm = build_alertas_abm(freq_out, norm_table, dict_df)\n",
    "            alertas_abm.to_excel(writer, \"Alertas de ABM\", index=False)\n",
    "\n",
    "    return plan, freq, output_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === EJEMPLO DE USO EN JUPYTER ===\n",
    "# (Editá las rutas de tus archivos y parámetros)\n",
    "# plan, freq, out_xlsx = run_pipeline_jupyter(\n",
    "#     input_file=r\"DIAGRAMA SW.xlsx\",\n",
    "#     nombres_pozo_file=r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\",\n",
    "#     coords_file=r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\",\n",
    "#     semanas_plan=4,\n",
    "#     equipos_activos=2,\n",
    "#     dias_por_semana=5,\n",
    "#     max_pozos_dia_equipo=10,\n",
    "#     K_max_pozos_por_cluster=5,\n",
    "#     clusters_por_dia_max=None,\n",
    "#     backfill_nearest=True,\n",
    "#     umbral_km_backfill=5.0,\n",
    "#     radius_km=3.0,\n",
    "#     rm3d_min=0.1,\n",
    "#     zonas_incluir=[\"Las Heras CG - Canadon Escondida\"],  # o None para todas\n",
    "#     baterias_por_zona=None,         # por ejemplo: {\"las heras cg - canadon escondida\": {\"swabing ce\",\"ce 04\"}}\n",
    "#     pozos_excluir=set(),            # set de pozos a excluir\n",
    "#     escribir_excel=False            # True para exportar Excel\n",
    "# )\n",
    "# display(freq.head(10))\n",
    "# display(plan.head(20))\n",
    "# print(\"Excel:\", out_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24c29c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\CursoML-UDEMY\\env\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:422: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  g[col] = g[col].replace({None: np.nan})\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:1132: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  plan = (pd.concat(plan_all, ignore_index=True)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:964: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  plan = pd.concat([plan, pd.DataFrame(add)], ignore_index=True)                 .sort_values([\"Plan_Fecha\",\"Equipo\",\"Orden\"])\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:1182: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:1209: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:1209: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:1209: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\3823692740.py:1212: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POZO</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>ZONA_NORM</th>\n",
       "      <th>BATERIA_NORM</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ultima_exitosa</th>\n",
       "      <th>delta_star_dias</th>\n",
       "      <th>proxima_visita_base</th>\n",
       "      <th>ceros_consec</th>\n",
       "      <th>alerta</th>\n",
       "      <th>comentario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BB-10</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BB-100</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BB-101</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB.a-104</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB-111</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB-133</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BB-170</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BB-21</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BB497</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BB-50</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       POZO                              ZONA     BATERIA  \\\n",
       "0     BB-10  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "1    BB-100  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "2    BB-101  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "3  BB.a-104  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "4    BB-111  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "5    BB-133  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "6    BB-170  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "7     BB-21  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "8     BB497                                           NaN   \n",
       "9     BB-50  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "\n",
       "                        ZONA_NORM BATERIA_NORM    r_m3_d ultima_medicion  \\\n",
       "0  las heras cg canadon escondida   swabing ce  0.015385      2025-07-16   \n",
       "1  las heras cg canadon escondida   swabing ce  0.142857      2023-08-04   \n",
       "2  las heras cg canadon escondida   swabing ce  0.035714      2025-08-25   \n",
       "3  las heras cg canadon escondida   swabing ce  0.285714      2025-01-24   \n",
       "4  las heras cg canadon escondida   swabing ce  0.428571      2025-07-01   \n",
       "5  las heras cg canadon escondida   swabing ce  0.037037      2025-02-19   \n",
       "6  las heras cg canadon escondida   swabing ce  0.285714      2024-07-24   \n",
       "7  las heras cg canadon escondida   swabing ce  0.015564      2025-05-12   \n",
       "8                                               0.571429      2025-01-08   \n",
       "9  las heras cg canadon escondida   swabing ce  0.081633      2023-03-10   \n",
       "\n",
       "  ultima_exitosa  delta_star_dias proxima_visita_base  ceros_consec alerta  \\\n",
       "0     2025-07-16               56          2025-09-10             0          \n",
       "1     2023-08-04               14          2023-08-18             0          \n",
       "2     2025-08-25               56          2025-10-20             0          \n",
       "3     2025-01-24                7          2025-01-31             0          \n",
       "4     2025-07-01                7          2025-07-08             0          \n",
       "5     2025-02-19               56          2025-04-16             0          \n",
       "6     2024-07-24                7          2024-07-31             0          \n",
       "7     2025-05-12               56          2025-07-07             0          \n",
       "8     2025-01-08                7          2025-01-15             0          \n",
       "9     2023-03-10               28          2023-04-07             0          \n",
       "\n",
       "  comentario  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             \n",
       "5             \n",
       "6             \n",
       "7             \n",
       "8             \n",
       "9             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_Fecha</th>\n",
       "      <th>Semana_ISO</th>\n",
       "      <th>Equipo</th>\n",
       "      <th>Dia_Idx</th>\n",
       "      <th>Orden</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>POZO</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>Vol_Estimado_m3</th>\n",
       "      <th>Seed_POZO</th>\n",
       "      <th>Dist_km_semilla</th>\n",
       "      <th>Dist_km_centroid</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>__key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>CE10</td>\n",
       "      <td>CNEX1</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>6.73</td>\n",
       "      <td>CNEX1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>1|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>3.00</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.755</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 04</td>\n",
       "      <td>CnE-219</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>186.96</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>1.351</td>\n",
       "      <td>1.903</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>2|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-210</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>9.93</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>2.166</td>\n",
       "      <td>1.450</td>\n",
       "      <td>2025-07-24</td>\n",
       "      <td>2|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 03</td>\n",
       "      <td>CnE-124</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.43</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.441</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>2|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 01</td>\n",
       "      <td>CnE-731</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.43</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>2|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 12</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>49.09</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.735</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>3|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-1234</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>72.86</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>2.276</td>\n",
       "      <td>1.591</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>3|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 20</td>\n",
       "      <td>CnE-1224(d)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>37.14</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>2.494</td>\n",
       "      <td>1.928</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>3|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-543</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>9.72</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>2.626</td>\n",
       "      <td>2.801</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>3|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-849</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>14.80</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>0.605</td>\n",
       "      <td>1.152</td>\n",
       "      <td>2025-07-17</td>\n",
       "      <td>3|2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4.80</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.808</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>2|2025-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>BB.a-104</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>71.14</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>2.283</td>\n",
       "      <td>2.600</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2|2025-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 10</td>\n",
       "      <td>CnE.a-93</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>59.86</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>2.865</td>\n",
       "      <td>2.422</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>2|2025-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 11</td>\n",
       "      <td>CnE-379</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>29.87</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>1.929</td>\n",
       "      <td>1.121</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>2|2025-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>BB-111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>BB-100</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>112.57</td>\n",
       "      <td>BB-100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.129</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>3|2025-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>BB.a-75</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>30.62</td>\n",
       "      <td>BB-100</td>\n",
       "      <td>2.257</td>\n",
       "      <td>1.129</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>3|2025-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-624</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>4.88</td>\n",
       "      <td>CnE-624</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>2|2025-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>BB-170</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>124.00</td>\n",
       "      <td>CnE-624</td>\n",
       "      <td>2.924</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>2|2025-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 15</td>\n",
       "      <td>CnE-549</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9.22</td>\n",
       "      <td>CnE-624</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.339</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>2|2025-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 02</td>\n",
       "      <td>CnE-104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 18</td>\n",
       "      <td>CnE-1192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CG 17</td>\n",
       "      <td>CG-623</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>98.00</td>\n",
       "      <td>CG-623</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2025-09-17</td>\n",
       "      <td>3|2025-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>30.50</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.099</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>2|2025-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-521</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>3.87</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>1.867</td>\n",
       "      <td>1.393</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>2|2025-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-728</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>14.06</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>0.343</td>\n",
       "      <td>1.226</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>2|2025-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-694</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.14</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>1.543</td>\n",
       "      <td>0.526</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>2|2025-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-792</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4.00</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>2.906</td>\n",
       "      <td>1.861</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>2|2025-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-868</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>14.18</td>\n",
       "      <td>CnE-868</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>3|2025-10-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plan_Fecha  Semana_ISO  Equipo  Dia_Idx  Orden  \\\n",
       "0   2025-09-29          40       1        1      1   \n",
       "1   2025-09-29          40       2        1      1   \n",
       "2   2025-09-29          40       2        1      2   \n",
       "3   2025-09-29          40       2        1      3   \n",
       "4   2025-09-29          40       2        1      4   \n",
       "5   2025-09-29          40       2        1      5   \n",
       "6   2025-09-29          40       3        1      1   \n",
       "7   2025-09-29          40       3        1      2   \n",
       "8   2025-09-29          40       3        1      3   \n",
       "9   2025-09-29          40       3        1      4   \n",
       "10  2025-09-29          40       3        1      5   \n",
       "11  2025-09-30          40       2        2      1   \n",
       "12  2025-09-30          40       2        2      2   \n",
       "13  2025-09-30          40       2        2      3   \n",
       "14  2025-09-30          40       2        2      4   \n",
       "59  2025-09-30          40       2        2      5   \n",
       "15  2025-09-30          40       3        2      1   \n",
       "16  2025-09-30          40       3        2      2   \n",
       "17  2025-10-01          40       2        3      1   \n",
       "18  2025-10-01          40       2        3      2   \n",
       "19  2025-10-01          40       2        3      3   \n",
       "60  2025-10-01          40       2        3      4   \n",
       "61  2025-10-01          40       2        3      5   \n",
       "20  2025-10-01          40       3        3      1   \n",
       "21  2025-10-02          40       2        4      1   \n",
       "22  2025-10-02          40       2        4      2   \n",
       "23  2025-10-02          40       2        4      3   \n",
       "24  2025-10-02          40       2        4      4   \n",
       "25  2025-10-02          40       2        4      5   \n",
       "26  2025-10-02          40       3        4      1   \n",
       "\n",
       "                                ZONA     BATERIA         POZO    r_m3_d  \\\n",
       "0                                           CE10        CNEX1  0.192308   \n",
       "1   Las Heras CG - Canadon Escondida  Swabing CE      CnE-221  0.157895   \n",
       "2   Las Heras CG - Canadon Escondida       CE 04      CnE-219  0.291667   \n",
       "3   Las Heras CG - Canadon Escondida  Swabing CE      CnE-210  0.148148   \n",
       "4   Las Heras CG - Canadon Escondida       CE 03      CnE-124  0.142857   \n",
       "5   Las Heras CG - Canadon Escondida       CE 01      CnE-731  0.142857   \n",
       "6   Las Heras CG - Canadon Escondida       CE 12      CnE-829  0.181818   \n",
       "7   Las Heras CG - Canadon Escondida  Swabing CE     CnE-1234  0.285714   \n",
       "8   Las Heras CG - Canadon Escondida       CE 20  CnE-1224(d)  0.285714   \n",
       "9   Las Heras CG - Canadon Escondida  Swabing CE      CnE-543  0.277778   \n",
       "10  Las Heras CG - Canadon Escondida  Swabing CE      CnE-849  0.200000   \n",
       "11  Las Heras CG - Canadon Escondida  Swabing CE      CnE-736  0.266667   \n",
       "12  Las Heras CG - Canadon Escondida  Swabing CE     BB.a-104  0.285714   \n",
       "13  Las Heras CG - Canadon Escondida       CE 10     CnE.a-93  0.142857   \n",
       "14  Las Heras CG - Canadon Escondida       CE 11      CnE-379  0.133333   \n",
       "59  Las Heras CG - Canadon Escondida  Swabing CE       BB-111       NaN   \n",
       "15  Las Heras CG - Canadon Escondida  Swabing CE       BB-100  0.142857   \n",
       "16  Las Heras CG - Canadon Escondida  Swabing CE      BB.a-75  0.125000   \n",
       "17  Las Heras CG - Canadon Escondida  Swabing CE      CnE-624  0.187500   \n",
       "18  Las Heras CG - Canadon Escondida  Swabing CE       BB-170  0.285714   \n",
       "19  Las Heras CG - Canadon Escondida       CE 15      CnE-549  0.111111   \n",
       "60  Las Heras CG - Canadon Escondida       CE 02      CnE-104       NaN   \n",
       "61  Las Heras CG - Canadon Escondida       CE 18     CnE-1192       NaN   \n",
       "20  Las Heras CG - Canadon Escondida       CG 17       CG-623  7.000000   \n",
       "21  Las Heras CG - Canadon Escondida       CE 19      CnE-696  0.250000   \n",
       "22  Las Heras CG - Canadon Escondida  Swabing CE      CnE-521  0.161290   \n",
       "23  Las Heras CG - Canadon Escondida  Swabing CE      CnE-728  0.156250   \n",
       "24  Las Heras CG - Canadon Escondida       CE 19      CnE-694  0.142857   \n",
       "25  Las Heras CG - Canadon Escondida  Swabing CE      CnE-792  0.111111   \n",
       "26  Las Heras CG - Canadon Escondida  Swabing CE      CnE-868  0.272727   \n",
       "\n",
       "    Vol_Estimado_m3 Seed_POZO  Dist_km_semilla  Dist_km_centroid  \\\n",
       "0              6.73     CNEX1              NaN               NaN   \n",
       "1              3.00   CnE-221            0.000             0.755   \n",
       "2            186.96   CnE-221            1.351             1.903   \n",
       "3              9.93   CnE-221            2.166             1.450   \n",
       "4              4.43   CnE-221            0.937             0.441   \n",
       "5             34.43   CnE-221            2.669             2.275   \n",
       "6             49.09   CnE-829            0.000             0.735   \n",
       "7             72.86   CnE-829            2.276             1.591   \n",
       "8             37.14   CnE-829            2.494             1.928   \n",
       "9              9.72   CnE-829            2.626             2.801   \n",
       "10            14.80   CnE-829            0.605             1.152   \n",
       "11             4.80   CnE-736            0.000             0.808   \n",
       "12            71.14   CnE-736            2.283             2.600   \n",
       "13            59.86   CnE-736            2.865             2.422   \n",
       "14            29.87   CnE-736            1.929             1.121   \n",
       "59             0.00                        NaN               NaN   \n",
       "15           112.57    BB-100            0.000             1.129   \n",
       "16            30.62    BB-100            2.257             1.129   \n",
       "17             4.88   CnE-624            0.000             0.875   \n",
       "18           124.00   CnE-624            2.924             2.099   \n",
       "19             9.22   CnE-624            0.844             1.339   \n",
       "60             0.00                        NaN               NaN   \n",
       "61             0.00                        NaN               NaN   \n",
       "20            98.00    CG-623            0.000             0.000   \n",
       "21            30.50   CnE-696            0.000             1.099   \n",
       "22             3.87   CnE-696            1.867             1.393   \n",
       "23            14.06   CnE-696            0.343             1.226   \n",
       "24            34.14   CnE-696            1.543             0.526   \n",
       "25             4.00   CnE-696            2.906             1.861   \n",
       "26            14.18   CnE-868            0.000             0.923   \n",
       "\n",
       "   ultima_medicion         __key  \n",
       "0       2025-08-25  1|2025-09-29  \n",
       "1       2025-09-10  2|2025-09-29  \n",
       "2       2023-12-28  2|2025-09-29  \n",
       "3       2025-07-24  2|2025-09-29  \n",
       "4       2025-08-29  2|2025-09-29  \n",
       "5       2025-01-31  2|2025-09-29  \n",
       "6       2025-01-02  3|2025-09-29  \n",
       "7       2025-01-17  3|2025-09-29  \n",
       "8       2025-05-22  3|2025-09-29  \n",
       "9       2025-08-25  3|2025-09-29  \n",
       "10      2025-07-17  3|2025-09-29  \n",
       "11      2025-09-12  2|2025-09-30  \n",
       "12      2025-01-24  2|2025-09-30  \n",
       "13      2024-08-07  2|2025-09-30  \n",
       "14      2025-02-18  2|2025-09-30  \n",
       "59             NaT           NaN  \n",
       "15      2023-08-04  3|2025-09-30  \n",
       "16      2025-01-28  3|2025-09-30  \n",
       "17      2025-09-05  2|2025-10-01  \n",
       "18      2024-07-24  2|2025-10-01  \n",
       "19      2025-07-10  2|2025-10-01  \n",
       "60             NaT           NaN  \n",
       "61             NaT           NaN  \n",
       "20      2025-09-17  3|2025-10-01  \n",
       "21      2025-06-02  2|2025-10-02  \n",
       "22      2025-09-08  2|2025-10-02  \n",
       "23      2025-07-04  2|2025-10-02  \n",
       "24      2025-02-05  2|2025-10-02  \n",
       "25      2025-08-27  2|2025-10-02  \n",
       "26      2025-08-11  3|2025-10-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel generado: C:\\Users\\ry16123\\Downloads\\Ultimo (ORIGINAL) TABLERO PRODUCCIÓN FLUG S.A 2025 (1)_CRONOGRAMA_20250927_(7).xlsx\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Monocelda Jupyter: Planificador + Harness + Runner\n",
    "# ============================================\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, unicodedata, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "# ==========================\n",
    "# CONFIG por defecto (se sobreescriben en el runner)\n",
    "# ==========================\n",
    "INPUT_FILE  = r\"DIAGRAMA SW.xlsx\"   # Excel base (NO se modifica)\n",
    "SHEET_HIST  = None                  # None => autodetecta hoja/encabezados\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "# Radio en km para agrupar por cercanía\n",
    "RADIUS_KM = 3.0\n",
    "# Filtro mínimo de potencial\n",
    "RM3D_MIN = 0.1\n",
    "\n",
    "# Umbrales para fuzzy (si se usan)\n",
    "FUZZY_REPLACE_THRESHOLD = 85\n",
    "FUZZY_SUGGEST_THRESHOLD = 75\n",
    "LETTERS_SIMILARITY_MIN  = 80\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"equipos_activos\": 4,                 # 1..4\n",
    "    \"dias_por_semana\": 5,                 # 5 o 6\n",
    "    \"semanas_plan\": 2,                    # para probar rápido en Jupyter\n",
    "    \"k_visitas\": 1,                       # tasas (K=1 por pedido)\n",
    "    \"max_pozos_dia_equipo\": 10,           # cupo por día por equipo\n",
    "    \"max_pozos_por_cluster\": 5,           # tamaño de clúster (K fijo si usás lógica de clústeres fijos)\n",
    "    \"m3_por_visita_objetivo\": 2.0,        # informativo\n",
    "    \"min_dias_freq\": 7,                   # 1 semana\n",
    "    \"max_dias_freq\": 56,                  # 8 semanas\n",
    "    \"dias_asumidos_una_visita\": 7,        # para r si hay 1 sola visita\n",
    "    \"freq_dias_ultimo_cero_valido\": 30,\n",
    "\n",
    "    # Semillas a evaluar (si se usa lógica de semillas)\n",
    "    \"top_semillas_eval\": 30,\n",
    "\n",
    "    # Control de clústeres por día y backfill (si se usa lógica por semilla)\n",
    "    \"clusters_por_dia_max\": None,\n",
    "    \"backfill_nearest_cluster\": True,\n",
    "    \"umbral_km_backfill\": 5.0,\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Utils\n",
    "# ==========================\n",
    "def _norm(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = s.replace(\"³\", \"3\")\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip().replace(\"\\xa0\",\" \")\n",
    "    s = s.replace(\"_\",\" \").replace(\"-\",\" \").replace(\".\",\" \").replace(\"\\n\",\" \")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _pozo_key(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return \"\".join(ch for ch in s if ch.isalnum()).upper()\n",
    "\n",
    "def _canonical_digits(d: str) -> str:\n",
    "    d = (d or \"\").lstrip(\"0\")\n",
    "    return d if d != \"\" else \"0\"\n",
    "\n",
    "def _letters_digits_from_key_both(k: str):\n",
    "    raw_digits = \"\".join(re.findall(r\"\\d+\", k))\n",
    "    digits_canon = _canonical_digits(raw_digits)\n",
    "    letters = re.sub(r\"\\d+\", \"\", k)\n",
    "    return letters, digits_canon, len(raw_digits)\n",
    "\n",
    "def _ratio_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _fuzzy_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.partial_ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _canon_prefix_pozo(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return s\n",
    "    raw = str(s).strip()\n",
    "    raw_up = raw.upper()\n",
    "    if raw_up.startswith(\"CÑE\"):\n",
    "        return \"CNE\" + raw_up[3:]\n",
    "    raw_ascii = unicodedata.normalize(\"NFKD\", raw_up).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    if raw_ascii.startswith(\"CNE\"):\n",
    "        return raw_ascii\n",
    "    if raw_ascii.startswith(\"CN\"):\n",
    "        return \"CNE\" + raw_ascii[2:]\n",
    "    m = re.match(r\"^CE(\\d+)$\", raw_ascii)\n",
    "    if m:\n",
    "        return \"CNE\" + m.group(1)\n",
    "    return raw_ascii\n",
    "\n",
    "def next_monday(d=None):\n",
    "    d = d or date.today()\n",
    "    return d + timedelta(days=(7 - d.weekday()) % 7)  # 0=Lunes\n",
    "\n",
    "def unique_output_path(base_input_path: str) -> str:\n",
    "    folder = os.path.dirname(os.path.abspath(base_input_path))\n",
    "    stem   = os.path.splitext(os.path.basename(base_input_path))[0]\n",
    "    today  = datetime.now().strftime(\"%Y%m%d\")\n",
    "    base   = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}.xlsx\")\n",
    "    if not os.path.exists(base): return base\n",
    "    i = 2\n",
    "    while True:\n",
    "        cand = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}_({i}).xlsx\")\n",
    "        if not os.path.exists(cand): return cand\n",
    "        i += 1\n",
    "\n",
    "EXPECTED_KEYS = {\n",
    "    \"fecha\":       [\"fecha\"],\n",
    "    \"pozo\":        [\"pozo\"],\n",
    "    \"zona\":        [\"zona\"],\n",
    "    \"bateria\":     [\"bateria\", \"batería\"],\n",
    "    \"m3\":          [\"m3 bruta\",\"m3\",\"m3_bruta\",\"m3bruta\",\"m 3 bruta\",\"m 3\",\"m3 bruto\",\"m3 recuperado\",\"m3 recupero\"],\n",
    "    \"carreras\":    [\"n de carreras\",\"n° de carreras\",\"nº de carreras\",\"no de carreras\",\"nro de carreras\",\"numero de carreras\",\"n° carreras\",\"n de carrera\",\"n carreras\"],\n",
    "    \"nivel_final\": [\"nivel final pozo\",\"nivel final\",\"nivel final del pozo\"],\n",
    "    \"obs_pozo\":    [\"observaciones del pozo\",\"observaciones\",\"comentarios\",\"comentario\"]\n",
    "}\n",
    "\n",
    "def _find_header_row(df_raw):\n",
    "    for i in range(min(200, len(df_raw))):\n",
    "        row_norm = [_norm(x) for x in df_raw.iloc[i,:].tolist()]\n",
    "        if not row_norm:\n",
    "            continue\n",
    "        colmap = {v:j for v,j in zip(row_norm, range(len(row_norm)))}\n",
    "        def has_any(keys): return any(k in colmap for k in keys)\n",
    "        if has_any(EXPECTED_KEYS[\"fecha\"]) and has_any(EXPECTED_KEYS[\"pozo\"]) and has_any(EXPECTED_KEYS[\"zona\"]) and has_any(EXPECTED_KEYS[\"bateria\"]):\n",
    "            return i, row_norm\n",
    "    return None, None\n",
    "\n",
    "# ---------- Nombres pozo ----------\n",
    "def load_pozo_dictionary(xlsx_path: str):\n",
    "    try:\n",
    "        ref = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer diccionario de pozos: {xlsx_path}\\n{e}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    cols = {c.lower().strip(): c for c in ref.columns}\n",
    "    if \"nombre_corto_pozo\" not in cols:\n",
    "        print(f\"\\n[AVISO] El diccionario no tiene la columna 'nombre_corto_pozo'. Columnas: {list(ref.columns)}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    c_pozo = cols[\"nombre_corto_pozo\"]\n",
    "    c_met  = cols.get(\"met_prod\")\n",
    "    c_n3   = cols.get(\"nivel_3\")\n",
    "    c_n5   = cols.get(\"nivel_5\")\n",
    "    c_est  = cols.get(\"estado\")\n",
    "\n",
    "    refv = ref.loc[ref[c_pozo].notna()].copy()\n",
    "    refv[c_pozo] = refv[c_pozo].astype(str).str.strip()\n",
    "\n",
    "    of_list  = refv[c_pozo].tolist()\n",
    "    met_vals = refv[c_met].astype(str).str.strip() if c_met else np.nan\n",
    "    n3_vals  = refv[c_n3].astype(str).str.strip()  if c_n3 else np.nan\n",
    "    n5_vals  = refv[c_n5].astype(str).str.strip()  if c_n5 else np.nan\n",
    "    est_vals = refv[c_est].astype(str).str.strip() if c_est else np.nan\n",
    "\n",
    "    keys, letters_, digits_canon_, digits_len_ = [], [], [], []\n",
    "    for val in of_list:\n",
    "        k = _pozo_key(val)\n",
    "        L, Dcanon, Dlen = _letters_digits_from_key_both(k)\n",
    "        keys.append(k); letters_.append(L); digits_canon_.append(Dcanon); digits_len_.append(Dlen)\n",
    "\n",
    "    dict_df = pd.DataFrame({\n",
    "        \"oficial\": of_list,\n",
    "        \"key\": keys,\n",
    "        \"letters\": letters_,\n",
    "        \"digits_canon\": digits_canon_,\n",
    "        \"digits_len\": digits_len_,\n",
    "        \"met_prod\": list(met_vals) if isinstance(met_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_3\":  list(n3_vals)  if isinstance(n3_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_5\":  list(n5_vals)  if isinstance(n5_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"estado\":   list(est_vals) if isinstance(est_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "    })\n",
    "\n",
    "    key2off = {}\n",
    "    for k, off in zip(dict_df[\"key\"], dict_df[\"oficial\"]):\n",
    "        if k and k not in key2off:\n",
    "            key2off[k] = off\n",
    "    return key2off, dict_df\n",
    "\n",
    "def apply_pozo_normalization(df: pd.DataFrame, key2off: dict, dict_df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"POZO_ORIG\"] = df[\"POZO\"].astype(str).str.strip()\n",
    "    df[\"POZO_PreCanon\"] = df[\"POZO_ORIG\"].apply(_canon_prefix_pozo)\n",
    "    df[\"__POZO_KEY\"] = df[\"POZO_PreCanon\"].apply(_pozo_key)\n",
    "\n",
    "    parts = df[\"__POZO_KEY\"].apply(_letters_digits_from_key_both)\n",
    "    df[\"__KEY_LET\"], df[\"__KEY_DIG_CANON\"], df[\"__KEY_DIG_LEN\"] = zip(*parts)\n",
    "\n",
    "    df[\"POZO_MATCH\"]   = None\n",
    "    df[\"MATCH_TIPO\"]   = \"NO\"\n",
    "    df[\"MATCH_SCORE\"]  = np.nan\n",
    "    df[\"LETTER_SCORE\"] = np.nan\n",
    "    df[\"APLICADO\"]     = \"NO\"\n",
    "    df[\"ALERTA_NORM\"]  = \"\"\n",
    "    df[\"VALIDO_POZO\"]  = True\n",
    "\n",
    "    invalid_mask = (df[\"__KEY_LET\"].str.len()==0) | (df[\"__KEY_DIG_LEN\"]==0)\n",
    "    if invalid_mask.any():\n",
    "        df.loc[invalid_mask, \"ALERTA_NORM\"] = \"SIN_LETRAS_O_DIGITOS\"\n",
    "        df.loc[invalid_mask, \"VALIDO_POZO\"] = False\n",
    "\n",
    "    valid_mask = ~invalid_mask\n",
    "    exact_mask = valid_mask & df[\"__POZO_KEY\"].isin(key2off.keys())\n",
    "    df.loc[exact_mask, \"POZO_MATCH\"]   = df.loc[exact_mask, \"__POZO_KEY\"].map(key2off)\n",
    "    df.loc[exact_mask, \"MATCH_TIPO\"]   = \"EXACTO\"\n",
    "    df.loc[exact_mask, \"MATCH_SCORE\"]  = 100\n",
    "    df.loc[exact_mask, \"LETTER_SCORE\"] = 100\n",
    "    df.loc[exact_mask, \"APLICADO\"]     = \"SI\"\n",
    "\n",
    "    pending = df[valid_mask & (~exact_mask)].index.tolist()\n",
    "    if pending and not dict_df.empty:\n",
    "        dict_by_spec = {}\n",
    "        for spec, sub in dict_df.groupby([\"digits_canon\",\"digits_len\"]):\n",
    "            dict_by_spec[spec] = sub\n",
    "\n",
    "        for idx in pending:\n",
    "            key_u   = df.at[idx, \"__POZO_KEY\"]\n",
    "            let_u   = df.at[idx, \"__KEY_LET\"]\n",
    "            digc_u  = df.at[idx, \"__KEY_DIG_CANON\"]\n",
    "            digl_u  = int(df.at[idx, \"__KEY_DIG_LEN\"])\n",
    "\n",
    "            cand_df = dict_by_spec.get((digc_u, digl_u), pd.DataFrame())\n",
    "            best_off, best_score, best_lscore = None, -1, -1\n",
    "\n",
    "            if cand_df is not None and not cand_df.empty:\n",
    "                for row in cand_df.itertuples():\n",
    "                    kk = row.key\n",
    "                    ll = row.letters\n",
    "                    sc_key = _fuzzy_score(key_u, kk)\n",
    "                    sc_let = _ratio_score(let_u, ll)\n",
    "                    if sc_let < LETTERS_SIMILARITY_MIN:\n",
    "                        continue\n",
    "                    if sc_key > best_score or (sc_key == best_score and sc_let > best_lscore):\n",
    "                        best_score = sc_key\n",
    "                        best_lscore = sc_let\n",
    "                        best_off   = row.oficial\n",
    "\n",
    "            if best_off is not None:\n",
    "                df.at[idx, \"POZO_MATCH\"]   = best_off\n",
    "                df.at[idx, \"MATCH_TIPO\"]   = \"SUGERIDO\"\n",
    "                df.at[idx, \"MATCH_SCORE\"]  = int(best_score)\n",
    "                df.at[idx, \"LETTER_SCORE\"] = int(best_lscore)\n",
    "            else:\n",
    "                df.at[idx, \"ALERTA_NORM\"] = \"SIN MATCH EN DICCIONARIO\"\n",
    "\n",
    "    # Reemplazos\n",
    "    df[\"POZO\"] = df[\"POZO_MATCH\"].where(df[\"POZO_MATCH\"].notna(), df[\"POZO\"])\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    df = df.merge(meta_first, how=\"left\", left_on=\"POZO\", right_index=True)\n",
    "\n",
    "    # ZONA sólo si hubo match; sino, vacío\n",
    "    if \"nivel_3\" in df.columns:\n",
    "        df.loc[df[\"POZO_MATCH\"].isna(), \"nivel_3\"] = \"\"\n",
    "        df[\"ZONA\"] = np.where(df[\"POZO_MATCH\"].notna(), df[\"nivel_3\"].fillna(\"\"), \"\")\n",
    "\n",
    "    # BATERIA si hay nivel_5\n",
    "    if \"nivel_5\" in df.columns:\n",
    "        df[\"BATERIA\"] = np.where(\n",
    "            df[\"nivel_5\"].notna() & (df[\"nivel_5\"].astype(str).str.strip()!=\"\"),\n",
    "            df[\"nivel_5\"], df[\"BATERIA\"]\n",
    "        )\n",
    "\n",
    "    df[\"__ZONA_NORM\"]    = df[\"ZONA\"].apply(_norm)\n",
    "    df[\"__BATERIA_NORM\"] = df[\"BATERIA\"].apply(_norm)\n",
    "\n",
    "    norm_table = (df[[\"POZO_ORIG\",\"POZO_PreCanon\",\"__POZO_KEY\",\n",
    "                      \"__KEY_LET\",\"__KEY_DIG_CANON\",\"__KEY_DIG_LEN\",\n",
    "                      \"POZO_MATCH\",\"MATCH_TIPO\",\"MATCH_SCORE\",\"LETTER_SCORE\",\n",
    "                      \"APLICADO\",\"ALERTA_NORM\",\"VALIDO_POZO\",\n",
    "                      \"met_prod\",\"nivel_3\",\"nivel_5\"]]\n",
    "                  .drop_duplicates()\n",
    "                  .rename(columns={\n",
    "                      \"POZO_ORIG\":\"Pozo_Original\",\n",
    "                      \"POZO_PreCanon\":\"Pozo_PreCanon\",\n",
    "                      \"__POZO_KEY\":\"Clave_Normalizada\",\n",
    "                      \"__KEY_LET\":\"Letras\",\n",
    "                      \"__KEY_DIG_CANON\":\"Digitos_Canon\",\n",
    "                      \"__KEY_DIG_LEN\":\"Digitos_Len\",\n",
    "                      \"POZO_MATCH\":\"Match_Oficial\",\n",
    "                      \"MATCH_TIPO\":\"Match_Tipo\",\n",
    "                      \"MATCH_SCORE\":\"Match_Score\",\n",
    "                      \"LETTER_SCORE\":\"Letter_Score\",\n",
    "                      \"APLICADO\":\"Aplicado\",\n",
    "                      \"ALERTA_NORM\":\"Alerta\",\n",
    "                      \"VALIDO_POZO\":\"Valido\",\n",
    "                      \"met_prod\":\"met_prod\",\n",
    "                      \"nivel_3\":\"nivel_3\",\n",
    "                      \"nivel_5\":\"nivel_5\"\n",
    "                  })\n",
    "                  .sort_values([\"Valido\",\"Aplicado\",\"Match_Tipo\",\"Pozo_Original\"], ascending=[False, False, True, True]))\n",
    "\n",
    "    alert_table = norm_table[(norm_table[\"Valido\"]==False) | (norm_table[\"Aplicado\"]==\"NO\") | (norm_table[\"Match_Tipo\"]==\"NO\")].copy()\n",
    "    return df, alert_table, norm_table\n",
    "\n",
    "def read_historial(xlsx_path, sheet_hist=None):\n",
    "    xl = pd.ExcelFile(xlsx_path)\n",
    "    sheets = [sheet_hist] if (sheet_hist and sheet_hist in xl.sheet_names) else xl.sheet_names\n",
    "    for sh in sheets:\n",
    "        raw = xl.parse(sh, header=None)\n",
    "        idx, header_norm = _find_header_row(raw)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        data = raw.iloc[idx:, :].copy()\n",
    "        true_headers = data.iloc[0,:].astype(str).tolist()\n",
    "        data = data.iloc[1:,:]\n",
    "        data.columns = true_headers\n",
    "\n",
    "        name_map = {c: _norm(c) for c in data.columns}\n",
    "        def find_col(candidates):\n",
    "            for c, n in name_map.items():\n",
    "                if n in candidates:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        c_fecha       = find_col(set(EXPECTED_KEYS[\"fecha\"]))\n",
    "        c_pozo        = find_col(set(EXPECTED_KEYS[\"pozo\"]))\n",
    "        c_zona        = find_col(set(EXPECTED_KEYS[\"zona\"]))\n",
    "        c_bateria     = find_col(set(EXPECTED_KEYS[\"bateria\"]))\n",
    "        c_m3          = find_col(set(EXPECTED_KEYS[\"m3\"]))\n",
    "        c_carr        = find_col(set(EXPECTED_KEYS[\"carreras\"]))\n",
    "        c_nivel_final = find_col(set(EXPECTED_KEYS[\"nivel_final\"]))\n",
    "        c_obs         = find_col(set(EXPECTED_KEYS[\"obs_pozo\"]))\n",
    "\n",
    "        if not (c_fecha and c_pozo and c_zona and c_bateria):\n",
    "            continue\n",
    "\n",
    "        use_cols = [c_fecha, c_pozo, c_zona, c_bateria]\n",
    "        headers  = [\"FECHA\",\"POZO\",\"ZONA\",\"BATERIA\"]\n",
    "        if c_m3:            use_cols.append(c_m3);            headers.append(\"M3\")\n",
    "        if c_carr:          use_cols.append(c_carr);          headers.append(\"CARRERAS\")\n",
    "        if c_nivel_final:   use_cols.append(c_nivel_final);   headers.append(\"NIVEL_FINAL\")\n",
    "        if c_obs:           use_cols.append(c_obs);           headers.append(\"OBS_POZO\")\n",
    "\n",
    "        df = data[use_cols].copy()\n",
    "        df.columns = headers\n",
    "\n",
    "        df[\"FECHA\"] = pd.to_datetime(df[\"FECHA\"], errors=\"coerce\")\n",
    "        if \"M3\" not in df.columns: df[\"M3\"] = np.nan\n",
    "        else: df[\"M3\"] = pd.to_numeric(df[\"M3\"], errors=\"coerce\")\n",
    "\n",
    "        if \"CARRERAS\" not in df.columns: df[\"CARRERAS\"] = np.nan\n",
    "        else: df[\"CARRERAS\"] = pd.to_numeric(df[\"CARRERAS\"], errors=\"coerce\")\n",
    "\n",
    "        if \"NIVEL_FINAL\" not in df.columns:\n",
    "            df[\"NIVEL_FINAL\"] = None\n",
    "        if \"OBS_POZO\" not in df.columns:\n",
    "            df[\"OBS_POZO\"] = None\n",
    "\n",
    "        for col in [\"POZO\",\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\",\"OBS_POZO\"]:\n",
    "            df[col] = df[col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "        df = df.dropna(subset=[\"FECHA\",\"POZO\"]).sort_values([\"POZO\",\"FECHA\"])\n",
    "        return df\n",
    "\n",
    "    raise ValueError(\"No pude detectar FECHA/POZO/ZONA/BATERÍA en ninguna hoja del Excel.\")\n",
    "\n",
    "def read_exclusions_from_sheet(xlsx_path):\n",
    "    excl = set()\n",
    "    try:\n",
    "        xl = pd.ExcelFile(xlsx_path)\n",
    "        if \"ExcluirPozos\" in xl.sheet_names:\n",
    "            e = xl.parse(\"ExcluirPozos\")\n",
    "            e.columns = [str(c).strip().lower() for c in e.columns]\n",
    "            if \"pozo\" in e.columns:\n",
    "                if \"excluir\" in e.columns:\n",
    "                    excl = set(e.loc[e[\"excluir\"].astype(str).str.upper().isin(\n",
    "                        [\"SI\",\"SÍ\",\"YES\",\"1\",\"TRUE\"]), \"pozo\"].astype(str).str.strip())\n",
    "                else:\n",
    "                    excl = set(e[\"pozo\"].astype(str).str.strip())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return excl\n",
    "\n",
    "# ==========================\n",
    "# Frecuencias / r_m3_d\n",
    "# ==========================\n",
    "def _count_trailing_zeros_with_carr(g):\n",
    "    cnt = 0\n",
    "    for _, row in g.sort_values(\"FECHA\").iloc[::-1].iterrows():\n",
    "        m3 = row.get(\"M3\", np.nan)\n",
    "        car = row.get(\"CARRERAS\", np.nan)\n",
    "        if pd.notna(m3) and float(m3) == 0.0 and pd.notna(car) and float(car) > 0:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    return cnt\n",
    "\n",
    "def compute_frecuencias(df, params):\n",
    "    v_target = params[\"m3_por_visita_objetivo\"]\n",
    "    min_d    = params[\"min_dias_freq\"]\n",
    "    max_d    = params[\"max_dias_freq\"]\n",
    "    k        = int(params[\"k_visitas\"])\n",
    "    one_days = int(params.get(\"dias_asumidos_una_visita\", 7))\n",
    "    freq_cero_ultimo = int(params.get(\"freq_dias_ultimo_cero_valido\", 30))\n",
    "\n",
    "    out = []\n",
    "    for pozo, g0 in df.groupby(\"POZO\", sort=False):\n",
    "        g = g0.sort_values(\"FECHA\").copy()\n",
    "\n",
    "        for col in [\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\"]:\n",
    "            if col in g.columns:\n",
    "                g[col] = g[col].replace({None: np.nan})\n",
    "                g[col] = g[col].ffill().bfill()\n",
    "\n",
    "        g[\"__ZONA_NORM\"]    = g[\"ZONA\"].apply(_norm)\n",
    "        g[\"__BATERIA_NORM\"] = g[\"BATERIA\"].apply(_norm)\n",
    "        g[\"__nf_norm\"]      = g[\"NIVEL_FINAL\"].apply(_norm) if \"NIVEL_FINAL\" in g.columns else \"\"\n",
    "\n",
    "        med_validas_all = g[g[\"M3\"].notna()].copy()\n",
    "\n",
    "        m3_eq0 = g[\"M3\"].fillna(0) == 0\n",
    "        carr   = g.get(\"CARRERAS\", pd.Series(index=g.index, dtype=float)).fillna(np.nan)\n",
    "        zero_cond_a = m3_eq0 & (carr.fillna(0) >= 1)\n",
    "        zero_cond_b = m3_eq0 & ((carr.isna()) | (carr.fillna(0) == 0)) & (g[\"__nf_norm\"] == \"surge\")\n",
    "        cond_cero_valido = zero_cond_a | zero_cond_b\n",
    "\n",
    "        validas_rate = g[(g[\"M3\"] > 0) | cond_cero_valido].copy()\n",
    "        zeros_tail = _count_trailing_zeros_with_carr(g)\n",
    "\n",
    "        ultima_med = med_validas_all[\"FECHA\"].max() if not med_validas_all.empty else pd.NaT\n",
    "        ultima_exi = g.loc[g[\"M3\"]>0, \"FECHA\"].max() if \"M3\" in g.columns and not g[g[\"M3\"]>0].empty else pd.NaT\n",
    "\n",
    "        last_zero_valido = False\n",
    "        if not med_validas_all.empty:\n",
    "            idx_last = med_validas_all[\"FECHA\"].idxmax()\n",
    "            m3_last  = g.at[idx_last, \"M3\"]\n",
    "            if pd.notna(m3_last) and float(m3_last) == 0.0:\n",
    "                try:\n",
    "                    last_zero_valido = bool(cond_cero_valido.loc[idx_last])\n",
    "                except Exception:\n",
    "                    last_zero_valido = False\n",
    "\n",
    "        alerta = \"\"\n",
    "        if last_zero_valido:\n",
    "            alerta = f\"ULTIMA_M3_0_VALIDO -> FREQ {freq_cero_ultimo}D\"\n",
    "        elif pd.notna(ultima_med):\n",
    "            if zeros_tail > 0:\n",
    "                alerta = f\"ALERTA: {zeros_tail} cero(s) consecutivo(s) con Carreras>0\"\n",
    "\n",
    "        # r_m3_d\n",
    "        r = np.nan\n",
    "        if not validas_rate.empty:\n",
    "            v = validas_rate.copy()\n",
    "            v[\"delta_d\"] = v[\"FECHA\"].diff().dt.days\n",
    "            v.loc[v[\"delta_d\"] <= 0, \"delta_d\"] = np.nan\n",
    "            v[\"rate\"] = v[\"M3\"].fillna(0) / v[\"delta_d\"]\n",
    "            rates = v[\"rate\"].dropna()\n",
    "            if len(rates) >= 1:\n",
    "                r = rates.tail(min(k, len(rates))).mean()\n",
    "            else:\n",
    "                row = v.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "        else:\n",
    "            if len(med_validas_all) == 1:\n",
    "                row = med_validas_all.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "\n",
    "        # FRECUENCIA\n",
    "        if last_zero_valido:\n",
    "            delta = int(freq_cero_ultimo)\n",
    "        else:\n",
    "            if pd.isna(r):      delta = 7\n",
    "            elif r <= 0:        delta = max_d\n",
    "            else:\n",
    "                delta = max(min_d, min(max_d, float(v_target)/float(r)))\n",
    "                delta = int(7 * round(delta / 7.0))\n",
    "                if delta < 7:\n",
    "                    delta = 7\n",
    "\n",
    "        prox = (ultima_med + pd.Timedelta(days=int(delta))) if pd.notna(ultima_med) else pd.Timestamp(next_monday())\n",
    "\n",
    "        out.append({\n",
    "            \"POZO\": pozo,\n",
    "            \"ZONA\": g[\"ZONA\"].iloc[-1],\n",
    "            \"BATERIA\": g[\"BATERIA\"].iloc[-1],\n",
    "            \"ZONA_NORM\": g[\"__ZONA_NORM\"].iloc[-1],\n",
    "            \"BATERIA_NORM\": g[\"__BATERIA_NORM\"].iloc[-1],\n",
    "            \"r_m3_d\": r,\n",
    "            \"ultima_medicion\": ultima_med,\n",
    "            \"ultima_exitosa\": ultima_exi,\n",
    "            \"delta_star_dias\": int(delta),\n",
    "            \"proxima_visita_base\": prox,\n",
    "            \"ceros_consec\": zeros_tail,\n",
    "            \"alerta\": alerta\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# ==========================\n",
    "# Coordenadas\n",
    "# ==========================\n",
    "def _to_float_maybe_comma(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if s == \"\": return np.nan\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def read_coords(xlsx_path):\n",
    "    try:\n",
    "        cdf = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer coordenadas: {xlsx_path}\\n{e}\\n\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    cols_map = {c.lower().strip(): c for c in cdf.columns}\n",
    "    c_pozo = cols_map.get(\"pozo\")\n",
    "    for k in [\"geo_latitude\",\"latitude\",\"lat\"]:\n",
    "        if k in cols_map:\n",
    "            c_lat = cols_map[k]; break\n",
    "    else:\n",
    "        c_lat = None\n",
    "    for k in [\"geo_longitude\",\"longitude\",\"lon\",\"long\"]:\n",
    "        if k in cols_map:\n",
    "            c_lon = cols_map[k]; break\n",
    "    else:\n",
    "        c_lon = None\n",
    "\n",
    "    if not (c_pozo and c_lat and c_lon):\n",
    "        print(f\"[AVISO] Coordenadas: columnas esperadas 'POZO','GEO_LATITUDE','GEO_LONGITUDE'. Columnas encontradas: {list(cdf.columns)}\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "\n",
    "    out = cdf[[c_pozo, c_lat, c_lon]].copy()\n",
    "    out.columns = [\"POZO\",\"LAT\",\"LON\"]\n",
    "    out[\"POZO\"] = out[\"POZO\"].astype(str).str.strip()\n",
    "    out[\"LAT\"] = out[\"LAT\"].apply(_to_float_maybe_comma)\n",
    "    out[\"LON\"] = out[\"LON\"].apply(_to_float_maybe_comma)\n",
    "    out = out.dropna(subset=[\"POZO\"])\n",
    "    out = out.drop_duplicates(subset=[\"POZO\"], keep=\"last\")\n",
    "    return out\n",
    "\n",
    "# ==========================\n",
    "# Candidatos y utilidades\n",
    "# ==========================\n",
    "def build_candidates_with_coords(freq, week_start, week_end, excl_pozos,\n",
    "                                 zonas_norm_incluidas, coords_df,\n",
    "                                 allowed_bats_by_zone_norm=None,\n",
    "                                 next_due_map=None):\n",
    "    F = freq.copy()\n",
    "\n",
    "    # due_date base (permitimos override con next_due_map)\n",
    "    F[\"due_date\"] = F[\"proxima_visita_base\"]\n",
    "    if next_due_map:\n",
    "        F[\"due_date\"] = F[\"POZO\"].map(next_due_map).fillna(F[\"due_date\"])\n",
    "\n",
    "    F[\"overdue_d\"] = (pd.Timestamp(week_start) - pd.to_datetime(F[\"due_date\"])).dt.days\n",
    "    F[\"is_overdue\"] = F[\"overdue_d\"] > 0\n",
    "\n",
    "    # prioridad\n",
    "    F[\"__v\"] = F[\"r_m3_d\"].astype(float)\n",
    "\n",
    "    # Filtro por ZONA (normalizada)\n",
    "    if \"ZONA_NORM\" in F.columns and zonas_norm_incluidas:\n",
    "        F = F[F[\"ZONA_NORM\"].isin(zonas_norm_incluidas)].copy()\n",
    "\n",
    "    # Sub-filtro por BATERÍA (si corresponde)\n",
    "    if allowed_bats_by_zone_norm:\n",
    "        mask = pd.Series(True, index=F.index)\n",
    "        for zn in zonas_norm_incluidas:\n",
    "            bats = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats is not None:\n",
    "                mask &= ~ (F[\"ZONA_NORM\"] == zn) | (F[\"BATERIA_NORM\"].isin(bats))\n",
    "        F = F[mask].copy()\n",
    "\n",
    "    # Exclusiones\n",
    "    if excl_pozos:\n",
    "        F = F[~F[\"POZO\"].isin(excl_pozos)].copy()\n",
    "\n",
    "    # Potencial mínimo y BATERÍA no vacía\n",
    "    F = F[F[\"r_m3_d\"].fillna(0) > RM3D_MIN].copy()\n",
    "    F = F[F[\"BATERIA\"].notna() & (F[\"BATERIA\"].astype(str).str.strip() != \"\")].copy()\n",
    "\n",
    "    # Excluir pozos con comentario no vacío en Frecuencias\n",
    "    if \"comentario\" in F.columns:\n",
    "        F[\"__comentario_txt\"] = F[\"comentario\"].astype(str).fillna(\"\").str.strip()\n",
    "        F = F[F[\"__comentario_txt\"] == \"\"].copy()\n",
    "        F.drop(columns=[\"__comentario_txt\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Merge coordenadas\n",
    "    coords_df = coords_df if coords_df is not None else pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    F = F.merge(coords_df, how=\"left\", on=\"POZO\")\n",
    "    F[\"has_coords\"] = F[\"LAT\"].notna() & F[\"LON\"].notna()\n",
    "\n",
    "    # Orden base\n",
    "    F = F.sort_values(by=[\"is_overdue\",\"__v\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    return F\n",
    "\n",
    "def _v_est_for_day(row, day_date):\n",
    "    r = row.get(\"r_m3_d\", np.nan)\n",
    "    u = row.get(\"ultima_medicion\", pd.NaT)\n",
    "    if pd.isna(u) or pd.isna(r) or r <= 0:\n",
    "        return 0.0\n",
    "    dd = max(0, (pd.Timestamp(day_date) - pd.Timestamp(u)).days)\n",
    "    return max(0.0, float(r) * float(dd))\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "            return np.nan\n",
    "        R = 6371.0088\n",
    "        p1 = math.radians(float(lat1)); p2 = math.radians(float(lat2))\n",
    "        dphi = math.radians(float(lat2) - float(lat1))\n",
    "        dlmb = math.radians(float(lon2) - float(lon1))\n",
    "        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "        return 2*R*math.asin(math.sqrt(a))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ==========================\n",
    "# Lógica de asignación diaria simple (por “semilla”, como en tu versión original)\n",
    "# ==========================\n",
    "def _fill_day_star_clusters(day_date, avail_df, cap_per_day, radius_km, used_set,\n",
    "                            cluster_cap, params=None,\n",
    "                            clusters_max=None, backfill_nearest=True, umbral_km_backfill=5.0):\n",
    "    assigned = []\n",
    "    remaining_cap = int(cap_per_day)\n",
    "    cluster_cap   = max(1, int(cluster_cap))\n",
    "    TOP_N = 30 if params is None else int(params.get(\"top_semillas_eval\", 30))\n",
    "\n",
    "    if params is not None and params.get(\"umbral_km_backfill\") is not None:\n",
    "        umbral_km_backfill = float(params.get(\"umbral_km_backfill\"))\n",
    "\n",
    "    has_xy = avail_df[\"has_coords\"].fillna(False)\n",
    "    pool = pd.concat([\n",
    "        avail_df.loc[has_xy].sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]),\n",
    "        avail_df.loc[~has_xy].sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]),\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    def _bb_filter(df, lat0, lon0, rad_km):\n",
    "        if pd.isna(lat0) or pd.isna(lon0) or df.empty:\n",
    "            return df.iloc[0:0]\n",
    "        dlat = rad_km / 110.574\n",
    "        dlon = rad_km / (111.320 * max(0.1, math.cos(math.radians(float(lat0)))))\n",
    "        return df[(df[\"LAT\"].between(lat0 - dlat, lat0 + dlat)) &\n",
    "                  (df[\"LON\"].between(lon0 - dlon, lon0 + dlon))].copy()\n",
    "\n",
    "    c_lat_acc, c_lon_acc, n_acc = (np.nan, np.nan, 0)\n",
    "\n",
    "    def _build_cluster_from_seed(seed_row, pool_df, cap_left):\n",
    "        seed_lat = seed_row.get(\"LAT\", np.nan)\n",
    "        seed_lon = seed_row.get(\"LON\", np.nan)\n",
    "        rows_cluster = [seed_row]\n",
    "\n",
    "        if pd.notna(seed_lat) and pd.notna(seed_lon):\n",
    "            neigh = _bb_filter(pool_df, seed_lat, seed_lon, radius_km)\n",
    "            if not neigh.empty:\n",
    "                neigh = neigh.copy()\n",
    "                neigh[\"__dist_seed\"] = neigh.apply(\n",
    "                    lambda r: haversine_km(seed_lat, seed_lon, r[\"LAT\"], r[\"LON\"]), axis=1\n",
    "                )\n",
    "                neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "                neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "                max_neighbors_by_cluster = max(0, cluster_cap - 1)\n",
    "                max_neighbors_by_day     = max(0, cap_left - 1)\n",
    "                take_n = min(max_neighbors_by_cluster, max_neighbors_by_day)\n",
    "                if take_n > 0 and not neigh.empty:\n",
    "                    rows_cluster.extend([nr for _, nr in neigh.head(take_n).iterrows()])\n",
    "\n",
    "        coords_cluster = [(r.get(\"LAT\", np.nan), r.get(\"LON\", np.nan))\n",
    "                          for r in rows_cluster\n",
    "                          if pd.notna(r.get(\"LAT\", np.nan)) and pd.notna(r.get(\"LON\", np.nan))]\n",
    "        if coords_cluster:\n",
    "            c_lat = float(np.mean([x for x,_ in coords_cluster]))\n",
    "            c_lon = float(np.mean([y for _,y in coords_cluster]))\n",
    "        else:\n",
    "            c_lat, c_lon = (np.nan, np.nan)\n",
    "\n",
    "        used_ids = [r[\"POZO\"] for r in rows_cluster]\n",
    "        return rows_cluster, (c_lat, c_lon), used_ids\n",
    "\n",
    "    def _append_cluster(rows_cluster, seed_pozo, seed_lat, seed_lon, c_lat, c_lon):\n",
    "        nonlocal remaining_cap, c_lat_acc, c_lon_acc, n_acc\n",
    "        used_now = set()\n",
    "        for r in rows_cluster:\n",
    "            if remaining_cap <= 0:\n",
    "                break\n",
    "            pozo = r[\"POZO\"]\n",
    "            if pozo in used_set or pozo in used_now:\n",
    "                continue\n",
    "\n",
    "            lat = r.get(\"LAT\", np.nan); lon = r.get(\"LON\", np.nan)\n",
    "            d_seed = haversine_km(seed_lat, seed_lon, lat, lon) if pd.notna(seed_lat) and pd.notna(seed_lon) else np.nan\n",
    "            d_cent = haversine_km(c_lat, c_lon, lat, lon)       if pd.notna(c_lat)  and pd.notna(c_lon)  else np.nan\n",
    "\n",
    "            assigned.append({\n",
    "                \"Plan_Fecha\": day_date.date(),\n",
    "                \"Semana_ISO\": day_date.isocalendar()[1],\n",
    "                \"ZONA\": r[\"ZONA\"],\n",
    "                \"BATERIA\": r[\"BATERIA\"],\n",
    "                \"POZO\": pozo,\n",
    "                \"r_m3_d\": float(r.get(\"__v\", r.get(\"r_m3_d\", np.nan))),\n",
    "                \"ultima_medicion\": r.get(\"ultima_medicion\", pd.NaT),\n",
    "                \"Seed_POZO\": seed_pozo,\n",
    "                \"Dist_km_semilla\": None if pd.isna(d_seed) else round(float(d_seed), 3),\n",
    "                \"Dist_km_centroid\": None if pd.isna(d_cent) else round(float(d_cent), 3),\n",
    "            })\n",
    "            used_now.add(pozo)\n",
    "            remaining_cap -= 1\n",
    "\n",
    "            if pd.notna(lat) and pd.notna(lon):\n",
    "                if n_acc == 0:\n",
    "                    c_lat_acc, c_lon_acc, n_acc = float(lat), float(lon), 1\n",
    "                else:\n",
    "                    c_lat_acc = (c_lat_acc*n_acc + float(lat)) / (n_acc + 1)\n",
    "                    c_lon_acc = (c_lon_acc*n_acc + float(lon)) / (n_acc + 1)\n",
    "                    n_acc += 1\n",
    "\n",
    "        return used_now\n",
    "\n",
    "    clusters_hechos = 0\n",
    "\n",
    "    # PRIMER CLÚSTER por mejor volumen\n",
    "    while (remaining_cap > 0) and (not pool.empty):\n",
    "        cand_pool = pool[pool[\"has_coords\"]].copy()\n",
    "        best_total = None\n",
    "        best_seed_idx = None\n",
    "        best_cluster_rows = None\n",
    "\n",
    "        if not cand_pool.empty:\n",
    "            cand_seeds = cand_pool.sort_values([\"__v\",\"is_overdue\",\"due_date\"],\n",
    "                                               ascending=[False, False, True]).head(max(1, TOP_N))\n",
    "            for seed_idx, seed_row in cand_seeds.iterrows():\n",
    "                seed_lat = seed_row.get(\"LAT\", np.nan)\n",
    "                seed_lon = seed_row.get(\"LON\", np.nan)\n",
    "                if pd.isna(seed_lat) or pd.isna(seed_lon):\n",
    "                    continue\n",
    "\n",
    "                neigh = _bb_filter(pool.drop(index=seed_idx, errors=\"ignore\"), seed_lat, seed_lon, radius_km)\n",
    "                if not neigh.empty:\n",
    "                    neigh = neigh.copy()\n",
    "                    neigh[\"__dist_seed\"] = neigh.apply(\n",
    "                        lambda r: haversine_km(seed_lat, seed_lon, r[\"LAT\"], r[\"LON\"]), axis=1\n",
    "                    )\n",
    "                    neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "                    neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "                max_neighbors_by_cluster = max(0, cluster_cap - 1)\n",
    "                max_neighbors_by_day     = max(0, remaining_cap - 1)\n",
    "                take_n = min(max_neighbors_by_cluster, max_neighbors_by_day)\n",
    "\n",
    "                if take_n > 0 and not neigh.empty:\n",
    "                    neigh_take = neigh.head(take_n)\n",
    "                    cluster_rows = [seed_row] + [nr for _, nr in neigh_take.iterrows()]\n",
    "                else:\n",
    "                    cluster_rows = [seed_row]\n",
    "\n",
    "                total_est = 0.0\n",
    "                for r in cluster_rows:\n",
    "                    rr = r.get(\"__v\", r.get(\"r_m3_d\", np.nan))\n",
    "                    total_est += _v_est_for_day({\"r_m3_d\": rr,\n",
    "                                                 \"ultima_medicion\": r.get(\"ultima_medicion\", pd.NaT)}, day_date)\n",
    "\n",
    "                if (best_total is None) or (total_est > best_total):\n",
    "                    best_total = total_est\n",
    "                    best_seed_idx = seed_idx\n",
    "                    best_cluster_rows = cluster_rows\n",
    "\n",
    "        else:\n",
    "            # fallback si nadie tiene coords\n",
    "            seed_row = pool.iloc[0]\n",
    "            seed_pozo = seed_row[\"POZO\"]\n",
    "            seed_lat  = seed_row.get(\"LAT\", np.nan)\n",
    "            seed_lon  = seed_row.get(\"LON\", np.nan)\n",
    "            best_cluster_rows = [seed_row]\n",
    "\n",
    "        # Centroide del clúster\n",
    "        coords_cluster = [(r.get(\"LAT\", np.nan), r.get(\"LON\", np.nan))\n",
    "                          for r in best_cluster_rows\n",
    "                          if pd.notna(r.get(\"LAT\", np.nan)) and pd.notna(r.get(\"LON\", np.nan))]\n",
    "        if coords_cluster:\n",
    "            c_lat = float(np.mean([x for x,_ in coords_cluster]))\n",
    "            c_lon = float(np.mean([y for _,y in coords_cluster]))\n",
    "        else:\n",
    "            c_lat, c_lon = (np.nan, np.nan)\n",
    "\n",
    "        used_now = _append_cluster(best_cluster_rows, best_cluster_rows[0][\"POZO\"],\n",
    "                                   best_cluster_rows[0].get(\"LAT\", np.nan),\n",
    "                                   best_cluster_rows[0].get(\"LON\", np.nan),\n",
    "                                   c_lat, c_lon)\n",
    "\n",
    "        if used_now:\n",
    "            clusters_hechos += 1\n",
    "            used_set.update(used_now)\n",
    "            pool = pool[~pool[\"POZO\"].isin(used_now)].copy()\n",
    "        else:\n",
    "            pool = pool.iloc[1:].copy()\n",
    "\n",
    "        # corte si no queremos backfill\n",
    "        if not backfill_nearest or remaining_cap <= 0 or (clusters_max and clusters_hechos >= int(clusters_max)):\n",
    "            break\n",
    "\n",
    "        # Backfill por centroide acumulado (umbral)\n",
    "        while (remaining_cap > 0) and (not pool.empty) and (not (clusters_max and clusters_hechos >= int(clusters_max))):\n",
    "            # no implementamos aquí para simplificar la monocelda\n",
    "            break\n",
    "\n",
    "    return assigned\n",
    "\n",
    "def assign_week_round_robin_by_zone(cand_all, team_ids, params, week_start, week_end, radius_km):\n",
    "    \"\"\"\n",
    "    Reparte equitativamente por día entre los equipos que comparten la misma ZONA.\n",
    "    cand_all: DF con columnas ['POZO','ZONA','BATERIA','due_date','is_overdue','__v','LAT','LON','has_coords','r_m3_d','ultima_medicion']\n",
    "    \"\"\"\n",
    "    dias   = int(params[\"dias_por_semana\"])\n",
    "    cap_pz = int(params[\"max_pozos_dia_equipo\"])\n",
    "    cap_cluster = int(params.get(\"max_pozos_por_cluster\", 4))\n",
    "\n",
    "    used_glob = set()\n",
    "    rows = []\n",
    "\n",
    "    for d in range(dias):\n",
    "        day_date = pd.Timestamp(week_start) + pd.Timedelta(days=d)\n",
    "\n",
    "        pool_day = cand_all[~cand_all[\"POZO\"].isin(used_glob)].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "        in_window = (pd.to_datetime(pool_day[\"due_date\"]) <= pd.Timestamp(week_end)) | pool_day[\"is_overdue\"]\n",
    "        pool_day = pool_day[in_window].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "\n",
    "        for eq in sorted(team_ids):\n",
    "            avail = pool_day[~pool_day[\"POZO\"].isin(used_glob)].copy()\n",
    "            if avail.empty:\n",
    "                continue\n",
    "\n",
    "            assigned_today = _fill_day_star_clusters(\n",
    "                day_date, avail, cap_pz, radius_km, used_glob,\n",
    "                cluster_cap=cap_cluster, params=params,\n",
    "                clusters_max=params.get(\"clusters_por_dia_max\"),\n",
    "                backfill_nearest=bool(params.get(\"backfill_nearest_cluster\", True)),\n",
    "                umbral_km_backfill=float(params.get(\"umbral_km_backfill\", 5.0))\n",
    "            )\n",
    "\n",
    "            for ord_idx, a in enumerate(assigned_today, start=1):\n",
    "                try:\n",
    "                    v_est = _v_est_for_day({\"r_m3_d\": a.get(\"r_m3_d\", np.nan),\n",
    "                                            \"ultima_medicion\": a.get(\"ultima_medicion\", pd.NaT)}, day_date)\n",
    "                except Exception:\n",
    "                    v_est = 0.0\n",
    "\n",
    "                a.update({\n",
    "                    \"Equipo\": int(eq),\n",
    "                    \"Dia_Idx\": d+1,\n",
    "                    \"Orden\": ord_idx,\n",
    "                    \"Vol_Estimado_m3\": round(float(v_est), 2)\n",
    "                })\n",
    "                rows.append(a)\n",
    "\n",
    "    cols = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "            \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "            \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\"]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "def ensure_annual_coverage_zone_locked(all_pozos_df, plan, params, start_date, equipo_to_zona,\n",
    "                                       allowed_bats_by_zone_norm=None, r_by_pozo=None):\n",
    "    cap_pz = params[\"max_pozos_dia_equipo\"]\n",
    "\n",
    "    keys = []\n",
    "    for w in range(params[\"semanas_plan\"]):\n",
    "        w_start = start_date + timedelta(weeks=w)\n",
    "        for d in range(params[\"dias_por_semana\"]):\n",
    "            f = w_start + timedelta(days=d)\n",
    "            for e in equipo_to_zona.keys():\n",
    "                keys.append((e, f))\n",
    "\n",
    "    if not plan.empty:\n",
    "        plan[\"__key\"] = plan[\"Equipo\"].astype(int).astype(str) + \"|\" + plan[\"Plan_Fecha\"].astype(str)\n",
    "        used_counts = plan.groupby(\"__key\")[\"POZO\"].count().to_dict()\n",
    "    else:\n",
    "        used_counts = {}\n",
    "\n",
    "    planned = set(plan[\"POZO\"].unique()) if not plan.empty else set()\n",
    "    missing_df = all_pozos_df[~all_pozos_df[\"POZO\"].isin(planned)].copy()\n",
    "    missing_df = missing_df[missing_df[\"BATERIA\"].notna() & (missing_df[\"BATERIA\"].astype(str).str.strip()!=\"\")].copy()\n",
    "\n",
    "    add = []\n",
    "    for _, row in missing_df.iterrows():\n",
    "        pz = row[\"POZO\"]; z = row[\"ZONA\"]\n",
    "        bat = row.get(\"BATERIA\", \"\")\n",
    "\n",
    "        if not isinstance(bat, str) or bat.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            zn = _norm(z)\n",
    "            bats_allowed = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats_allowed is not None:\n",
    "                if _norm(bat) not in bats_allowed:\n",
    "                    continue\n",
    "\n",
    "        if r_by_pozo is not None:\n",
    "            r_val = float(r_by_pozo.get(pz, np.nan))\n",
    "            if not (r_val > RM3D_MIN):\n",
    "                continue\n",
    "\n",
    "        target_teams = [e for e, zona in equipo_to_zona.items() if zona == z]\n",
    "        if not target_teams:\n",
    "            continue\n",
    "        placed = False\n",
    "        for e in target_teams:\n",
    "            for (ee, f) in keys:\n",
    "                if ee != e:\n",
    "                    continue\n",
    "                key = f\"{e}|{f}\"\n",
    "                cnt = used_counts.get(key, 0)\n",
    "                if cnt < cap_pz:\n",
    "                    add.append({\n",
    "                        \"Plan_Fecha\": f,\n",
    "                        \"Semana_ISO\": f.isocalendar()[1],\n",
    "                        \"Equipo\": int(e),\n",
    "                        \"Dia_Idx\": f.weekday()+1,\n",
    "                        \"Orden\": cnt+1,\n",
    "                        \"ZONA\": z,\n",
    "                        \"BATERIA\": bat,\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": np.nan,\n",
    "                        \"Vol_Estimado_m3\": 0.0,\n",
    "                        \"Seed_POZO\": \"\",\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": None,\n",
    "                        \"ultima_medicion\": pd.NaT,\n",
    "                    })\n",
    "                    used_counts[key] = cnt+1\n",
    "                    placed = True\n",
    "                    break\n",
    "            if placed:\n",
    "                break\n",
    "\n",
    "    if add:\n",
    "        plan = pd.concat([plan, pd.DataFrame(add)], ignore_index=True)                 .sort_values([\"Plan_Fecha\",\"Equipo\",\"Orden\"])\n",
    "    return plan\n",
    "\n",
    "def build_alertas_abm(freq_df: pd.DataFrame, norm_table: pd.DataFrame, dict_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = freq_df[[\"POZO\",\"ZONA\",\"BATERIA\",\"ultima_medicion\",\"ultima_exitosa\"]].copy()\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"estado\",\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    base = base.merge(meta_first[[\"estado\",\"met_prod\"]], left_on=\"POZO\", right_index=True, how=\"left\")\n",
    "\n",
    "    out = base.copy()\n",
    "    for c in [\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "        out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "    out = out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ============================================\n",
    "# HARNES PARA JUPYTER\n",
    "# ============================================\n",
    "def run_pipeline_jupyter(\n",
    "    input_file,\n",
    "    nombres_pozo_file,\n",
    "    coords_file,\n",
    "    *,\n",
    "    semanas_plan=2,\n",
    "    equipos_activos=2,\n",
    "    dias_por_semana=5,\n",
    "    max_pozos_dia_equipo=10,\n",
    "    K_max_pozos_por_cluster=5,\n",
    "    clusters_por_dia_max=None,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,\n",
    "    baterias_por_zona=None,      # {\"las heras cg - canadon escondida\": {\"swabing ce\",\"ce 04\"}}\n",
    "    pozos_excluir=None,\n",
    "    escribir_excel=False\n",
    "):\n",
    "    global INPUT_FILE, NOMBRES_POZO_FILE, COORDS_FILE, RADIUS_KM, RM3D_MIN, DEFAULTS\n",
    "    INPUT_FILE       = input_file\n",
    "    NOMBRES_POZO_FILE= nombres_pozo_file\n",
    "    COORDS_FILE      = coords_file\n",
    "    RADIUS_KM        = float(radius_km)\n",
    "    RM3D_MIN         = float(rm3d_min)\n",
    "\n",
    "    DEFAULTS = DEFAULTS.copy()\n",
    "    DEFAULTS.update({\n",
    "        \"equipos_activos\": int(equipos_activos),\n",
    "        \"dias_por_semana\": int(dias_por_semana),\n",
    "        \"semanas_plan\": int(semanas_plan),\n",
    "        \"max_pozos_dia_equipo\": int(max_pozos_dia_equipo),\n",
    "        \"max_pozos_por_cluster\": int(K_max_pozos_por_cluster),\n",
    "        \"clusters_por_dia_max\": clusters_por_dia_max,\n",
    "        \"backfill_nearest_cluster\": bool(backfill_nearest),\n",
    "        \"umbral_km_backfill\": float(umbral_km_backfill),\n",
    "    })\n",
    "\n",
    "    # 1) Lee historial (Excel del usuario)\n",
    "    df = read_historial(INPUT_FILE, SHEET_HIST)\n",
    "\n",
    "    # 2) Normalización por diccionario\n",
    "    key2off, dict_df = load_pozo_dictionary(NOMBRES_POZO_FILE)\n",
    "    df_norm, alert_table, norm_table = apply_pozo_normalization(df, key2off, dict_df)\n",
    "\n",
    "    # 3) Filtra inválidos\n",
    "    df = df_norm[df_norm[\"VALIDO_POZO\"] == True].copy()\n",
    "\n",
    "    # 4) Filtro por ZONA (si se pide explícito)\n",
    "    if zonas_incluir:\n",
    "        zonas_incluir = set(zonas_incluir)\n",
    "        znorm = {_norm(z) for z in zonas_incluir}\n",
    "        df = df[df[\"__ZONA_NORM\"].isin(znorm)].copy()\n",
    "        zonas_labels = zonas_incluir\n",
    "        zonas_norm   = znorm\n",
    "    else:\n",
    "        zonas_labels, zonas_norm = set(df[\"ZONA\"].dropna().astype(str)), set(df[\"__ZONA_NORM\"].dropna().astype(str))\n",
    "\n",
    "    # 5) Sub-filtro de baterías (si lo pasaste por parámetro)\n",
    "    if baterias_por_zona:\n",
    "        allowed_bats_by_zone_norm = {zn: set(baterias_por_zona[zn]) if baterias_por_zona[zn] is not None else None\n",
    "                                     for zn in baterias_por_zona}\n",
    "    else:\n",
    "        allowed_bats_by_zone_norm = {zn: None for zn in zonas_norm}\n",
    "\n",
    "    # 6) Exclusiones (si te pasan un set)\n",
    "    excl_total = set(pozos_excluir or [])\n",
    "\n",
    "    # 7) Frecuencias\n",
    "    params = DEFAULTS.copy()\n",
    "    freq = compute_frecuencias(df, params)\n",
    "\n",
    "    # Comentarios desde OBS cuando ultima_medicion != ultima_exitosa\n",
    "    df_obs = df[[\"POZO\", \"FECHA\", \"OBS_POZO\"]].copy() if \"OBS_POZO\" in df.columns else pd.DataFrame(columns=[\"POZO\",\"FECHA\",\"OBS_POZO\"])\n",
    "    df_obs[\"FECHA_DATE\"] = pd.to_datetime(df_obs[\"FECHA\"], errors=\"coerce\").dt.date\n",
    "    df_obs = (df_obs.dropna(subset=[\"FECHA_DATE\"])\n",
    "                    .sort_values([\"POZO\",\"FECHA_DATE\"])\n",
    "                    .drop_duplicates(subset=[\"POZO\",\"FECHA_DATE\"], keep=\"last\"))\n",
    "    obs_map = {(r.POZO, r.FECHA_DATE): (str(r.OBS_POZO).strip() if pd.notna(r.OBS_POZO) else \"\")\n",
    "               for r in df_obs.itertuples(index=False)}\n",
    "    freq[\"__UMED_DATE\"] = pd.to_datetime(freq[\"ultima_medicion\"], errors=\"coerce\").dt.date\n",
    "    freq[\"__UEXI_DATE\"] = pd.to_datetime(freq[\"ultima_exitosa\"], errors=\"coerce\").dt.date\n",
    "    freq[\"comentario\"] = [obs_map.get((pz, fmed), \"\") for pz, fmed in zip(freq[\"POZO\"], freq[\"__UMED_DATE\"])]\n",
    "    mask_both_valid = freq[\"__UMED_DATE\"].notna() & freq[\"__UEXI_DATE\"].notna()\n",
    "    mask_diff = mask_both_valid & (freq[\"__UMED_DATE\"] != freq[\"__UEXI_DATE\"])\n",
    "    freq.loc[~mask_diff, \"comentario\"] = \"\"\n",
    "    freq.drop(columns=[\"__UMED_DATE\",\"__UEXI_DATE\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # 8) Coordenadas\n",
    "    coords_df = read_coords(COORDS_FILE)\n",
    "\n",
    "    # 9) Mapas auxiliares\n",
    "    delta_by_pozo = freq.set_index(\"POZO\")[\"delta_star_dias\"].to_dict()\n",
    "    r_by_pozo     = freq.set_index(\"POZO\")[\"r_m3_d\"].to_dict()\n",
    "\n",
    "    # 10) Semanas a planificar\n",
    "    start = next_monday(date.today())\n",
    "    weeks = [(start + timedelta(weeks=i), start + timedelta(weeks=i, days=6)) for i in range(params[\"semanas_plan\"])]\n",
    "\n",
    "    # 11) Equipos -> ZONA (fijo)\n",
    "    zonas_list = sorted(set(zonas_labels))\n",
    "    equipo_to_zona = {}\n",
    "    for i in range(1, params[\"equipos_activos\"]+1):\n",
    "        zona_asignada = zonas_list[min(i-1, len(zonas_list)-1)]\n",
    "        equipo_to_zona[i] = zona_asignada\n",
    "\n",
    "    # 12) Plan semanal por ZONA (round-robin entre equipos)\n",
    "    plan_all = []\n",
    "    next_due = {row.POZO: row.proxima_visita_base for row in freq.itertuples()}\n",
    "    zone_to_teams = {}\n",
    "    for eq, zona_label in equipo_to_zona.items():\n",
    "        zone_to_teams.setdefault(zona_label, []).append(eq)\n",
    "\n",
    "    for (w_start, w_end) in weeks:\n",
    "        for zona_label, team_list in zone_to_teams.items():\n",
    "            zona_norm_label = _norm(zona_label)\n",
    "            cand_all = build_candidates_with_coords(\n",
    "                freq=freq,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                excl_pozos=excl_total,\n",
    "                zonas_norm_incluidas={zona_norm_label},\n",
    "                coords_df=coords_df,\n",
    "                allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "                next_due_map=next_due\n",
    "            )\n",
    "            if cand_all.empty:\n",
    "                continue\n",
    "\n",
    "            cand_zone = cand_all[[\n",
    "                \"POZO\",\"ZONA\",\"BATERIA\",\"due_date\",\"is_overdue\",\"__v\",\n",
    "                \"LAT\",\"LON\",\"has_coords\",\"r_m3_d\",\"ultima_medicion\"\n",
    "            ]].copy()\n",
    "\n",
    "            plan_week_zone = assign_week_round_robin_by_zone(\n",
    "                cand_all=cand_zone,\n",
    "                team_ids=sorted(team_list),\n",
    "                params=params,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                radius_km=RADIUS_KM\n",
    "            )\n",
    "\n",
    "            if not plan_week_zone.empty:\n",
    "                plan_all.append(plan_week_zone)\n",
    "\n",
    "                for pz, fcal in plan_week_zone[[\"POZO\",\"Plan_Fecha\"]].drop_duplicates().itertuples(index=False):\n",
    "                    dd = int(delta_by_pozo.get(pz, params[\"min_dias_freq\"]))\n",
    "                    next_due[pz] = pd.Timestamp(fcal) + pd.Timedelta(days=dd)\n",
    "\n",
    "    plan = (pd.concat(plan_all, ignore_index=True)\n",
    "            if plan_all else\n",
    "            pd.DataFrame(columns=[\n",
    "                \"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\"ZONA\",\"BATERIA\",\n",
    "                \"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\"\n",
    "            ]))\n",
    "\n",
    "    # 13) Cobertura anual reforzada (opcional)\n",
    "    if not freq.empty:\n",
    "        eligible_mask = (freq[\"ZONA\"].isin(zonas_labels)) & (freq[\"r_m3_d\"].fillna(0) > RM3D_MIN)\n",
    "        if \"comentario\" in freq.columns:\n",
    "            eligible_mask &= (freq[\"comentario\"].astype(str).fillna(\"\").str.strip() == \"\")\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            for zn, bats in allowed_bats_by_zone_norm.items():\n",
    "                if bats is not None:\n",
    "                    eligible_mask &= (~(freq[\"ZONA_NORM\"] == zn)) | (freq[\"BATERIA_NORM\"].isin(bats))\n",
    "\n",
    "        all_pozos_in_zonas = freq.loc[eligible_mask, [\"POZO\",\"ZONA\",\"BATERIA\"]].drop_duplicates().copy()\n",
    "        all_pozos_in_zonas = all_pozos_in_zonas[\n",
    "            all_pozos_in_zonas[\"BATERIA\"].notna() & (all_pozos_in_zonas[\"BATERIA\"].astype(str).str.strip() != \"\")\n",
    "        ].copy()\n",
    "\n",
    "        plan = ensure_annual_coverage_zone_locked(\n",
    "            all_pozos_in_zonas,\n",
    "            plan,\n",
    "            params,\n",
    "            start,\n",
    "            equipo_to_zona,\n",
    "            allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "            r_by_pozo=r_by_pozo\n",
    "        )\n",
    "\n",
    "    # 14) Export opcional\n",
    "    # 14) Export opcional\n",
    "    out_xlsx = None\n",
    "    if escribir_excel:\n",
    "        out_xlsx = unique_output_path(INPUT_FILE)\n",
    "        coords_all = read_coords(COORDS_FILE)\n",
    "        with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "            # Frecuencias\n",
    "            freq_out = freq.copy()\n",
    "            for c in [\"proxima_visita_base\",\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "                freq_out[c] = pd.to_datetime(freq_out[c], errors=\"coerce\").dt.date\n",
    "            freq_out = freq_out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"])\n",
    "            cols_pref = [\"POZO\",\"ZONA\",\"BATERIA\",\"ZONA_NORM\",\"BATERIA_NORM\",\"r_m3_d\",\n",
    "                         \"ultima_medicion\",\"ultima_exitosa\",\"delta_star_dias\",\"comentario\",\n",
    "                         \"proxima_visita_base\",\"ceros_consec\",\"alerta\"]\n",
    "            cols_final = [c for c in cols_pref if c in freq_out.columns] + \\\n",
    "                         [c for c in freq_out.columns if c not in cols_pref]\n",
    "            freq_out = freq_out[cols_final]\n",
    "            freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
    "\n",
    "            # Plan por equipo + Km_al_siguiente\n",
    "            cols_plan = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "                         \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "                         \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\"]\n",
    "            for eq in range(1, params[\"equipos_activos\"]+1):\n",
    "                pe = plan.loc[plan[\"Equipo\"]==eq].copy()\n",
    "                if pe.empty:\n",
    "                    pe = pd.DataFrame(columns=cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"])\n",
    "                else:\n",
    "                    pe = pe.sort_values([\"Plan_Fecha\",\"Dia_Idx\",\"Orden\",\"POZO\"]).copy()\n",
    "                    pe = pe.merge(coords_all, how=\"left\", on=\"POZO\")\n",
    "                    pe[\"LAT_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LAT\"].shift(-1)\n",
    "                    pe[\"LON_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LON\"].shift(-1)\n",
    "                    def _leg_km(row):\n",
    "                        if (pd.isna(row.get(\"LAT\")) or pd.isna(row.get(\"LON\")) or\n",
    "                            pd.isna(row.get(\"LAT_next\")) or pd.isna(row.get(\"LON_next\"))):\n",
    "                            return None\n",
    "                        return round(float(haversine_km(row[\"LAT\"], row[\"LON\"],\n",
    "                                                        row[\"LAT_next\"], row[\"LON_next\"])), 3)\n",
    "                    pe[\"Km_al_siguiente\"] = pe.apply(_leg_km, axis=1)\n",
    "                    pe.drop(columns=[\"LAT\",\"LON\",\"LAT_next\",\"LON_next\"], inplace=True, errors=\"ignore\")\n",
    "                    pe[\"Ejecutado\"] = \"\"\n",
    "                    for c in cols_plan:\n",
    "                        if c not in pe.columns: pe[c] = \"\"\n",
    "                    pe = pe[cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"]]\n",
    "                pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
    "\n",
    "            # Auxiliares\n",
    "            pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n",
    "\n",
    "    return plan, freq, out_xlsx\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# RUNNER (EDITÁ TUS RUTAS Y PARÁMETROS ACÁ)\n",
    "# ============================================\n",
    "\n",
    "INPUT_FILE = r\"C:\\Users\\ry16123\\Downloads\\Ultimo (ORIGINAL) TABLERO PRODUCCIÓN FLUG S.A 2025 (1).xlsx\"\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "plan, freq, out_xlsx = run_pipeline_jupyter(\n",
    "    input_file=INPUT_FILE,\n",
    "    nombres_pozo_file=NOMBRES_POZO_FILE,\n",
    "    coords_file=COORDS_FILE,\n",
    "    semanas_plan=2,                 # probá corto para iterar rápido\n",
    "    equipos_activos=3,              # cantidad de equipos\n",
    "    dias_por_semana=5,              # 5 ó 6\n",
    "    max_pozos_dia_equipo=5,\n",
    "    K_max_pozos_por_cluster=5,      # tamaño máximo de clúster\n",
    "    clusters_por_dia_max=1,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,             # o lista como [\"Las Heras CG - Canadon Escondida\"]\n",
    "    baterias_por_zona=None,         # dict normalizado (keys en _norm) o None\n",
    "    pozos_excluir=set(),            # ej.: {\"BB-100\"}\n",
    "    escribir_excel=True            # poné True si querés exportar el Excel\n",
    ")\n",
    "\n",
    "# Mostrar un vistazo rápido\n",
    "display(freq.head(10))\n",
    "display(plan.head(30))\n",
    "print(\"Excel generado:\", out_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de308d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\CursoML-UDEMY\\env\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\1616445945.py:426: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  g[col] = g[col].replace({None: np.nan})\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\1616445945.py:1288: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\1616445945.py:1316: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\1616445945.py:1316: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\1616445945.py:1316: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\1616445945.py:1319: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POZO</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>ZONA_NORM</th>\n",
       "      <th>BATERIA_NORM</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ultima_exitosa</th>\n",
       "      <th>delta_star_dias</th>\n",
       "      <th>proxima_visita_base</th>\n",
       "      <th>ceros_consec</th>\n",
       "      <th>alerta</th>\n",
       "      <th>comentario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BB-10</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BB-100</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BB-101</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB.a-104</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB-111</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB-133</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BB-170</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BB-21</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BB497</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BB-50</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       POZO                              ZONA     BATERIA  \\\n",
       "0     BB-10  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "1    BB-100  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "2    BB-101  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "3  BB.a-104  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "4    BB-111  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "5    BB-133  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "6    BB-170  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "7     BB-21  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "8     BB497                                           NaN   \n",
       "9     BB-50  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "\n",
       "                        ZONA_NORM BATERIA_NORM    r_m3_d ultima_medicion  \\\n",
       "0  las heras cg canadon escondida   swabing ce  0.015385      2025-07-16   \n",
       "1  las heras cg canadon escondida   swabing ce  0.142857      2023-08-04   \n",
       "2  las heras cg canadon escondida   swabing ce  0.035714      2025-08-25   \n",
       "3  las heras cg canadon escondida   swabing ce  0.285714      2025-01-24   \n",
       "4  las heras cg canadon escondida   swabing ce  0.428571      2025-07-01   \n",
       "5  las heras cg canadon escondida   swabing ce  0.037037      2025-02-19   \n",
       "6  las heras cg canadon escondida   swabing ce  0.285714      2024-07-24   \n",
       "7  las heras cg canadon escondida   swabing ce  0.015564      2025-05-12   \n",
       "8                                               0.571429      2025-01-08   \n",
       "9  las heras cg canadon escondida   swabing ce  0.081633      2023-03-10   \n",
       "\n",
       "  ultima_exitosa  delta_star_dias proxima_visita_base  ceros_consec alerta  \\\n",
       "0     2025-07-16               56          2025-09-10             0          \n",
       "1     2023-08-04               14          2023-08-18             0          \n",
       "2     2025-08-25               56          2025-10-20             0          \n",
       "3     2025-01-24                7          2025-01-31             0          \n",
       "4     2025-07-01                7          2025-07-08             0          \n",
       "5     2025-02-19               56          2025-04-16             0          \n",
       "6     2024-07-24                7          2024-07-31             0          \n",
       "7     2025-05-12               56          2025-07-07             0          \n",
       "8     2025-01-08                7          2025-01-15             0          \n",
       "9     2023-03-10               28          2023-04-07             0          \n",
       "\n",
       "  comentario  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             \n",
       "5             \n",
       "6             \n",
       "7             \n",
       "8             \n",
       "9             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_Fecha</th>\n",
       "      <th>Semana_ISO</th>\n",
       "      <th>Equipo</th>\n",
       "      <th>Dia_Idx</th>\n",
       "      <th>Orden</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>POZO</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>Vol_Estimado_m3</th>\n",
       "      <th>Seed_POZO</th>\n",
       "      <th>Dist_km_semilla</th>\n",
       "      <th>Dist_km_centroid</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>Centroide_LAT</th>\n",
       "      <th>Centroide_LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-1234</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>72.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.290</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 20</td>\n",
       "      <td>CnE-1224(d)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>37.14</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.468</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-473</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>12.75</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.172</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-868</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>13.36</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.583</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-849</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>14.80</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.331</td>\n",
       "      <td>2025-07-17</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-808</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>3.19</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.056</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-226</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>5.71</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.278</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-199</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.414</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-534</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.504</td>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-660</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.80</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 10</td>\n",
       "      <td>CnE.a-93</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>59.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.903</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 11</td>\n",
       "      <td>CnE-379</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>29.87</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-543</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>10.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.036</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4.80</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-885</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>35.31</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.976</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 03</td>\n",
       "      <td>CnE-124</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.57</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.441</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>3.16</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.755</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-210</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>10.07</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.450</td>\n",
       "      <td>2025-07-24</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 04</td>\n",
       "      <td>CnE-219</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>187.25</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.903</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 01</td>\n",
       "      <td>CnE-731</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.57</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-694</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.789</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-521</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>3.71</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.969</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>30.25</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.321</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-728</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>13.91</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.531</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-586</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>7.07</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 12</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>49.45</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.547</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-422</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>10.92</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.821</td>\n",
       "      <td>2025-07-22</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-504</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>33.14</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.307</td>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-1155</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>10.71</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.366</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-732</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>4.73</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plan_Fecha  Semana_ISO  Equipo   Dia_Idx  Orden  \\\n",
       "0   2025-09-29          40       2  2.171666      1   \n",
       "1   2025-09-29          40       2  2.171666      2   \n",
       "2   2025-09-29          40       2  2.171666      3   \n",
       "3   2025-09-29          40       2  2.171666      4   \n",
       "4   2025-09-29          40       2  2.171666      5   \n",
       "5   2025-09-29          40       3  2.055880      1   \n",
       "6   2025-09-29          40       3  2.055880      2   \n",
       "7   2025-09-29          40       3  2.055880      3   \n",
       "8   2025-09-29          40       3  2.055880      4   \n",
       "9   2025-09-29          40       3  2.055880      5   \n",
       "10  2025-09-30          40       2  2.250334      1   \n",
       "11  2025-09-30          40       2  2.250334      2   \n",
       "12  2025-09-30          40       2  2.250334      3   \n",
       "13  2025-09-30          40       2  2.250334      4   \n",
       "14  2025-09-30          40       2  2.250334      5   \n",
       "15  2025-09-30          40       3  3.274812      1   \n",
       "16  2025-09-30          40       3  3.274812      2   \n",
       "17  2025-09-30          40       3  3.274812      3   \n",
       "18  2025-09-30          40       3  3.274812      4   \n",
       "19  2025-09-30          40       3  3.274812      5   \n",
       "20  2025-10-01          40       2  1.788638      1   \n",
       "21  2025-10-01          40       2  1.788638      2   \n",
       "22  2025-10-01          40       2  1.788638      3   \n",
       "23  2025-10-01          40       2  1.788638      4   \n",
       "24  2025-10-01          40       2  1.788638      5   \n",
       "25  2025-10-01          40       3  3.366298      1   \n",
       "26  2025-10-01          40       3  3.366298      2   \n",
       "27  2025-10-01          40       3  3.366298      3   \n",
       "28  2025-10-01          40       3  3.366298      4   \n",
       "29  2025-10-01          40       3  3.366298      5   \n",
       "\n",
       "                                ZONA     BATERIA         POZO    r_m3_d  \\\n",
       "0   Las Heras CG - Canadon Escondida  Swabing CE     CnE-1234  0.285714   \n",
       "1   Las Heras CG - Canadon Escondida       CE 20  CnE-1224(d)  0.285714   \n",
       "2   Las Heras CG - Canadon Escondida  Swabing CE      CnE-473  0.187500   \n",
       "3   Las Heras CG - Canadon Escondida  Swabing CE      CnE-868  0.272727   \n",
       "4   Las Heras CG - Canadon Escondida  Swabing CE      CnE-849  0.200000   \n",
       "5   Las Heras CG - Canadon Escondida  Swabing CE      CnE-808  0.187500   \n",
       "6   Las Heras CG - Canadon Escondida  Swabing CE    CnE.a-226  0.238095   \n",
       "7   Las Heras CG - Canadon Escondida  Swabing CE      CnE-199  0.285714   \n",
       "8   Las Heras CG - Canadon Escondida  Swabing CE      CnE-534  0.214286   \n",
       "9   Las Heras CG - Canadon Escondida  Swabing CE      CnE-660  0.200000   \n",
       "10  Las Heras CG - Canadon Escondida       CE 10     CnE.a-93  0.142857   \n",
       "11  Las Heras CG - Canadon Escondida       CE 11      CnE-379  0.133333   \n",
       "12  Las Heras CG - Canadon Escondida  Swabing CE      CnE-543  0.277778   \n",
       "13  Las Heras CG - Canadon Escondida  Swabing CE      CnE-736  0.266667   \n",
       "14  Las Heras CG - Canadon Escondida  Swabing CE      CnE-885  0.230769   \n",
       "15  Las Heras CG - Canadon Escondida       CE 03      CnE-124  0.142857   \n",
       "16  Las Heras CG - Canadon Escondida  Swabing CE      CnE-221  0.157895   \n",
       "17  Las Heras CG - Canadon Escondida  Swabing CE      CnE-210  0.148148   \n",
       "18  Las Heras CG - Canadon Escondida       CE 04      CnE-219  0.291667   \n",
       "19  Las Heras CG - Canadon Escondida       CE 01      CnE-731  0.142857   \n",
       "20  Las Heras CG - Canadon Escondida       CE 19      CnE-694  0.142857   \n",
       "21  Las Heras CG - Canadon Escondida  Swabing CE      CnE-521  0.161290   \n",
       "22  Las Heras CG - Canadon Escondida       CE 19      CnE-696  0.250000   \n",
       "23  Las Heras CG - Canadon Escondida  Swabing CE      CnE-728  0.156250   \n",
       "24  Las Heras CG - Canadon Escondida  Swabing CE    CnE.a-586  0.172414   \n",
       "25  Las Heras CG - Canadon Escondida       CE 12      CnE-829  0.181818   \n",
       "26  Las Heras CG - Canadon Escondida  Swabing CE      CnE-422  0.153846   \n",
       "27  Las Heras CG - Canadon Escondida  Swabing CE      CnE-504  0.142857   \n",
       "28  Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-1155  0.107143   \n",
       "29  Las Heras CG - Canadon Escondida  Swabing CE      CnE-732  0.181818   \n",
       "\n",
       "    Vol_Estimado_m3 Seed_POZO Dist_km_semilla  Dist_km_centroid  \\\n",
       "0             72.86                      None             0.290   \n",
       "1             37.14                      None             0.468   \n",
       "2             12.75                      None             1.172   \n",
       "3             13.36                      None             1.583   \n",
       "4             14.80                      None             2.331   \n",
       "5              3.19                      None             1.056   \n",
       "6              5.71                      None             1.278   \n",
       "7              4.86                      None             1.414   \n",
       "8              3.86                      None             1.504   \n",
       "9              3.80                      None             2.039   \n",
       "10            59.86                      None             0.903   \n",
       "11            29.87                      None             1.250   \n",
       "12            10.00                      None             2.036   \n",
       "13             4.80                      None             2.275   \n",
       "14            35.31                      None             2.976   \n",
       "15             4.57                      None             0.441   \n",
       "16             3.16                      None             0.755   \n",
       "17            10.07                      None             1.450   \n",
       "18           187.25                      None             1.903   \n",
       "19            34.57                      None             2.275   \n",
       "20            34.00                      None             0.789   \n",
       "21             3.71                      None             0.969   \n",
       "22            30.25                      None             1.321   \n",
       "23            13.91                      None             1.531   \n",
       "24             7.07                      None             2.521   \n",
       "25            49.45                      None             0.547   \n",
       "26            10.92                      None             1.821   \n",
       "27            33.14                      None             2.307   \n",
       "28            10.71                      None             2.366   \n",
       "29             4.73                      None             2.817   \n",
       "\n",
       "   ultima_medicion ClusterID  Centroide_LAT  Centroide_LON  \n",
       "0       2025-01-17    C00002     -46.438652     -68.577977  \n",
       "1       2025-05-22    C00002     -46.438652     -68.577977  \n",
       "2       2025-07-23    C00002     -46.438652     -68.577977  \n",
       "3       2025-08-11    C00002     -46.438652     -68.577977  \n",
       "4       2025-07-17    C00002     -46.438652     -68.577977  \n",
       "5       2025-09-12    C00003     -46.403392     -68.562792  \n",
       "6       2025-09-05    C00003     -46.403392     -68.562792  \n",
       "7       2025-09-12    C00003     -46.403392     -68.562792  \n",
       "8       2025-09-11    C00003     -46.403392     -68.562792  \n",
       "9       2025-09-10    C00003     -46.403392     -68.562792  \n",
       "10      2024-08-07    C00010     -46.467081     -68.524865  \n",
       "11      2025-02-18    C00010     -46.467081     -68.524865  \n",
       "12      2025-08-25    C00010     -46.467081     -68.524865  \n",
       "13      2025-09-12    C00010     -46.467081     -68.524865  \n",
       "14      2025-04-30    C00010     -46.467081     -68.524865  \n",
       "15      2025-08-29    C00009     -46.452249     -68.679064  \n",
       "16      2025-09-10    C00009     -46.452249     -68.679064  \n",
       "17      2025-07-24    C00009     -46.452249     -68.679064  \n",
       "18      2023-12-28    C00009     -46.452249     -68.679064  \n",
       "19      2025-01-31    C00009     -46.452249     -68.679064  \n",
       "20      2025-02-05    C00004     -46.396247     -68.601993  \n",
       "21      2025-09-08    C00004     -46.396247     -68.601993  \n",
       "22      2025-06-02    C00004     -46.396247     -68.601993  \n",
       "23      2025-07-04    C00004     -46.396247     -68.601993  \n",
       "24      2025-08-21    C00004     -46.396247     -68.601993  \n",
       "25      2025-01-02    C00002     -46.437632     -68.552173  \n",
       "26      2025-07-22    C00002     -46.437632     -68.552173  \n",
       "27      2025-02-11    C00002     -46.437632     -68.552173  \n",
       "28      2025-06-23    C00002     -46.437632     -68.552173  \n",
       "29      2025-09-05    C00002     -46.437632     -68.552173  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel generado: C:\\Users\\ry16123\\Downloads\\Ultimo (ORIGINAL) TABLERO PRODUCCIÓN FLUG S.A 2025 (1)_CRONOGRAMA_20250928_(8).xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#RELATIVAMENTE BIEN, NO DISTRIBUYE BIEN POR CANTIDAD DE EQIUPOS - Y CUANDO NO ENCUNETRA LAS COORDENADAS HACE LIO.\n",
    "\n",
    "# ============================================\n",
    "# Monocelda Jupyter: Planificador + Harness + Runner\n",
    "# ============================================\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, unicodedata, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# CONFIG por defecto (se sobreescriben en el runner)\n",
    "# ==========================\n",
    "INPUT_FILE  = r\"DIAGRAMA SW.xlsx\"   # Excel base (NO se modifica)\n",
    "SHEET_HIST  = None                  # None => autodetecta hoja/encabezados\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "# Radio en km para agrupar por cercanía\n",
    "RADIUS_KM = 3.0\n",
    "# Filtro mínimo de potencial\n",
    "RM3D_MIN = 0.1\n",
    "\n",
    "# Umbrales para fuzzy (si se usan)\n",
    "FUZZY_REPLACE_THRESHOLD = 85\n",
    "FUZZY_SUGGEST_THRESHOLD = 75\n",
    "LETTERS_SIMILARITY_MIN  = 80\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"equipos_activos\": 4,                 # 1..4\n",
    "    \"dias_por_semana\": 5,                 # 5 o 6\n",
    "    \"semanas_plan\": 2,                    # para probar rápido en Jupyter\n",
    "    \"k_visitas\": 1,                       # tasas (K=1 por pedido)\n",
    "    \"max_pozos_dia_equipo\": 10,           # cupo por día por equipo\n",
    "    \"max_pozos_por_cluster\": 5,           # tamaño de clúster (K fijo si usás lógica de clústeres fijos)\n",
    "    \"m3_por_visita_objetivo\": 2.0,        # informativo\n",
    "    \"min_dias_freq\": 7,                   # 1 semana\n",
    "    \"max_dias_freq\": 56,                  # 8 semanas\n",
    "    \"dias_asumidos_una_visita\": 7,        # para r si hay 1 sola visita\n",
    "    \"freq_dias_ultimo_cero_valido\": 30,\n",
    "\n",
    "    # Semillas a evaluar (si se usa lógica de semillas)\n",
    "    \"top_semillas_eval\": 30,\n",
    "\n",
    "    # Control de clústeres por día y backfill (si se usa lógica por semilla)\n",
    "    \"clusters_por_dia_max\": None,\n",
    "    \"backfill_nearest_cluster\": True,\n",
    "    \"umbral_km_backfill\": 5.0,\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Utils\n",
    "# ==========================\n",
    "def _norm(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = s.replace(\"³\", \"3\")\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip().replace(\"\\xa0\",\" \")\n",
    "    s = s.replace(\"_\",\" \").replace(\"-\",\" \").replace(\".\",\" \").replace(\"\\n\",\" \")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _pozo_key(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return \"\".join(ch for ch in s if ch.isalnum()).upper()\n",
    "\n",
    "def _canonical_digits(d: str) -> str:\n",
    "    d = (d or \"\").lstrip(\"0\")\n",
    "    return d if d != \"\" else \"0\"\n",
    "\n",
    "def _letters_digits_from_key_both(k: str):\n",
    "    raw_digits = \"\".join(re.findall(r\"\\d+\", k))\n",
    "    digits_canon = _canonical_digits(raw_digits)\n",
    "    letters = re.sub(r\"\\d+\", \"\", k)\n",
    "    return letters, digits_canon, len(raw_digits)\n",
    "\n",
    "def _ratio_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _fuzzy_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.partial_ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _canon_prefix_pozo(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return s\n",
    "    raw = str(s).strip()\n",
    "    raw_up = raw.upper()\n",
    "    if raw_up.startswith(\"CÑE\"):\n",
    "        return \"CNE\" + raw_up[3:]\n",
    "    raw_ascii = unicodedata.normalize(\"NFKD\", raw_up).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    if raw_ascii.startswith(\"CNE\"):\n",
    "        return raw_ascii\n",
    "    if raw_ascii.startswith(\"CN\"):\n",
    "        return \"CNE\" + raw_ascii[2:]\n",
    "    m = re.match(r\"^CE(\\d+)$\", raw_ascii)\n",
    "    if m:\n",
    "        return \"CNE\" + m.group(1)\n",
    "    return raw_ascii\n",
    "\n",
    "def next_monday(d=None):\n",
    "    d = d or date.today()\n",
    "    return d + timedelta(days=(7 - d.weekday()) % 7)  # 0=Lunes\n",
    "\n",
    "def unique_output_path(base_input_path: str) -> str:\n",
    "    folder = os.path.dirname(os.path.abspath(base_input_path))\n",
    "    stem   = os.path.splitext(os.path.basename(base_input_path))[0]\n",
    "    today  = datetime.now().strftime(\"%Y%m%d\")\n",
    "    base   = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}.xlsx\")\n",
    "    if not os.path.exists(base): return base\n",
    "    i = 2\n",
    "    while True:\n",
    "        cand = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}_({i}).xlsx\")\n",
    "        if not os.path.exists(cand): return cand\n",
    "        i += 1\n",
    "\n",
    "EXPECTED_KEYS = {\n",
    "    \"fecha\":       [\"fecha\"],\n",
    "    \"pozo\":        [\"pozo\"],\n",
    "    \"zona\":        [\"zona\"],\n",
    "    \"bateria\":     [\"bateria\", \"batería\"],\n",
    "    \"m3\":          [\"m3 bruta\",\"m3\",\"m3_bruta\",\"m3bruta\",\"m 3 bruta\",\"m 3\",\"m3 bruto\",\"m3 recuperado\",\"m3 recupero\"],\n",
    "    \"carreras\":    [\"n de carreras\",\"n° de carreras\",\"nº de carreras\",\"no de carreras\",\"nro de carreras\",\"numero de carreras\",\"n° carreras\",\"n de carrera\",\"n carreras\"],\n",
    "    \"nivel_final\": [\"nivel final pozo\",\"nivel final\",\"nivel final del pozo\"],\n",
    "    \"obs_pozo\":    [\"observaciones del pozo\",\"observaciones\",\"comentarios\",\"comentario\"]\n",
    "}\n",
    "\n",
    "def _find_header_row(df_raw):\n",
    "    for i in range(min(200, len(df_raw))):\n",
    "        row_norm = [_norm(x) for x in df_raw.iloc[i,:].tolist()]\n",
    "        if not row_norm:\n",
    "            continue\n",
    "        colmap = {v:j for v,j in zip(row_norm, range(len(row_norm)))}\n",
    "        def has_any(keys): return any(k in colmap for k in keys)\n",
    "        if has_any(EXPECTED_KEYS[\"fecha\"]) and has_any(EXPECTED_KEYS[\"pozo\"]) and has_any(EXPECTED_KEYS[\"zona\"]) and has_any(EXPECTED_KEYS[\"bateria\"]):\n",
    "            return i, row_norm\n",
    "    return None, None\n",
    "\n",
    "# ---------- Nombres pozo ----------\n",
    "def load_pozo_dictionary(xlsx_path: str):\n",
    "    try:\n",
    "        ref = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer diccionario de pozos: {xlsx_path}\\n{e}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    cols = {c.lower().strip(): c for c in ref.columns}\n",
    "    if \"nombre_corto_pozo\" not in cols:\n",
    "        print(f\"\\n[AVISO] El diccionario no tiene la columna 'nombre_corto_pozo'. Columnas: {list(ref.columns)}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    c_pozo = cols[\"nombre_corto_pozo\"]\n",
    "    c_met  = cols.get(\"met_prod\")\n",
    "    c_n3   = cols.get(\"nivel_3\")\n",
    "    c_n5   = cols.get(\"nivel_5\")\n",
    "    c_est  = cols.get(\"estado\")\n",
    "\n",
    "    refv = ref.loc[ref[c_pozo].notna()].copy()\n",
    "    refv[c_pozo] = refv[c_pozo].astype(str).str.strip()\n",
    "\n",
    "    of_list  = refv[c_pozo].tolist()\n",
    "    met_vals = refv[c_met].astype(str).str.strip() if c_met else np.nan\n",
    "    n3_vals  = refv[c_n3].astype(str).str.strip()  if c_n3 else np.nan\n",
    "    n5_vals  = refv[c_n5].astype(str).str.strip()  if c_n5 else np.nan\n",
    "    est_vals = refv[c_est].astype(str).str.strip() if c_est else np.nan\n",
    "\n",
    "    keys, letters_, digits_canon_, digits_len_ = [], [], [], []\n",
    "    for val in of_list:\n",
    "        k = _pozo_key(val)\n",
    "        L, Dcanon, Dlen = _letters_digits_from_key_both(k)\n",
    "        keys.append(k); letters_.append(L); digits_canon_.append(Dcanon); digits_len_.append(Dlen)\n",
    "\n",
    "    dict_df = pd.DataFrame({\n",
    "        \"oficial\": of_list,\n",
    "        \"key\": keys,\n",
    "        \"letters\": letters_,\n",
    "        \"digits_canon\": digits_canon_,\n",
    "        \"digits_len\": digits_len_,\n",
    "        \"met_prod\": list(met_vals) if isinstance(met_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_3\":  list(n3_vals)  if isinstance(n3_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_5\":  list(n5_vals)  if isinstance(n5_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"estado\":   list(est_vals) if isinstance(est_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "    })\n",
    "\n",
    "    key2off = {}\n",
    "    for k, off in zip(dict_df[\"key\"], dict_df[\"oficial\"]):\n",
    "        if k and k not in key2off:\n",
    "            key2off[k] = off\n",
    "    return key2off, dict_df\n",
    "\n",
    "def apply_pozo_normalization(df: pd.DataFrame, key2off: dict, dict_df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"POZO_ORIG\"] = df[\"POZO\"].astype(str).str.strip()\n",
    "    df[\"POZO_PreCanon\"] = df[\"POZO_ORIG\"].apply(_canon_prefix_pozo)\n",
    "    df[\"__POZO_KEY\"] = df[\"POZO_PreCanon\"].apply(_pozo_key)\n",
    "\n",
    "    parts = df[\"__POZO_KEY\"].apply(_letters_digits_from_key_both)\n",
    "    df[\"__KEY_LET\"], df[\"__KEY_DIG_CANON\"], df[\"__KEY_DIG_LEN\"] = zip(*parts)\n",
    "\n",
    "    df[\"POZO_MATCH\"]   = None\n",
    "    df[\"MATCH_TIPO\"]   = \"NO\"\n",
    "    df[\"MATCH_SCORE\"]  = np.nan\n",
    "    df[\"LETTER_SCORE\"] = np.nan\n",
    "    df[\"APLICADO\"]     = \"NO\"\n",
    "    df[\"ALERTA_NORM\"]  = \"\"\n",
    "    df[\"VALIDO_POZO\"]  = True\n",
    "\n",
    "    invalid_mask = (df[\"__KEY_LET\"].str.len()==0) | (df[\"__KEY_DIG_LEN\"]==0)\n",
    "    if invalid_mask.any():\n",
    "        df.loc[invalid_mask, \"ALERTA_NORM\"] = \"SIN_LETRAS_O_DIGITOS\"\n",
    "        df.loc[invalid_mask, \"VALIDO_POZO\"] = False\n",
    "\n",
    "    valid_mask = ~invalid_mask\n",
    "    exact_mask = valid_mask & df[\"__POZO_KEY\"].isin(key2off.keys())\n",
    "    df.loc[exact_mask, \"POZO_MATCH\"]   = df.loc[exact_mask, \"__POZO_KEY\"].map(key2off)\n",
    "    df.loc[exact_mask, \"MATCH_TIPO\"]   = \"EXACTO\"\n",
    "    df.loc[exact_mask, \"MATCH_SCORE\"]  = 100\n",
    "    df.loc[exact_mask, \"LETTER_SCORE\"] = 100\n",
    "    df.loc[exact_mask, \"APLICADO\"]     = \"SI\"\n",
    "\n",
    "    pending = df[valid_mask & (~exact_mask)].index.tolist()\n",
    "    if pending and not dict_df.empty:\n",
    "        dict_by_spec = {}\n",
    "        for spec, sub in dict_df.groupby([\"digits_canon\",\"digits_len\"]):\n",
    "            dict_by_spec[spec] = sub\n",
    "\n",
    "        for idx in pending:\n",
    "            key_u   = df.at[idx, \"__POZO_KEY\"]\n",
    "            let_u   = df.at[idx, \"__KEY_LET\"]\n",
    "            digc_u  = df.at[idx, \"__KEY_DIG_CANON\"]\n",
    "            digl_u  = int(df.at[idx, \"__KEY_DIG_LEN\"])\n",
    "\n",
    "            cand_df = dict_by_spec.get((digc_u, digl_u), pd.DataFrame())\n",
    "            best_off, best_score, best_lscore = None, -1, -1\n",
    "\n",
    "            if cand_df is not None and not cand_df.empty:\n",
    "                for row in cand_df.itertuples():\n",
    "                    kk = row.key\n",
    "                    ll = row.letters\n",
    "                    sc_key = _fuzzy_score(key_u, kk)\n",
    "                    sc_let = _ratio_score(let_u, ll)\n",
    "                    if sc_let < LETTERS_SIMILARITY_MIN:\n",
    "                        continue\n",
    "                    if sc_key > best_score or (sc_key == best_score and sc_let > best_lscore):\n",
    "                        best_score = sc_key\n",
    "                        best_lscore = sc_let\n",
    "                        best_off   = row.oficial\n",
    "\n",
    "            if best_off is not None:\n",
    "                df.at[idx, \"POZO_MATCH\"]   = best_off\n",
    "                df.at[idx, \"MATCH_TIPO\"]   = \"SUGERIDO\"\n",
    "                df.at[idx, \"MATCH_SCORE\"]  = int(best_score)\n",
    "                df.at[idx, \"LETTER_SCORE\"] = int(best_lscore)\n",
    "            else:\n",
    "                df.at[idx, \"ALERTA_NORM\"] = \"SIN MATCH EN DICCIONARIO\"\n",
    "\n",
    "    # Reemplazos\n",
    "    df[\"POZO\"] = df[\"POZO_MATCH\"].where(df[\"POZO_MATCH\"].notna(), df[\"POZO\"])\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    df = df.merge(meta_first, how=\"left\", left_on=\"POZO\", right_index=True)\n",
    "\n",
    "    # ZONA sólo si hubo match; sino, vacío\n",
    "    if \"nivel_3\" in df.columns:\n",
    "        df.loc[df[\"POZO_MATCH\"].isna(), \"nivel_3\"] = \"\"\n",
    "        df[\"ZONA\"] = np.where(df[\"POZO_MATCH\"].notna(), df[\"nivel_3\"].fillna(\"\"), \"\")\n",
    "\n",
    "    # BATERIA si hay nivel_5\n",
    "    if \"nivel_5\" in df.columns:\n",
    "        df[\"BATERIA\"] = np.where(\n",
    "            df[\"nivel_5\"].notna() & (df[\"nivel_5\"].astype(str).str.strip()!=\"\"),\n",
    "            df[\"nivel_5\"], df[\"BATERIA\"]\n",
    "        )\n",
    "\n",
    "    df[\"__ZONA_NORM\"]    = df[\"ZONA\"].apply(_norm)\n",
    "    df[\"__BATERIA_NORM\"] = df[\"BATERIA\"].apply(_norm)\n",
    "\n",
    "    norm_table = (df[[\"POZO_ORIG\",\"POZO_PreCanon\",\"__POZO_KEY\",\n",
    "                      \"__KEY_LET\",\"__KEY_DIG_CANON\",\"__KEY_DIG_LEN\",\n",
    "                      \"POZO_MATCH\",\"MATCH_TIPO\",\"MATCH_SCORE\",\"LETTER_SCORE\",\n",
    "                      \"APLICADO\",\"ALERTA_NORM\",\"VALIDO_POZO\",\n",
    "                      \"met_prod\",\"nivel_3\",\"nivel_5\"]]\n",
    "                  .drop_duplicates()\n",
    "                  .rename(columns={\n",
    "                      \"POZO_ORIG\":\"Pozo_Original\",\n",
    "                      \"POZO_PreCanon\":\"Pozo_PreCanon\",\n",
    "                      \"__POZO_KEY\":\"Clave_Normalizada\",\n",
    "                      \"__KEY_LET\":\"Letras\",\n",
    "                      \"__KEY_DIG_CANON\":\"Digitos_Canon\",\n",
    "                      \"__KEY_DIG_LEN\":\"Digitos_Len\",\n",
    "                      \"POZO_MATCH\":\"Match_Oficial\",\n",
    "                      \"MATCH_TIPO\":\"Match_Tipo\",\n",
    "                      \"MATCH_SCORE\":\"Match_Score\",\n",
    "                      \"LETTER_SCORE\":\"Letter_Score\",\n",
    "                      \"APLICADO\":\"Aplicado\",\n",
    "                      \"ALERTA_NORM\":\"Alerta\",\n",
    "                      \"VALIDO_POZO\":\"Valido\",\n",
    "                      \"met_prod\":\"met_prod\",\n",
    "                      \"nivel_3\":\"nivel_3\",\n",
    "                      \"nivel_5\":\"nivel_5\"\n",
    "                  })\n",
    "                  .sort_values([\"Valido\",\"Aplicado\",\"Match_Tipo\",\"Pozo_Original\"], ascending=[False, False, True, True]))\n",
    "\n",
    "    alert_table = norm_table[(norm_table[\"Valido\"]==False) | (norm_table[\"Aplicado\"]==\"NO\") | (norm_table[\"Match_Tipo\"]==\"NO\")].copy()\n",
    "    return df, alert_table, norm_table\n",
    "\n",
    "def read_historial(xlsx_path, sheet_hist=None):\n",
    "    xl = pd.ExcelFile(xlsx_path)\n",
    "    sheets = [sheet_hist] if (sheet_hist and sheet_hist in xl.sheet_names) else xl.sheet_names\n",
    "    for sh in sheets:\n",
    "        raw = xl.parse(sh, header=None)\n",
    "        idx, header_norm = _find_header_row(raw)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        data = raw.iloc[idx:, :].copy()\n",
    "        true_headers = data.iloc[0,:].astype(str).tolist()\n",
    "        data = data.iloc[1:,:]\n",
    "        data.columns = true_headers\n",
    "\n",
    "        name_map = {c: _norm(c) for c in data.columns}\n",
    "        def find_col(candidates):\n",
    "            for c, n in name_map.items():\n",
    "                if n in candidates:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        c_fecha       = find_col(set(EXPECTED_KEYS[\"fecha\"]))\n",
    "        c_pozo        = find_col(set(EXPECTED_KEYS[\"pozo\"]))\n",
    "        c_zona        = find_col(set(EXPECTED_KEYS[\"zona\"]))\n",
    "        c_bateria     = find_col(set(EXPECTED_KEYS[\"bateria\"]))\n",
    "        c_m3          = find_col(set(EXPECTED_KEYS[\"m3\"]))\n",
    "        c_carr        = find_col(set(EXPECTED_KEYS[\"carreras\"]))\n",
    "        c_nivel_final = find_col(set(EXPECTED_KEYS[\"nivel_final\"]))\n",
    "        c_obs         = find_col(set(EXPECTED_KEYS[\"obs_pozo\"]))\n",
    "\n",
    "        if not (c_fecha and c_pozo and c_zona and c_bateria):\n",
    "            continue\n",
    "\n",
    "        use_cols = [c_fecha, c_pozo, c_zona, c_bateria]\n",
    "        headers  = [\"FECHA\",\"POZO\",\"ZONA\",\"BATERIA\"]\n",
    "        if c_m3:            use_cols.append(c_m3);            headers.append(\"M3\")\n",
    "        if c_carr:          use_cols.append(c_carr);          headers.append(\"CARRERAS\")\n",
    "        if c_nivel_final:   use_cols.append(c_nivel_final);   headers.append(\"NIVEL_FINAL\")\n",
    "        if c_obs:           use_cols.append(c_obs);           headers.append(\"OBS_POZO\")\n",
    "\n",
    "        df = data[use_cols].copy()\n",
    "        df.columns = headers\n",
    "\n",
    "        df[\"FECHA\"] = pd.to_datetime(df[\"FECHA\"], errors=\"coerce\")\n",
    "        if \"M3\" not in df.columns: df[\"M3\"] = np.nan\n",
    "        else: df[\"M3\"] = pd.to_numeric(df[\"M3\"], errors=\"coerce\")\n",
    "\n",
    "        if \"CARRERAS\" not in df.columns: df[\"CARRERAS\"] = np.nan\n",
    "        else: df[\"CARRERAS\"] = pd.to_numeric(df[\"CARRERAS\"], errors=\"coerce\")\n",
    "\n",
    "        if \"NIVEL_FINAL\" not in df.columns:\n",
    "            df[\"NIVEL_FINAL\"] = None\n",
    "        if \"OBS_POZO\" not in df.columns:\n",
    "            df[\"OBS_POZO\"] = None\n",
    "\n",
    "        for col in [\"POZO\",\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\",\"OBS_POZO\"]:\n",
    "            df[col] = df[col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "        df = df.dropna(subset=[\"FECHA\",\"POZO\"]).sort_values([\"POZO\",\"FECHA\"])\n",
    "        return df\n",
    "\n",
    "    raise ValueError(\"No pude detectar FECHA/POZO/ZONA/BATERÍA en ninguna hoja del Excel.\")\n",
    "\n",
    "def read_exclusions_from_sheet(xlsx_path):\n",
    "    excl = set()\n",
    "    try:\n",
    "        xl = pd.ExcelFile(xlsx_path)\n",
    "        if \"ExcluirPozos\" in xl.sheet_names:\n",
    "            e = xl.parse(\"ExcluirPozos\")\n",
    "            e.columns = [str(c).strip().lower() for c in e.columns]\n",
    "            if \"pozo\" in e.columns:\n",
    "                if \"excluir\" in e.columns:\n",
    "                    excl = set(e.loc[e[\"excluir\"].astype(str).str.upper().isin(\n",
    "                        [\"SI\",\"SÍ\",\"YES\",\"1\",\"TRUE\"]), \"pozo\"].astype(str).str.strip())\n",
    "                else:\n",
    "                    excl = set(e[\"pozo\"].astype(str).str.strip())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return excl\n",
    "\n",
    "# ==========================\n",
    "# Frecuencias / r_m3_d\n",
    "# ==========================\n",
    "def _count_trailing_zeros_with_carr(g):\n",
    "    cnt = 0\n",
    "    for _, row in g.sort_values(\"FECHA\").iloc[::-1].iterrows():\n",
    "        m3 = row.get(\"M3\", np.nan)\n",
    "        car = row.get(\"CARRERAS\", np.nan)\n",
    "        if pd.notna(m3) and float(m3) == 0.0 and pd.notna(car) and float(car) > 0:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    return cnt\n",
    "\n",
    "def compute_frecuencias(df, params):\n",
    "    v_target = params[\"m3_por_visita_objetivo\"]\n",
    "    min_d    = params[\"min_dias_freq\"]\n",
    "    max_d    = params[\"max_dias_freq\"]\n",
    "    k        = int(params[\"k_visitas\"])\n",
    "    one_days = int(params.get(\"dias_asumidos_una_visita\", 7))\n",
    "    freq_cero_ultimo = int(params.get(\"freq_dias_ultimo_cero_valido\", 30))\n",
    "\n",
    "    out = []\n",
    "    for pozo, g0 in df.groupby(\"POZO\", sort=False):\n",
    "        g = g0.sort_values(\"FECHA\").copy()\n",
    "\n",
    "        for col in [\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\"]:\n",
    "            if col in g.columns:\n",
    "                g[col] = g[col].replace({None: np.nan})\n",
    "                g[col] = g[col].ffill().bfill()\n",
    "\n",
    "        g[\"__ZONA_NORM\"]    = g[\"ZONA\"].apply(_norm)\n",
    "        g[\"__BATERIA_NORM\"] = g[\"BATERIA\"].apply(_norm)\n",
    "        g[\"__nf_norm\"]      = g[\"NIVEL_FINAL\"].apply(_norm) if \"NIVEL_FINAL\" in g.columns else \"\"\n",
    "\n",
    "        med_validas_all = g[g[\"M3\"].notna()].copy()\n",
    "\n",
    "        m3_eq0 = g[\"M3\"].fillna(0) == 0\n",
    "        carr   = g.get(\"CARRERAS\", pd.Series(index=g.index, dtype=float)).fillna(np.nan)\n",
    "        zero_cond_a = m3_eq0 & (carr.fillna(0) >= 1)\n",
    "        zero_cond_b = m3_eq0 & ((carr.isna()) | (carr.fillna(0) == 0)) & (g[\"__nf_norm\"] == \"surge\")\n",
    "        cond_cero_valido = zero_cond_a | zero_cond_b\n",
    "\n",
    "        validas_rate = g[(g[\"M3\"] > 0) | cond_cero_valido].copy()\n",
    "        zeros_tail = _count_trailing_zeros_with_carr(g)\n",
    "\n",
    "        ultima_med = med_validas_all[\"FECHA\"].max() if not med_validas_all.empty else pd.NaT\n",
    "        ultima_exi = g.loc[g[\"M3\"]>0, \"FECHA\"].max() if \"M3\" in g.columns and not g[g[\"M3\"]>0].empty else pd.NaT\n",
    "\n",
    "        last_zero_valido = False\n",
    "        if not med_validas_all.empty:\n",
    "            idx_last = med_validas_all[\"FECHA\"].idxmax()\n",
    "            m3_last  = g.at[idx_last, \"M3\"]\n",
    "            if pd.notna(m3_last) and float(m3_last) == 0.0:\n",
    "                try:\n",
    "                    last_zero_valido = bool(cond_cero_valido.loc[idx_last])\n",
    "                except Exception:\n",
    "                    last_zero_valido = False\n",
    "\n",
    "        alerta = \"\"\n",
    "        if last_zero_valido:\n",
    "            alerta = f\"ULTIMA_M3_0_VALIDO -> FREQ {freq_cero_ultimo}D\"\n",
    "        elif pd.notna(ultima_med):\n",
    "            if zeros_tail > 0:\n",
    "                alerta = f\"ALERTA: {zeros_tail} cero(s) consecutivo(s) con Carreras>0\"\n",
    "\n",
    "        # r_m3_d\n",
    "        r = np.nan\n",
    "        if not validas_rate.empty:\n",
    "            v = validas_rate.copy()\n",
    "            v[\"delta_d\"] = v[\"FECHA\"].diff().dt.days\n",
    "            v.loc[v[\"delta_d\"] <= 0, \"delta_d\"] = np.nan\n",
    "            v[\"rate\"] = v[\"M3\"].fillna(0) / v[\"delta_d\"]\n",
    "            rates = v[\"rate\"].dropna()\n",
    "            if len(rates) >= 1:\n",
    "                r = rates.tail(min(k, len(rates))).mean()\n",
    "            else:\n",
    "                row = v.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "        else:\n",
    "            if len(med_validas_all) == 1:\n",
    "                row = med_validas_all.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "\n",
    "        # FRECUENCIA\n",
    "        if last_zero_valido:\n",
    "            delta = int(freq_cero_ultimo)\n",
    "        else:\n",
    "            if pd.isna(r):      delta = 7\n",
    "            elif r <= 0:        delta = max_d\n",
    "            else:\n",
    "                delta = max(min_d, min(max_d, float(v_target)/float(r)))\n",
    "                delta = int(7 * round(delta / 7.0))\n",
    "                if delta < 7:\n",
    "                    delta = 7\n",
    "\n",
    "        prox = (ultima_med + pd.Timedelta(days=int(delta))) if pd.notna(ultima_med) else pd.Timestamp(next_monday())\n",
    "\n",
    "        out.append({\n",
    "            \"POZO\": pozo,\n",
    "            \"ZONA\": g[\"ZONA\"].iloc[-1],\n",
    "            \"BATERIA\": g[\"BATERIA\"].iloc[-1],\n",
    "            \"ZONA_NORM\": g[\"__ZONA_NORM\"].iloc[-1],\n",
    "            \"BATERIA_NORM\": g[\"__BATERIA_NORM\"].iloc[-1],\n",
    "            \"r_m3_d\": r,\n",
    "            \"ultima_medicion\": ultima_med,\n",
    "            \"ultima_exitosa\": ultima_exi,\n",
    "            \"delta_star_dias\": int(delta),\n",
    "            \"proxima_visita_base\": prox,\n",
    "            \"ceros_consec\": zeros_tail,\n",
    "            \"alerta\": alerta\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# ==========================\n",
    "# Coordenadas\n",
    "# ==========================\n",
    "def _to_float_maybe_comma(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if s == \"\": return np.nan\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def read_coords(xlsx_path):\n",
    "    try:\n",
    "        cdf = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer coordenadas: {xlsx_path}\\n{e}\\n\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    cols_map = {c.lower().strip(): c for c in cdf.columns}\n",
    "    c_pozo = cols_map.get(\"pozo\")\n",
    "    for k in [\"geo_latitude\",\"latitude\",\"lat\"]:\n",
    "        if k in cols_map:\n",
    "            c_lat = cols_map[k]; break\n",
    "    else:\n",
    "        c_lat = None\n",
    "    for k in [\"geo_longitude\",\"longitude\",\"lon\",\"long\"]:\n",
    "        if k in cols_map:\n",
    "            c_lon = cols_map[k]; break\n",
    "    else:\n",
    "        c_lon = None\n",
    "\n",
    "    if not (c_pozo and c_lat and c_lon):\n",
    "        print(f\"[AVISO] Coordenadas: columnas esperadas 'POZO','GEO_LATITUDE','GEO_LONGITUDE'. Columnas encontradas: {list(cdf.columns)}\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "\n",
    "    out = cdf[[c_pozo, c_lat, c_lon]].copy()\n",
    "    out.columns = [\"POZO\",\"LAT\",\"LON\"]\n",
    "    out[\"POZO\"] = out[\"POZO\"].astype(str).str.strip()\n",
    "    out[\"LAT\"] = out[\"LAT\"].apply(_to_float_maybe_comma)\n",
    "    out[\"LON\"] = out[\"LON\"].apply(_to_float_maybe_comma)\n",
    "    out = out.dropna(subset=[\"POZO\"])\n",
    "    out = out.drop_duplicates(subset=[\"POZO\"], keep=\"last\")\n",
    "    return out\n",
    "\n",
    "# ==========================\n",
    "# Candidatos y utilidades\n",
    "# ==========================\n",
    "def build_candidates_with_coords(freq, week_start, week_end, excl_pozos,\n",
    "                                 zonas_norm_incluidas, coords_df,\n",
    "                                 allowed_bats_by_zone_norm=None,\n",
    "                                 next_due_map=None):\n",
    "    F = freq.copy()\n",
    "\n",
    "    # due_date base (permitimos override con next_due_map)\n",
    "    F[\"due_date\"] = F[\"proxima_visita_base\"]\n",
    "    if next_due_map:\n",
    "        F[\"due_date\"] = F[\"POZO\"].map(next_due_map).fillna(F[\"due_date\"])\n",
    "\n",
    "    F[\"overdue_d\"] = (pd.Timestamp(week_start) - pd.to_datetime(F[\"due_date\"])).dt.days\n",
    "    F[\"is_overdue\"] = F[\"overdue_d\"] > 0\n",
    "\n",
    "    # prioridad\n",
    "    F[\"__v\"] = F[\"r_m3_d\"].astype(float)\n",
    "\n",
    "    # Filtro por ZONA (normalizada)\n",
    "    if \"ZONA_NORM\" in F.columns and zonas_norm_incluidas:\n",
    "        F = F[F[\"ZONA_NORM\"].isin(zonas_norm_incluidas)].copy()\n",
    "\n",
    "    # Sub-filtro por BATERÍA (si corresponde)\n",
    "    if allowed_bats_by_zone_norm:\n",
    "        mask = pd.Series(True, index=F.index)\n",
    "        for zn in zonas_norm_incluidas:\n",
    "            bats = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats is not None:\n",
    "                mask &= ~ (F[\"ZONA_NORM\"] == zn) | (F[\"BATERIA_NORM\"].isin(bats))\n",
    "        F = F[mask].copy()\n",
    "\n",
    "    # Exclusiones\n",
    "    if excl_pozos:\n",
    "        F = F[~F[\"POZO\"].isin(excl_pozos)].copy()\n",
    "\n",
    "    # Potencial mínimo y BATERÍA no vacía\n",
    "    F = F[F[\"r_m3_d\"].fillna(0) > RM3D_MIN].copy()\n",
    "    F = F[F[\"BATERIA\"].notna() & (F[\"BATERIA\"].astype(str).str.strip() != \"\")].copy()\n",
    "\n",
    "    # Excluir pozos con comentario no vacío en Frecuencias\n",
    "    if \"comentario\" in F.columns:\n",
    "        F[\"__comentario_txt\"] = F[\"comentario\"].astype(str).fillna(\"\").str.strip()\n",
    "        F = F[F[\"__comentario_txt\"] == \"\"].copy()\n",
    "        F.drop(columns=[\"__comentario_txt\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Merge coordenadas\n",
    "    coords_df = coords_df if coords_df is not None else pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    F = F.merge(coords_df, how=\"left\", on=\"POZO\")\n",
    "    F[\"has_coords\"] = F[\"LAT\"].notna() & F[\"LON\"].notna()\n",
    "\n",
    "    # Orden base\n",
    "    F = F.sort_values(by=[\"is_overdue\",\"__v\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    return F\n",
    "\n",
    "def _v_est_for_day(row, day_date):\n",
    "    r = row.get(\"r_m3_d\", np.nan)\n",
    "    u = row.get(\"ultima_medicion\", pd.NaT)\n",
    "    if pd.isna(u) or pd.isna(r) or r <= 0:\n",
    "        return 0.0\n",
    "    dd = max(0, (pd.Timestamp(day_date) - pd.Timestamp(u)).days)\n",
    "    return max(0.0, float(r) * float(dd))\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "            return np.nan\n",
    "        R = 6371.0088\n",
    "        p1 = math.radians(float(lat1)); p2 = math.radians(float(lat2))\n",
    "        dphi = math.radians(float(lat2) - float(lat1))\n",
    "        dlmb = math.radians(float(lon2) - float(lon1))\n",
    "        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "        return 2*R*math.asin(math.sqrt(a))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ==========================\n",
    "# NUEVA LÓGICA DE CLÚSTERES (según prompt)\n",
    "# ==========================\n",
    "def _bbox_filter(df, lat0, lon0, rad_km):\n",
    "    \"\"\"Bounding-box previo a haversine para acotar vecinos.\"\"\"\n",
    "    if pd.isna(lat0) or pd.isna(lon0) or df.empty:\n",
    "        return df.iloc[0:0]\n",
    "    dlat = rad_km / 110.574\n",
    "    dlon = rad_km / (111.320 * max(0.1, math.cos(math.radians(float(lat0)))))\n",
    "    return df[(df[\"LAT\"].between(lat0 - dlat, lat0 + dlat)) &\n",
    "              (df[\"LON\"].between(lon0 - dlon, lon0 + dlon))].copy()\n",
    "\n",
    "def _cluster_centroid(lat_list, lon_list):\n",
    "    if not lat_list or not lon_list:\n",
    "        return (np.nan, np.nan)\n",
    "    return float(np.mean(lat_list)), float(np.mean(lon_list))\n",
    "\n",
    "def _validate_cluster_by_centroid(lat_list, lon_list, radius_km):\n",
    "    c_lat, c_lon = _cluster_centroid(lat_list, lon_list)\n",
    "    if pd.isna(c_lat) or pd.isna(c_lon):\n",
    "        return False, (np.nan, np.nan), np.inf\n",
    "    dmax = 0.0\n",
    "    for la, lo in zip(lat_list, lon_list):\n",
    "        d = haversine_km(c_lat, c_lon, la, lo)\n",
    "        if pd.isna(d) or d > radius_km + 1e-9:\n",
    "            return False, (c_lat, c_lon), np.inf\n",
    "        dmax = max(dmax, d)\n",
    "    return True, (c_lat, c_lon), dmax\n",
    "\n",
    "def build_all_clusters(\n",
    "    cands: pd.DataFrame,\n",
    "    K: int,\n",
    "    radius_km: float,\n",
    "    score_mode: str = \"rm3d\",\n",
    "    top_seeds: int = 30\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve DF con:\n",
    "    ['ClusterID','POZOS','Centroide_LAT','Centroide_LON','Score','ZONA','BATERIAS']\n",
    "    - Exactamente K pozos por clúster\n",
    "    - Validación: todos a <= radius_km del CENTROIDE\n",
    "    - Overlap permitido en generación\n",
    "    - Semillas: mejores 'top_seeds' por __v\n",
    "    - Elimina duplicados exactos (mismo conjunto de pozos)\n",
    "    \"\"\"\n",
    "    if cands.empty:\n",
    "        return pd.DataFrame(columns=[\"ClusterID\",\"POZOS\",\"Centroide_LAT\",\"Centroide_LON\",\"Score\",\"ZONA\",\"BATERIAS\"])\n",
    "\n",
    "    # trabajar solo con pozos con coords\n",
    "    base = cands[cands[\"has_coords\"]].copy()\n",
    "    if base.empty:\n",
    "        return pd.DataFrame(columns=[\"ClusterID\",\"POZOS\",\"Centroide_LAT\",\"Centroide_LON\",\"Score\",\"ZONA\",\"BATERIAS\"])\n",
    "\n",
    "    base = base.sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    seeds = base.head(max(1, int(top_seeds))).copy()\n",
    "\n",
    "    clusters = []\n",
    "    seen_sets = set()  # para deduplicar por conjunto de pozos\n",
    "    for _, seed in seeds.iterrows():\n",
    "        s_lat, s_lon = seed[\"LAT\"], seed[\"LON\"]\n",
    "        neigh = _bbox_filter(base, s_lat, s_lon, radius_km)\n",
    "        if neigh.empty:\n",
    "            continue\n",
    "        # Orden por valor y cercanía a la semilla\n",
    "        neigh = neigh.copy()\n",
    "        neigh[\"__dist_seed\"] = neigh.apply(lambda r: haversine_km(s_lat, s_lon, r[\"LAT\"], r[\"LON\"]), axis=1)\n",
    "        neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "        neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "        # Tomar candidatos top K alrededor de la semilla (semilla incluida)\n",
    "        if seed[\"POZO\"] not in neigh[\"POZO\"].values:\n",
    "            # asegurar que la semilla esté\n",
    "            neigh = pd.concat([pd.DataFrame([seed]), neigh], ignore_index=True)\n",
    "            neigh = neigh.drop_duplicates(subset=[\"POZO\"], keep=\"first\")\n",
    "\n",
    "        if len(neigh) < K:\n",
    "            # no alcanza tamaño K dentro del radio de la semilla\n",
    "            continue\n",
    "\n",
    "        # Probar ventana de los top K mejor valuados dentro del radio\n",
    "        topk = neigh.head(K).copy()\n",
    "        pozos = tuple(topk[\"POZO\"].tolist())\n",
    "        lats  = topk[\"LAT\"].tolist()\n",
    "        lons  = topk[\"LON\"].tolist()\n",
    "\n",
    "        ok, (c_lat, c_lon), dmax = _validate_cluster_by_centroid(lats, lons, radius_km)\n",
    "        if not ok:\n",
    "            # Intentar ajustar: expandir lista ordenada y mover una ventana sobre los N mejores vecinos\n",
    "            N = min(len(neigh), K + 10)  # ventana corta para evitar combinatoria\n",
    "            window = neigh.head(N).copy()\n",
    "            found = False\n",
    "            # estrategia greedy: fijar semilla y tomar los K-1 mejores por __v que cumplan centroide\n",
    "            # probando reemplazos simples si no valida\n",
    "            for i in range(0, N-K+1):\n",
    "                cand = window.iloc[i:i+K]\n",
    "                lats2 = cand[\"LAT\"].tolist(); lons2 = cand[\"LON\"].tolist()\n",
    "                ok2, (c_lat2, c_lon2), _ = _validate_cluster_by_centroid(lats2, lons2, radius_km)\n",
    "                if ok2:\n",
    "                    topk = cand.copy()\n",
    "                    c_lat, c_lon = c_lat2, c_lon2\n",
    "                    pozos = tuple(topk[\"POZO\"].tolist())\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                continue  # no se pudo validar centroide\n",
    "\n",
    "        # dedupe exacto por set\n",
    "        key_set = frozenset(pozos)\n",
    "        if key_set in seen_sets:\n",
    "            continue\n",
    "        seen_sets.add(key_set)\n",
    "\n",
    "        # Score: rm3d o vest (hook)\n",
    "        if score_mode == \"vest\":\n",
    "            # si se usa vest, en generación no sabemos el día; dejamos rm3d como aproximación\n",
    "            score = float(topk[\"r_m3_d\"].fillna(0).sum())\n",
    "        else:\n",
    "            score = float(topk[\"r_m3_d\"].fillna(0).sum())\n",
    "\n",
    "        # ZONA/BATERIAS: mayoritaria (o homogénea si ya lo está)\n",
    "        zona_mode = topk[\"ZONA\"].mode()\n",
    "        zona_val = zona_mode.iloc[0] if not zona_mode.empty else \"\"\n",
    "        bats = tuple(sorted(set(str(x) for x in topk[\"BATERIA\"].fillna(\"\").astype(str))))\n",
    "\n",
    "        clusters.append({\n",
    "            \"ClusterID\": f\"C{len(seen_sets):05d}\",\n",
    "            \"POZOS\": pozos,\n",
    "            \"Centroide_LAT\": float(c_lat),\n",
    "            \"Centroide_LON\": float(c_lon),\n",
    "            \"Score\": score,\n",
    "            \"ZONA\": zona_val,\n",
    "            \"BATERIAS\": bats\n",
    "        })\n",
    "\n",
    "    cldf = pd.DataFrame(clusters)\n",
    "    if cldf.empty:\n",
    "        return cldf\n",
    "    cldf = cldf.sort_values(\"Score\", ascending=False).reset_index(drop=True)\n",
    "    return cldf\n",
    "\n",
    "\n",
    "def select_clusters_for_day(\n",
    "    clusters_df: pd.DataFrame,\n",
    "    used_today: set[str],\n",
    "    cap_pozos: int,\n",
    "    backfill_nearest: bool,\n",
    "    umbral_km_backfill: float,\n",
    "    clusters_por_dia_max: Optional[int] = None,\n",
    "    K: int = 5\n",
    ") -> list[dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Devuelve lista de dicts: {'POZOS', 'ClusterID', 'Centroide_LAT', 'Centroide_LON', 'Score'}\n",
    "    - Greedy por Score desc.\n",
    "    - No repetir pozos del día.\n",
    "    - Respetar clusters_por_dia_max y cap_pozos (multiplo de K).\n",
    "    - Si backfill_nearest=True: exigir distancia del centroide nuevo al centroide acumulado ≤ umbral.\n",
    "    \"\"\"\n",
    "    if clusters_df is None or clusters_df.empty:\n",
    "        return []\n",
    "\n",
    "    selected = []\n",
    "    pozos_usados = set(used_today)\n",
    "    cap_left = int(cap_pozos)\n",
    "    max_clusters = int(clusters_por_dia_max) if clusters_por_dia_max is not None else None\n",
    "\n",
    "    # centroide acumulado del día (promedio incremental)\n",
    "    c_lat_acc, c_lon_acc, n_acc = (np.nan, np.nan, 0)\n",
    "\n",
    "    def _update_centroid_acc(lat, lon):\n",
    "        nonlocal c_lat_acc, c_lon_acc, n_acc\n",
    "        if pd.isna(lat) or pd.isna(lon): \n",
    "            return\n",
    "        if n_acc == 0:\n",
    "            c_lat_acc, c_lon_acc, n_acc = float(lat), float(lon), 1\n",
    "        else:\n",
    "            c_lat_acc = (c_lat_acc*n_acc + float(lat)) / (n_acc + 1)\n",
    "            c_lon_acc = (c_lon_acc*n_acc + float(lon)) / (n_acc + 1)\n",
    "            n_acc += 1\n",
    "\n",
    "    for _, row in clusters_df.iterrows():\n",
    "        if cap_left < K:\n",
    "            break\n",
    "        if max_clusters is not None and len(selected) >= max_clusters:\n",
    "            break\n",
    "\n",
    "        pozos = set(row[\"POZOS\"])\n",
    "        if pozos & pozos_usados:\n",
    "            # contiene pozo ya tomado hoy\n",
    "            continue\n",
    "\n",
    "        if backfill_nearest and len(selected) >= 1 and not (pd.isna(c_lat_acc) or pd.isna(c_lon_acc)):\n",
    "            dcc = haversine_km(c_lat_acc, c_lon_acc, row[\"Centroide_LAT\"], row[\"Centroide_LON\"])\n",
    "            if pd.isna(dcc) or dcc > float(umbral_km_backfill) + 1e-9:\n",
    "                continue\n",
    "\n",
    "        selected.append({\n",
    "            \"POZOS\": list(row[\"POZOS\"]),\n",
    "            \"ClusterID\": row[\"ClusterID\"],\n",
    "            \"Centroide_LAT\": float(row[\"Centroide_LAT\"]),\n",
    "            \"Centroide_LON\": float(row[\"Centroide_LON\"]),\n",
    "            \"Score\": float(row[\"Score\"])\n",
    "        })\n",
    "        pozos_usados |= pozos\n",
    "        cap_left -= K\n",
    "        _update_centroid_acc(row[\"Centroide_LAT\"], row[\"Centroide_LON\"])\n",
    "\n",
    "    return selected\n",
    "\n",
    "# ==========================\n",
    "# ASIGNACIÓN SEMANAL ROUND-ROBIN (usando clústeres precomputados)\n",
    "# ==========================\n",
    "def assign_week_round_robin_by_zone(cand_all, team_ids, params, week_start, week_end, radius_km):\n",
    "    \"\"\"\n",
    "    Reparte por día/equipo en una zona, eligiendo clústeres precomputados (no pozos sueltos).\n",
    "    Reglas duras:\n",
    "    - Clúster tamaño exacto K\n",
    "    - Todos los pozos del clúster a ≤ radius_km del centroide (ya validado en build_all_clusters)\n",
    "    - No repetir POZO en el mismo día (entre equipos de la misma zona)\n",
    "    \"\"\"\n",
    "    dias   = int(params[\"dias_por_semana\"])\n",
    "    cap_pz = int(params[\"max_pozos_dia_equipo\"])\n",
    "    K      = int(params.get(\"max_pozos_por_cluster\", 4))\n",
    "    backfill_nearest = bool(params.get(\"backfill_nearest_cluster\", True))\n",
    "    umbral_backfill  = float(params.get(\"umbral_km_backfill\", 5.0))\n",
    "    clusters_por_dia_max = params.get(\"clusters_por_dia_max\", None)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # NUEVO: pozos ya usados en la semana (para no repetirlos lunes, martes, ...)\n",
    "    used_week = set()  # <<<\n",
    "\n",
    "    for d in range(dias):\n",
    "        day_date = pd.Timestamp(week_start) + pd.Timedelta(days=d)\n",
    "\n",
    "        # Ventana por DÍA (no por fin de semana) y excluir lo ya usado en la semana\n",
    "        pool_day = cand_all[~cand_all[\"POZO\"].isin(used_week)].copy()  # <<<\n",
    "        in_window = (pd.to_datetime(pool_day[\"due_date\"]) <= pd.Timestamp(day_date)) | pool_day[\"is_overdue\"]\n",
    "        pool_day = pool_day[in_window].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "\n",
    "        # Precomputar TODOS los clústeres de este día y zona (overlap permitido)\n",
    "        clusters_df = build_all_clusters(\n",
    "            cands=pool_day,\n",
    "            K=K,\n",
    "            radius_km=radius_km,\n",
    "            score_mode=\"rm3d\",\n",
    "            top_seeds=int(params.get(\"top_semillas_eval\", 30))\n",
    "        )\n",
    "        if clusters_df.empty:\n",
    "            # no hay clúster válido → ese día pueden quedar huecos\n",
    "            continue\n",
    "\n",
    "        # Greedy por equipo, sin repetir pozos el mismo día entre equipos\n",
    "        used_today = set()\n",
    "        for eq in sorted(team_ids):\n",
    "            chosen = select_clusters_for_day(\n",
    "                clusters_df=clusters_df,\n",
    "                used_today=used_today,\n",
    "                cap_pozos=cap_pz,\n",
    "                backfill_nearest=backfill_nearest,\n",
    "                umbral_km_backfill=umbral_backfill,     # ojo: si tu var se llama umbral_km_backfill, usa ese nombre\n",
    "                clusters_por_dia_max=clusters_por_dia_max,\n",
    "                K=K\n",
    "            )\n",
    "            if not chosen:\n",
    "                continue\n",
    "\n",
    "            # Materializar filas del plan a partir de los clústeres seleccionados\n",
    "            ord_idx = 1\n",
    "            for cluster in chosen:\n",
    "                pozos = cluster[\"POZOS\"]\n",
    "                c_lat = cluster[\"Centroide_LAT\"]\n",
    "                c_lon = cluster[\"Centroide_LON\"]\n",
    "                cid   = cluster[\"ClusterID\"]\n",
    "\n",
    "                # Traer filas originales para info r_m3_d, zona, batería, ultima_medicion\n",
    "                info = pool_day[pool_day[\"POZO\"].isin(pozos)].copy()\n",
    "                info = info.set_index(\"POZO\")\n",
    "\n",
    "                # asserts (criterios de aceptación)\n",
    "                assert len(pozos) == K, f\"Cluster {cid} no tiene tamaño K={K}\"\n",
    "                # distancias al centroide\n",
    "                dists = []\n",
    "                for pz in pozos:\n",
    "                    la = info.at[pz, \"LAT\"]; lo = info.at[pz, \"LON\"]\n",
    "                    d = haversine_km(c_lat, c_lon, la, lo)\n",
    "                    dists.append(d)\n",
    "                    assert (not pd.isna(d)) and d <= radius_km + 1e-6, f\"Pozo {pz} excede radio al centroide en cluster {cid}\"\n",
    "                max_d = float(np.max(dists))  # (no lo usamos pero te queda para log)\n",
    "\n",
    "                # Orden dentro del cluster: por cercanía al centroide, opcional\n",
    "                pozos_sorted = sorted(pozos, key=lambda p: haversine_km(c_lat, c_lon, info.at[p, \"LAT\"], info.at[p, \"LON\"]))\n",
    "\n",
    "                for pz in pozos_sorted:\n",
    "                    rec = info.loc[pz]\n",
    "                    try:\n",
    "                        v_est = _v_est_for_day({\"r_m3_d\": rec.get(\"r_m3_d\", np.nan),\n",
    "                                                \"ultima_medicion\": rec.get(\"ultima_medicion\", pd.NaT)}, day_date)\n",
    "                    except Exception:\n",
    "                        v_est = 0.0\n",
    "\n",
    "                    rows.append({\n",
    "                        \"Plan_Fecha\": day_date.date(),\n",
    "                        \"Semana_ISO\": day_date.isocalendar()[1],\n",
    "                        \"Equipo\": int(eq),\n",
    "                        \"Dia_Idx\": d+1,\n",
    "                        \"Orden\": ord_idx,\n",
    "                        \"ZONA\": rec.get(\"ZONA\",\"\"),\n",
    "                        \"BATERIA\": rec.get(\"BATERIA\",\"\"),\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": float(rec.get(\"__v\", rec.get(\"r_m3_d\", np.nan))),\n",
    "                        \"Vol_Estimado_m3\": round(float(v_est), 2),\n",
    "                        \"Seed_POZO\": \"\",  # ya no trabajamos por semilla en asignación\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": round(float(haversine_km(c_lat, c_lon, rec.get(\"LAT\"), rec.get(\"LON\"))), 3) if not (pd.isna(rec.get(\"LAT\")) or pd.isna(rec.get(\"LON\"))) else None,\n",
    "                        \"ultima_medicion\": rec.get(\"ultima_medicion\", pd.NaT),\n",
    "                        # Nuevas columnas informativas del cluster:\n",
    "                        \"ClusterID\": cid,\n",
    "                        \"Centroide_LAT\": c_lat,\n",
    "                        \"Centroide_LON\": c_lon,\n",
    "                    })\n",
    "                    ord_idx += 1\n",
    "\n",
    "                # Marcar pozos usados hoy y para el resto de la semana\n",
    "                used_today.update(pozos)\n",
    "                used_week.update(pozos)  # <<<  clave para que no se repitan en martes/miércoles/etc.\n",
    "\n",
    "        # verificación de no duplicación diaria\n",
    "        if rows:\n",
    "            plan_day = pd.DataFrame(rows)\n",
    "            same_day = plan_day[plan_day[\"Plan_Fecha\"] == day_date.date()]\n",
    "            if not same_day.empty:\n",
    "                dup = same_day.groupby([\"Plan_Fecha\",\"POZO\"]).size().max()\n",
    "                assert int(dup) == 1, \"Un pozo se repite el mismo día (violación de regla).\"\n",
    "\n",
    "    cols = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "            \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "            \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\",\n",
    "            \"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\"]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "# (Se elimina la versión anterior _fill_day_star_clusters: ahora ya no se usa.)\n",
    "\n",
    "def ensure_annual_coverage_zone_locked(all_pozos_df, plan, params, start_date, equipo_to_zona,\n",
    "                                       allowed_bats_by_zone_norm=None, r_by_pozo=None):\n",
    "    cap_pz = params[\"max_pozos_dia_equipo\"]\n",
    "\n",
    "    keys = []\n",
    "    for w in range(params[\"semanas_plan\"]):\n",
    "        w_start = start_date + timedelta(weeks=w)\n",
    "        for d in range(params[\"dias_por_semana\"]):\n",
    "            f = w_start + timedelta(days=d)\n",
    "            for e in equipo_to_zona.keys():\n",
    "                keys.append((e, f))\n",
    "\n",
    "    if not plan.empty:\n",
    "        plan[\"__key\"] = plan[\"Equipo\"].astype(int).astype(str) + \"|\" + plan[\"Plan_Fecha\"].astype(str)\n",
    "        used_counts = plan.groupby(\"__key\")[\"POZO\"].count().to_dict()\n",
    "    else:\n",
    "        used_counts = {}\n",
    "\n",
    "    planned = set(plan[\"POZO\"].unique()) if not plan.empty else set()\n",
    "    missing_df = all_pozos_df[~all_pozos_df[\"POZO\"].isin(planned)].copy()\n",
    "    missing_df = missing_df[missing_df[\"BATERIA\"].notna() & (missing_df[\"BATERIA\"].astype(str).str.strip()!=\"\")].copy()\n",
    "\n",
    "    add = []\n",
    "    for _, row in missing_df.iterrows():\n",
    "        pz = row[\"POZO\"]; z = row[\"ZONA\"]\n",
    "        bat = row.get(\"BATERIA\", \"\")\n",
    "\n",
    "        if not isinstance(bat, str) or bat.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            zn = _norm(z)\n",
    "            bats_allowed = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats_allowed is not None:\n",
    "                if _norm(bat) not in bats_allowed:\n",
    "                    continue\n",
    "\n",
    "        if r_by_pozo is not None:\n",
    "            r_val = float(r_by_pozo.get(pz, np.nan))\n",
    "            if not (r_val > RM3D_MIN):\n",
    "                continue\n",
    "\n",
    "        target_teams = [e for e, zona in equipo_to_zona.items() if zona == z]\n",
    "        if not target_teams:\n",
    "            continue\n",
    "        placed = False\n",
    "        for e in target_teams:\n",
    "            for (ee, f) in keys:\n",
    "                if ee != e:\n",
    "                    continue\n",
    "                key = f\"{e}|{f}\"\n",
    "                cnt = used_counts.get(key, 0)\n",
    "                if cnt < cap_pz:\n",
    "                    add.append({\n",
    "                        \"Plan_Fecha\": f,\n",
    "                        \"Semana_ISO\": f.isocalendar()[1],\n",
    "                        \"Equipo\": int(e),\n",
    "                        \"Dia_Idx\": f.weekday()+1,\n",
    "                        \"Orden\": cnt+1,\n",
    "                        \"ZONA\": z,\n",
    "                        \"BATERIA\": bat,\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": np.nan,\n",
    "                        \"Vol_Estimado_m3\": 0.0,\n",
    "                        \"Seed_POZO\": \"\",\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": None,\n",
    "                        \"ultima_medicion\": pd.NaT,\n",
    "                        \"ClusterID\": \"\",\n",
    "                        \"Centroide_LAT\": np.nan,\n",
    "                        \"Centroide_LON\": np.nan,\n",
    "                    })\n",
    "                    used_counts[key] = cnt+1\n",
    "                    placed = True\n",
    "                    break\n",
    "            if placed:\n",
    "                break\n",
    "\n",
    "    if add:\n",
    "        plan = pd.concat([plan, pd.DataFrame(add)], ignore_index=True)                 .sort_values([\"Plan_Fecha\",\"Equipo\",\"Orden\"])\n",
    "    return plan\n",
    "\n",
    "def build_alertas_abm(freq_df: pd.DataFrame, norm_table: pd.DataFrame, dict_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = freq_df[[\"POZO\",\"ZONA\",\"BATERIA\",\"ultima_medicion\",\"ultima_exitosa\"]].copy()\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"estado\",\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    base = base.merge(meta_first[[\"estado\",\"met_prod\"]], left_on=\"POZO\", right_index=True, how=\"left\")\n",
    "\n",
    "    out = base.copy()\n",
    "    for c in [\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "        out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "    out = out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ============================================\n",
    "# HARNES PARA JUPYTER\n",
    "# ============================================\n",
    "def run_pipeline_jupyter(\n",
    "    input_file,\n",
    "    nombres_pozo_file,\n",
    "    coords_file,\n",
    "    *,\n",
    "    semanas_plan=2,\n",
    "    equipos_activos=2,\n",
    "    dias_por_semana=5,\n",
    "    max_pozos_dia_equipo=10,\n",
    "    K_max_pozos_por_cluster=5,\n",
    "    clusters_por_dia_max=None,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,\n",
    "    baterias_por_zona=None,      # {\"las heras cg - canadon escondida\": {\"swabing ce\",\"ce 04\"}}\n",
    "    pozos_excluir=None,\n",
    "    escribir_excel=False\n",
    "):\n",
    "    global INPUT_FILE, NOMBRES_POZO_FILE, COORDS_FILE, RADIUS_KM, RM3D_MIN, DEFAULTS\n",
    "    INPUT_FILE       = input_file\n",
    "    NOMBRES_POZO_FILE= nombres_pozo_file\n",
    "    COORDS_FILE      = coords_file\n",
    "    RADIUS_KM        = float(radius_km)\n",
    "    RM3D_MIN         = float(rm3d_min)\n",
    "\n",
    "    DEFAULTS = DEFAULTS.copy()\n",
    "    DEFAULTS.update({\n",
    "        \"equipos_activos\": int(equipos_activos),\n",
    "        \"dias_por_semana\": int(dias_por_semana),\n",
    "        \"semanas_plan\": int(semanas_plan),\n",
    "        \"max_pozos_dia_equipo\": int(max_pozos_dia_equipo),\n",
    "        \"max_pozos_por_cluster\": int(K_max_pozos_por_cluster),\n",
    "        \"clusters_por_dia_max\": clusters_por_dia_max,\n",
    "        \"backfill_nearest_cluster\": bool(backfill_nearest),\n",
    "        \"umbral_km_backfill\": float(umbral_km_backfill),\n",
    "    })\n",
    "\n",
    "    # 1) Lee historial (Excel del usuario)\n",
    "    df = read_historial(INPUT_FILE, SHEET_HIST)\n",
    "\n",
    "    # 2) Normalización por diccionario\n",
    "    key2off, dict_df = load_pozo_dictionary(NOMBRES_POZO_FILE)\n",
    "    df_norm, alert_table, norm_table = apply_pozo_normalization(df, key2off, dict_df)\n",
    "\n",
    "    # 3) Filtra inválidos\n",
    "    df = df_norm[df_norm[\"VALIDO_POZO\"] == True].copy()\n",
    "\n",
    "    # 4) Filtro por ZONA (si se pide explícito)\n",
    "    if zonas_incluir:\n",
    "        zonas_incluir = set(zonas_incluir)\n",
    "        znorm = {_norm(z) for z in zonas_incluir}\n",
    "        df = df[df[\"__ZONA_NORM\"].isin(znorm)].copy()\n",
    "        zonas_labels = zonas_incluir\n",
    "        zonas_norm   = znorm\n",
    "    else:\n",
    "        zonas_labels, zonas_norm = set(df[\"ZONA\"].dropna().astype(str)), set(df[\"__ZONA_NORM\"].dropna().astype(str))\n",
    "\n",
    "    # 5) Sub-filtro de baterías (si lo pasaste por parámetro)\n",
    "    if baterias_por_zona:\n",
    "        allowed_bats_by_zone_norm = {zn: set(baterias_por_zona[zn]) if baterias_por_zona[zn] is not None else None\n",
    "                                     for zn in baterias_por_zona}\n",
    "    else:\n",
    "        allowed_bats_by_zone_norm = {zn: None for zn in zonas_norm}\n",
    "\n",
    "    # 6) Exclusiones (si te pasan un set)\n",
    "    excl_total = set(pozos_excluir or [])\n",
    "\n",
    "    # 7) Frecuencias\n",
    "    params = DEFAULTS.copy()\n",
    "    freq = compute_frecuencias(df, params)\n",
    "\n",
    "    # Comentarios desde OBS cuando ultima_medicion != ultima_exitosa\n",
    "    df_obs = df[[\"POZO\", \"FECHA\", \"OBS_POZO\"]].copy() if \"OBS_POZO\" in df.columns else pd.DataFrame(columns=[\"POZO\",\"FECHA\",\"OBS_POZO\"])\n",
    "    df_obs[\"FECHA_DATE\"] = pd.to_datetime(df_obs[\"FECHA\"], errors=\"coerce\").dt.date\n",
    "    df_obs = (df_obs.dropna(subset=[\"FECHA_DATE\"])\n",
    "                    .sort_values([\"POZO\",\"FECHA_DATE\"])\n",
    "                    .drop_duplicates(subset=[\"POZO\",\"FECHA_DATE\"], keep=\"last\"))\n",
    "    obs_map = {(r.POZO, r.FECHA_DATE): (str(r.OBS_POZO).strip() if pd.notna(r.OBS_POZO) else \"\")\n",
    "               for r in df_obs.itertuples(index=False)}\n",
    "    freq[\"__UMED_DATE\"] = pd.to_datetime(freq[\"ultima_medicion\"], errors=\"coerce\").dt.date\n",
    "    freq[\"__UEXI_DATE\"] = pd.to_datetime(freq[\"ultima_exitosa\"], errors=\"coerce\").dt.date\n",
    "    freq[\"comentario\"] = [obs_map.get((pz, fmed), \"\") for pz, fmed in zip(freq[\"POZO\"], freq[\"__UMED_DATE\"])]\n",
    "    mask_both_valid = freq[\"__UMED_DATE\"].notna() & freq[\"__UEXI_DATE\"].notna()\n",
    "    mask_diff = mask_both_valid & (freq[\"__UMED_DATE\"] != freq[\"__UEXI_DATE\"])\n",
    "    freq.loc[~mask_diff, \"comentario\"] = \"\"\n",
    "    freq.drop(columns=[\"__UMED_DATE\",\"__UEXI_DATE\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # 8) Coordenadas\n",
    "    coords_df = read_coords(COORDS_FILE)\n",
    "\n",
    "    # 9) Mapas auxiliares\n",
    "    delta_by_pozo = freq.set_index(\"POZO\")[\"delta_star_dias\"].to_dict()\n",
    "    r_by_pozo     = freq.set_index(\"POZO\")[\"r_m3_d\"].to_dict()\n",
    "\n",
    "    # 10) Semanas a planificar\n",
    "    start = next_monday(date.today())\n",
    "    weeks = [(start + timedelta(weeks=i), start + timedelta(weeks=i, days=6)) for i in range(params[\"semanas_plan\"])]\n",
    "\n",
    "    # 11) Equipos -> ZONA (fijo)\n",
    "    zonas_list = sorted(set(zonas_labels))\n",
    "    equipo_to_zona = {}\n",
    "    for i in range(1, params[\"equipos_activos\"]+1):\n",
    "        zona_asignada = zonas_list[min(i-1, len(zonas_list)-1)]\n",
    "        equipo_to_zona[i] = zona_asignada\n",
    "\n",
    "    # 12) Plan semanal por ZONA usando la versión V2 (clústeres)\n",
    "    plan_all = []\n",
    "    next_due = {row.POZO: row.proxima_visita_base for row in freq.itertuples()}\n",
    "    zone_to_teams = {}\n",
    "    for eq, zona_label in equipo_to_zona.items():\n",
    "        zone_to_teams.setdefault(zona_label, []).append(eq)\n",
    "\n",
    "    for (w_start, w_end) in weeks:\n",
    "        for zona_label, team_list in zone_to_teams.items():\n",
    "            zona_norm_label = _norm(zona_label)\n",
    "            cand_all = build_candidates_with_coords(\n",
    "                freq=freq,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                excl_pozos=excl_total,\n",
    "                zonas_norm_incluidas={zona_norm_label},\n",
    "                coords_df=coords_df,\n",
    "                allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "                next_due_map=next_due\n",
    "            )\n",
    "            if cand_all.empty:\n",
    "                continue\n",
    "\n",
    "            cand_zone = cand_all[[  # mantener las columnas necesarias\n",
    "                \"POZO\",\"ZONA\",\"BATERIA\",\"due_date\",\"is_overdue\",\"__v\",\n",
    "                \"LAT\",\"LON\",\"has_coords\",\"r_m3_d\",\"ultima_medicion\"\n",
    "            ]].copy()\n",
    "\n",
    "            plan_week_zone = assign_week_round_robin_by_zone(\n",
    "                cand_all=cand_zone,\n",
    "                team_ids=sorted(team_list),\n",
    "                params=params,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                radius_km=RADIUS_KM\n",
    "            )\n",
    "\n",
    "            if not plan_week_zone.empty:\n",
    "                plan_all.append(plan_week_zone)\n",
    "                # actualizar next_due por pozo asignado\n",
    "                for pz, fcal in plan_week_zone[[\"POZO\",\"Plan_Fecha\"]].drop_duplicates().itertuples(index=False):\n",
    "                    dd = int(delta_by_pozo.get(pz, params[\"min_dias_freq\"]))\n",
    "                    next_due[pz] = pd.Timestamp(fcal) + pd.Timedelta(days=dd)\n",
    "\n",
    "    plan = (pd.concat(plan_all, ignore_index=True)\n",
    "            if plan_all else\n",
    "            pd.DataFrame(columns=[\n",
    "                \"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\"ZONA\",\"BATERIA\",\n",
    "                \"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\"Seed_POZO\",\"Dist_km_semilla\",\n",
    "                \"Dist_km_centroid\",\"ultima_medicion\",\"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\",\"Cluster_Score\"\n",
    "            ]))\n",
    "\n",
    "    # 13) Cobertura anual reforzada (opcional) — mantiene tu lógica original (no forma clúster)\n",
    "    if not freq.empty:\n",
    "        eligible_mask = (freq[\"ZONA\"].isin(zonas_labels)) & (freq[\"r_m3_d\"].fillna(0) > RM3D_MIN)\n",
    "        if \"comentario\" in freq.columns:\n",
    "            eligible_mask &= (freq[\"comentario\"].astype(str).fillna(\"\").str.strip() == \"\")\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            for zn, bats in allowed_bats_by_zone_norm.items():\n",
    "                if bats is not None:\n",
    "                    eligible_mask &= (~(freq[\"ZONA_NORM\"] == zn)) | (freq[\"BATERIA_NORM\"].isin(bats))\n",
    "\n",
    "        all_pozos_in_zonas = freq.loc[eligible_mask, [\"POZO\",\"ZONA\",\"BATERIA\"]].drop_duplicates().copy()\n",
    "        all_pozos_in_zonas = all_pozos_in_zonas[\n",
    "            all_pozos_in_zonas[\"BATERIA\"].notna() & (all_pozos_in_zonas[\"BATERIA\"].astype(str).str.strip() != \"\")\n",
    "        ].copy()\n",
    "\n",
    "        # usa el filler original (sin clúster) SOLO para cubrir huecos anuales\n",
    "     #   plan = ensure_annual_coverage_zone_locked(\n",
    "      #      all_pozos_df=all_pozos_in_zonas,\n",
    "       #     plan=plan,\n",
    "        #    params=params,\n",
    "         #   start_date=start,\n",
    "          #  equipo_to_zona=equipo_to_zona,\n",
    "           # allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "            #r_by_pozo=r_by_pozo\n",
    "       # )\n",
    "\n",
    "    # 14) Export opcional (agrego columnas nuevas de clúster)\n",
    "    out_xlsx = None\n",
    "    if escribir_excel:\n",
    "        out_xlsx = unique_output_path(INPUT_FILE)\n",
    "        coords_all = read_coords(COORDS_FILE)\n",
    "        with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "            # Frecuencias\n",
    "            freq_out = freq.copy()\n",
    "            for c in [\"proxima_visita_base\",\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "                freq_out[c] = pd.to_datetime(freq_out[c], errors=\"coerce\").dt.date\n",
    "            freq_out = freq_out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"])\n",
    "            cols_pref = [\"POZO\",\"ZONA\",\"BATERIA\",\"ZONA_NORM\",\"BATERIA_NORM\",\"r_m3_d\",\n",
    "                         \"ultima_medicion\",\"ultima_exitosa\",\"delta_star_dias\",\"comentario\",\n",
    "                         \"proxima_visita_base\",\"ceros_consec\",\"alerta\"]\n",
    "            cols_final = [c for c in cols_pref if c in freq_out.columns] + \\\n",
    "                         [c for c in freq_out.columns if c not in cols_pref]\n",
    "            freq_out = freq_out[cols_final]\n",
    "            freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
    "\n",
    "            # Plan por equipo + Km_al_siguiente\n",
    "            cols_plan = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "                         \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "                         \"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\",\"Cluster_Score\",\n",
    "                         \"Dist_km_centroid\"]\n",
    "            for eq in range(1, params[\"equipos_activos\"]+1):\n",
    "                pe = plan.loc[plan[\"Equipo\"]==eq].copy()\n",
    "                if pe.empty:\n",
    "                    pe = pd.DataFrame(columns=cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"])\n",
    "                else:\n",
    "                    pe = pe.sort_values([\"Plan_Fecha\",\"Dia_Idx\",\"Orden\",\"POZO\"]).copy()\n",
    "                    pe = pe.merge(coords_all, how=\"left\", on=\"POZO\")\n",
    "                    pe[\"LAT_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LAT\"].shift(-1)\n",
    "                    pe[\"LON_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LON\"].shift(-1)\n",
    "                    def _leg_km(row):\n",
    "                        if (pd.isna(row.get(\"LAT\")) or pd.isna(row.get(\"LON\")) or\n",
    "                            pd.isna(row.get(\"LAT_next\")) or pd.isna(row.get(\"LON_next\"))):\n",
    "                            return None\n",
    "                        return round(float(haversine_km(row[\"LAT\"], row[\"LON\"],\n",
    "                                                        row[\"LAT_next\"], row[\"LON_next\"])), 3)\n",
    "                    pe[\"Km_al_siguiente\"] = pe.apply(_leg_km, axis=1)\n",
    "                    pe.drop(columns=[\"LAT\",\"LON\",\"LAT_next\",\"LON_next\"], inplace=True, errors=\"ignore\")\n",
    "                    pe[\"Ejecutado\"] = \"\"\n",
    "                    for c in cols_plan:\n",
    "                        if c not in pe.columns: pe[c] = \"\"\n",
    "                    pe = pe[cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"]]\n",
    "                pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
    "\n",
    "            # Auxiliares\n",
    "            pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n",
    "\n",
    "    # ====== Asserts/chequeos mínimos ======\n",
    "    # ====== Asserts/chequeos mínimos ======\n",
    "    if not plan.empty:\n",
    "        K_chk = int(params.get(\"max_pozos_por_cluster\", 5))\n",
    "\n",
    "        # ✅ Validar SOLO clústeres reales (ClusterID no vacío)\n",
    "        mask_real = plan[\"ClusterID\"].notna() & (plan[\"ClusterID\"].astype(str).str.strip() != \"\")\n",
    "        gsize = (plan.loc[mask_real]\n",
    "                 .groupby([\"Plan_Fecha\",\"Equipo\",\"ClusterID\"])[\"POZO\"]\n",
    "                 .count())\n",
    "\n",
    "        if not gsize.empty:\n",
    "            assert (gsize % K_chk == 0).all(), \"Hay clústeres asignados que no cumplen tamaño K exacto.\"\n",
    "\n",
    "        # ✅ No duplicación diaria (ningún pozo se repite en el mismo día)\n",
    "        dupmax = plan.groupby([\"Plan_Fecha\",\"POZO\"]).size().max()\n",
    "        assert int(dupmax) == 1, \"Un pozo aparece más de una vez en el mismo día.\"\n",
    "\n",
    "        # ✅ Radio cumplido (tolerancia numérica)\n",
    "        if \"Dist_km_centroid\" in plan.columns and plan[\"Dist_km_centroid\"].notna().any():\n",
    "            assert float(plan[\"Dist_km_centroid\"].fillna(0).max()) <= float(RADIUS_KM) + 1e-6, \\\n",
    "                \"Distancia a centroide excede el radio.\"\n",
    "\n",
    "    return plan, freq, out_xlsx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# RUNNER (EDITÁ TUS RUTAS Y PARÁMETROS ACÁ)\n",
    "# ============================================\n",
    "\n",
    "INPUT_FILE = r\"C:\\Users\\ry16123\\Downloads\\Ultimo (ORIGINAL) TABLERO PRODUCCIÓN FLUG S.A 2025 (1).xlsx\"\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "plan, freq, out_xlsx = run_pipeline_jupyter(\n",
    "    input_file=INPUT_FILE,\n",
    "    nombres_pozo_file=NOMBRES_POZO_FILE,\n",
    "    coords_file=COORDS_FILE,\n",
    "    semanas_plan=3,                 # probá corto para iterar rápido\n",
    "    equipos_activos=3,              # cantidad de equipos\n",
    "    dias_por_semana=5,              # 5 ó 6\n",
    "    max_pozos_dia_equipo=5,\n",
    "    K_max_pozos_por_cluster=5,      # tamaño máximo de clúster\n",
    "    clusters_por_dia_max=1,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,             # o lista como [\"Las Heras CG - Canadon Escondida\"]\n",
    "    baterias_por_zona=None,         # dict normalizado (keys en _norm) o None\n",
    "    pozos_excluir=set(),            # ej.: {\"BB-100\"}\n",
    "    escribir_excel=True            # poné True si querés exportar el Excel\n",
    ")\n",
    "\n",
    "# Mostrar un vistazo rápido\n",
    "display(freq.head(10))\n",
    "display(plan.head(30))\n",
    "print(\"Excel generado:\", out_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e9982ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\CursoML-UDEMY\\env\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\4274411451.py:424: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  g[col] = g[col].replace({None: np.nan})\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\4274411451.py:1291: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\4274411451.py:1319: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\4274411451.py:1319: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_19128\\4274411451.py:1322: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POZO</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>ZONA_NORM</th>\n",
       "      <th>BATERIA_NORM</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ultima_exitosa</th>\n",
       "      <th>delta_star_dias</th>\n",
       "      <th>proxima_visita_base</th>\n",
       "      <th>ceros_consec</th>\n",
       "      <th>alerta</th>\n",
       "      <th>comentario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BB-10</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BB-100</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BB-101</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB.a-104</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB-111</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB-133</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BB-170</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BB-21</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BB497</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BB-50</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       POZO                              ZONA     BATERIA  \\\n",
       "0     BB-10  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "1    BB-100  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "2    BB-101  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "3  BB.a-104  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "4    BB-111  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "5    BB-133  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "6    BB-170  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "7     BB-21  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "8     BB497                                           NaN   \n",
       "9     BB-50  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "\n",
       "                        ZONA_NORM BATERIA_NORM    r_m3_d ultima_medicion  \\\n",
       "0  las heras cg canadon escondida   swabing ce  0.015385      2025-07-16   \n",
       "1  las heras cg canadon escondida   swabing ce  0.142857      2023-08-04   \n",
       "2  las heras cg canadon escondida   swabing ce  0.035714      2025-08-25   \n",
       "3  las heras cg canadon escondida   swabing ce  0.285714      2025-01-24   \n",
       "4  las heras cg canadon escondida   swabing ce  0.428571      2025-07-01   \n",
       "5  las heras cg canadon escondida   swabing ce  0.037037      2025-02-19   \n",
       "6  las heras cg canadon escondida   swabing ce  0.285714      2024-07-24   \n",
       "7  las heras cg canadon escondida   swabing ce  0.015564      2025-05-12   \n",
       "8                                               0.571429      2025-01-08   \n",
       "9  las heras cg canadon escondida   swabing ce  0.081633      2023-03-10   \n",
       "\n",
       "  ultima_exitosa  delta_star_dias proxima_visita_base  ceros_consec alerta  \\\n",
       "0     2025-07-16               56          2025-09-10             0          \n",
       "1     2023-08-04               14          2023-08-18             0          \n",
       "2     2025-08-25               56          2025-10-20             0          \n",
       "3     2025-01-24                7          2025-01-31             0          \n",
       "4     2025-07-01                7          2025-07-08             0          \n",
       "5     2025-02-19               56          2025-04-16             0          \n",
       "6     2024-07-24                7          2024-07-31             0          \n",
       "7     2025-05-12               56          2025-07-07             0          \n",
       "8     2025-01-08                7          2025-01-15             0          \n",
       "9     2023-03-10               28          2023-04-07             0          \n",
       "\n",
       "  comentario  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             \n",
       "5             \n",
       "6             \n",
       "7             \n",
       "8             \n",
       "9             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_Fecha</th>\n",
       "      <th>Semana_ISO</th>\n",
       "      <th>Equipo</th>\n",
       "      <th>Dia_Idx</th>\n",
       "      <th>Orden</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>POZO</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>Vol_Estimado_m3</th>\n",
       "      <th>Seed_POZO</th>\n",
       "      <th>Dist_km_semilla</th>\n",
       "      <th>Dist_km_centroid</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>Centroide_LAT</th>\n",
       "      <th>Centroide_LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-1234</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>72.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.290</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 20</td>\n",
       "      <td>CnE-1224(d)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>37.14</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.468</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-473</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>12.75</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.172</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-868</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>13.36</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.583</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-849</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>14.80</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.331</td>\n",
       "      <td>2025-07-17</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.438652</td>\n",
       "      <td>-68.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-808</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>3.19</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.056</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-226</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>5.71</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.278</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-199</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.414</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-534</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.504</td>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2.055880</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-660</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.80</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.403392</td>\n",
       "      <td>-68.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 10</td>\n",
       "      <td>CnE.a-93</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>59.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.903</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 11</td>\n",
       "      <td>CnE-379</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>29.87</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-543</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>10.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.036</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4.80</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.250334</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-885</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>35.31</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.976</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>C00010</td>\n",
       "      <td>-46.467081</td>\n",
       "      <td>-68.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 03</td>\n",
       "      <td>CnE-124</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.57</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.441</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-221</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>3.16</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.755</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-210</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>10.07</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.450</td>\n",
       "      <td>2025-07-24</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 04</td>\n",
       "      <td>CnE-219</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>187.25</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.903</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.274812</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 01</td>\n",
       "      <td>CnE-731</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.57</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>C00009</td>\n",
       "      <td>-46.452249</td>\n",
       "      <td>-68.679064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-694</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.789</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-521</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>3.71</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.969</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>30.25</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.321</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-728</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>13.91</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.531</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788638</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-586</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>7.07</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.396247</td>\n",
       "      <td>-68.601993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 12</td>\n",
       "      <td>CnE-829</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>49.45</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.547</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-422</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>10.92</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.821</td>\n",
       "      <td>2025-07-22</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-504</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>33.14</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.307</td>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-1155</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>10.71</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.366</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>5</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-732</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>4.73</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.437632</td>\n",
       "      <td>-68.552173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plan_Fecha  Semana_ISO  Equipo   Dia_Idx  Orden  \\\n",
       "0   2025-09-29          40       1  2.171666      1   \n",
       "1   2025-09-29          40       1  2.171666      2   \n",
       "2   2025-09-29          40       1  2.171666      3   \n",
       "3   2025-09-29          40       1  2.171666      4   \n",
       "4   2025-09-29          40       1  2.171666      5   \n",
       "5   2025-09-29          40       2  2.055880      1   \n",
       "6   2025-09-29          40       2  2.055880      2   \n",
       "7   2025-09-29          40       2  2.055880      3   \n",
       "8   2025-09-29          40       2  2.055880      4   \n",
       "9   2025-09-29          40       2  2.055880      5   \n",
       "10  2025-09-30          40       1  2.250334      1   \n",
       "11  2025-09-30          40       1  2.250334      2   \n",
       "12  2025-09-30          40       1  2.250334      3   \n",
       "13  2025-09-30          40       1  2.250334      4   \n",
       "14  2025-09-30          40       1  2.250334      5   \n",
       "15  2025-09-30          40       2  3.274812      1   \n",
       "16  2025-09-30          40       2  3.274812      2   \n",
       "17  2025-09-30          40       2  3.274812      3   \n",
       "18  2025-09-30          40       2  3.274812      4   \n",
       "19  2025-09-30          40       2  3.274812      5   \n",
       "20  2025-10-01          40       1  1.788638      1   \n",
       "21  2025-10-01          40       1  1.788638      2   \n",
       "22  2025-10-01          40       1  1.788638      3   \n",
       "23  2025-10-01          40       1  1.788638      4   \n",
       "24  2025-10-01          40       1  1.788638      5   \n",
       "25  2025-10-01          40       2  3.366298      1   \n",
       "26  2025-10-01          40       2  3.366298      2   \n",
       "27  2025-10-01          40       2  3.366298      3   \n",
       "28  2025-10-01          40       2  3.366298      4   \n",
       "29  2025-10-01          40       2  3.366298      5   \n",
       "\n",
       "                                ZONA     BATERIA         POZO    r_m3_d  \\\n",
       "0   Las Heras CG - Canadon Escondida  Swabing CE     CnE-1234  0.285714   \n",
       "1   Las Heras CG - Canadon Escondida       CE 20  CnE-1224(d)  0.285714   \n",
       "2   Las Heras CG - Canadon Escondida  Swabing CE      CnE-473  0.187500   \n",
       "3   Las Heras CG - Canadon Escondida  Swabing CE      CnE-868  0.272727   \n",
       "4   Las Heras CG - Canadon Escondida  Swabing CE      CnE-849  0.200000   \n",
       "5   Las Heras CG - Canadon Escondida  Swabing CE      CnE-808  0.187500   \n",
       "6   Las Heras CG - Canadon Escondida  Swabing CE    CnE.a-226  0.238095   \n",
       "7   Las Heras CG - Canadon Escondida  Swabing CE      CnE-199  0.285714   \n",
       "8   Las Heras CG - Canadon Escondida  Swabing CE      CnE-534  0.214286   \n",
       "9   Las Heras CG - Canadon Escondida  Swabing CE      CnE-660  0.200000   \n",
       "10  Las Heras CG - Canadon Escondida       CE 10     CnE.a-93  0.142857   \n",
       "11  Las Heras CG - Canadon Escondida       CE 11      CnE-379  0.133333   \n",
       "12  Las Heras CG - Canadon Escondida  Swabing CE      CnE-543  0.277778   \n",
       "13  Las Heras CG - Canadon Escondida  Swabing CE      CnE-736  0.266667   \n",
       "14  Las Heras CG - Canadon Escondida  Swabing CE      CnE-885  0.230769   \n",
       "15  Las Heras CG - Canadon Escondida       CE 03      CnE-124  0.142857   \n",
       "16  Las Heras CG - Canadon Escondida  Swabing CE      CnE-221  0.157895   \n",
       "17  Las Heras CG - Canadon Escondida  Swabing CE      CnE-210  0.148148   \n",
       "18  Las Heras CG - Canadon Escondida       CE 04      CnE-219  0.291667   \n",
       "19  Las Heras CG - Canadon Escondida       CE 01      CnE-731  0.142857   \n",
       "20  Las Heras CG - Canadon Escondida       CE 19      CnE-694  0.142857   \n",
       "21  Las Heras CG - Canadon Escondida  Swabing CE      CnE-521  0.161290   \n",
       "22  Las Heras CG - Canadon Escondida       CE 19      CnE-696  0.250000   \n",
       "23  Las Heras CG - Canadon Escondida  Swabing CE      CnE-728  0.156250   \n",
       "24  Las Heras CG - Canadon Escondida  Swabing CE    CnE.a-586  0.172414   \n",
       "25  Las Heras CG - Canadon Escondida       CE 12      CnE-829  0.181818   \n",
       "26  Las Heras CG - Canadon Escondida  Swabing CE      CnE-422  0.153846   \n",
       "27  Las Heras CG - Canadon Escondida  Swabing CE      CnE-504  0.142857   \n",
       "28  Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-1155  0.107143   \n",
       "29  Las Heras CG - Canadon Escondida  Swabing CE      CnE-732  0.181818   \n",
       "\n",
       "    Vol_Estimado_m3 Seed_POZO Dist_km_semilla  Dist_km_centroid  \\\n",
       "0             72.86                      None             0.290   \n",
       "1             37.14                      None             0.468   \n",
       "2             12.75                      None             1.172   \n",
       "3             13.36                      None             1.583   \n",
       "4             14.80                      None             2.331   \n",
       "5              3.19                      None             1.056   \n",
       "6              5.71                      None             1.278   \n",
       "7              4.86                      None             1.414   \n",
       "8              3.86                      None             1.504   \n",
       "9              3.80                      None             2.039   \n",
       "10            59.86                      None             0.903   \n",
       "11            29.87                      None             1.250   \n",
       "12            10.00                      None             2.036   \n",
       "13             4.80                      None             2.275   \n",
       "14            35.31                      None             2.976   \n",
       "15             4.57                      None             0.441   \n",
       "16             3.16                      None             0.755   \n",
       "17            10.07                      None             1.450   \n",
       "18           187.25                      None             1.903   \n",
       "19            34.57                      None             2.275   \n",
       "20            34.00                      None             0.789   \n",
       "21             3.71                      None             0.969   \n",
       "22            30.25                      None             1.321   \n",
       "23            13.91                      None             1.531   \n",
       "24             7.07                      None             2.521   \n",
       "25            49.45                      None             0.547   \n",
       "26            10.92                      None             1.821   \n",
       "27            33.14                      None             2.307   \n",
       "28            10.71                      None             2.366   \n",
       "29             4.73                      None             2.817   \n",
       "\n",
       "   ultima_medicion ClusterID  Centroide_LAT  Centroide_LON  \n",
       "0       2025-01-17    C00002     -46.438652     -68.577977  \n",
       "1       2025-05-22    C00002     -46.438652     -68.577977  \n",
       "2       2025-07-23    C00002     -46.438652     -68.577977  \n",
       "3       2025-08-11    C00002     -46.438652     -68.577977  \n",
       "4       2025-07-17    C00002     -46.438652     -68.577977  \n",
       "5       2025-09-12    C00003     -46.403392     -68.562792  \n",
       "6       2025-09-05    C00003     -46.403392     -68.562792  \n",
       "7       2025-09-12    C00003     -46.403392     -68.562792  \n",
       "8       2025-09-11    C00003     -46.403392     -68.562792  \n",
       "9       2025-09-10    C00003     -46.403392     -68.562792  \n",
       "10      2024-08-07    C00010     -46.467081     -68.524865  \n",
       "11      2025-02-18    C00010     -46.467081     -68.524865  \n",
       "12      2025-08-25    C00010     -46.467081     -68.524865  \n",
       "13      2025-09-12    C00010     -46.467081     -68.524865  \n",
       "14      2025-04-30    C00010     -46.467081     -68.524865  \n",
       "15      2025-08-29    C00009     -46.452249     -68.679064  \n",
       "16      2025-09-10    C00009     -46.452249     -68.679064  \n",
       "17      2025-07-24    C00009     -46.452249     -68.679064  \n",
       "18      2023-12-28    C00009     -46.452249     -68.679064  \n",
       "19      2025-01-31    C00009     -46.452249     -68.679064  \n",
       "20      2025-02-05    C00004     -46.396247     -68.601993  \n",
       "21      2025-09-08    C00004     -46.396247     -68.601993  \n",
       "22      2025-06-02    C00004     -46.396247     -68.601993  \n",
       "23      2025-07-04    C00004     -46.396247     -68.601993  \n",
       "24      2025-08-21    C00004     -46.396247     -68.601993  \n",
       "25      2025-01-02    C00002     -46.437632     -68.552173  \n",
       "26      2025-07-22    C00002     -46.437632     -68.552173  \n",
       "27      2025-02-11    C00002     -46.437632     -68.552173  \n",
       "28      2025-06-23    C00002     -46.437632     -68.552173  \n",
       "29      2025-09-05    C00002     -46.437632     -68.552173  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel generado: C:\\Users\\ry16123\\Downloads\\Ultimo (ORIGINAL) TABLERO PRODUCCIÓN FLUG S.A 2025 (1)_CRONOGRAMA_20250928_(12).xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================\n",
    "# Monocelda Jupyter: Planificador + Harness + Runner\n",
    "# ============================================\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, unicodedata, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# CONFIG por defecto (se sobreescriben en el runner)\n",
    "# ==========================\n",
    "INPUT_FILE  = r\"DIAGRAMA SW.xlsx\"   # Excel base (NO se modifica)\n",
    "SHEET_HIST  = None                  # None => autodetecta hoja/encabezados\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "# Radio en km para agrupar por cercanía\n",
    "RADIUS_KM = 3.0\n",
    "# Filtro mínimo de potencial\n",
    "RM3D_MIN = 0.1\n",
    "\n",
    "# Umbrales para fuzzy (si se usan)\n",
    "FUZZY_REPLACE_THRESHOLD = 85\n",
    "FUZZY_SUGGEST_THRESHOLD = 75\n",
    "LETTERS_SIMILARITY_MIN  = 80\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"equipos_activos\": 4,                 # 1..4\n",
    "    \"dias_por_semana\": 5,                 # 5 o 6\n",
    "    \"semanas_plan\": 2,                    # para probar rápido en Jupyter\n",
    "    \"k_visitas\": 1,                       # tasas (K=1 por pedido)\n",
    "    \"max_pozos_dia_equipo\": 10,           # cupo por día por equipo\n",
    "    \"max_pozos_por_cluster\": 5,           # tamaño de clúster (K fijo si usás lógica de clústeres fijos)\n",
    "    \"m3_por_visita_objetivo\": 2.0,        # informativo\n",
    "    \"min_dias_freq\": 7,                   # 1 semana\n",
    "    \"max_dias_freq\": 56,                  # 8 semanas\n",
    "    \"dias_asumidos_una_visita\": 7,        # para r si hay 1 sola visita\n",
    "    \"freq_dias_ultimo_cero_valido\": 30,\n",
    "\n",
    "    # Semillas a evaluar (si se usa lógica de semillas)\n",
    "    \"top_semillas_eval\": 30,\n",
    "\n",
    "    # Control de clústeres por día y backfill (si se usa lógica por semilla)\n",
    "    \"clusters_por_dia_max\": None,\n",
    "    \"backfill_nearest_cluster\": True,\n",
    "    \"umbral_km_backfill\": 5.0,\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Utils\n",
    "# ==========================\n",
    "def _norm(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = s.replace(\"³\", \"3\")\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip().replace(\"\\xa0\",\" \")\n",
    "    s = s.replace(\"_\",\" \").replace(\"-\",\" \").replace(\".\",\" \").replace(\"\\n\",\" \")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _pozo_key(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return \"\".join(ch for ch in s if ch.isalnum()).upper()\n",
    "\n",
    "def _canonical_digits(d: str) -> str:\n",
    "    d = (d or \"\").lstrip(\"0\")\n",
    "    return d if d != \"\" else \"0\"\n",
    "\n",
    "def _letters_digits_from_key_both(k: str):\n",
    "    raw_digits = \"\".join(re.findall(r\"\\d+\", k))\n",
    "    digits_canon = _canonical_digits(raw_digits)\n",
    "    letters = re.sub(r\"\\d+\", \"\", k)\n",
    "    return letters, digits_canon, len(raw_digits)\n",
    "\n",
    "def _ratio_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _fuzzy_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.partial_ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _canon_prefix_pozo(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return s\n",
    "    raw = str(s).strip()\n",
    "    raw_up = raw.upper()\n",
    "    if raw_up.startswith(\"CÑE\"):\n",
    "        return \"CNE\" + raw_up[3:]\n",
    "    raw_ascii = unicodedata.normalize(\"NFKD\", raw_up).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    if raw_ascii.startswith(\"CNE\"):\n",
    "        return raw_ascii\n",
    "    if raw_ascii.startswith(\"CN\"):\n",
    "        return \"CNE\" + raw_ascii[2:]\n",
    "    m = re.match(r\"^CE(\\d+)$\", raw_ascii)\n",
    "    if m:\n",
    "        return \"CNE\" + m.group(1)\n",
    "    return raw_ascii\n",
    "\n",
    "def next_monday(d=None):\n",
    "    d = d or date.today()\n",
    "    return d + timedelta(days=(7 - d.weekday()) % 7)  # 0=Lunes\n",
    "\n",
    "def unique_output_path(base_input_path: str) -> str:\n",
    "    folder = os.path.dirname(os.path.abspath(base_input_path))\n",
    "    stem   = os.path.splitext(os.path.basename(base_input_path))[0]\n",
    "    today  = datetime.now().strftime(\"%Y%m%d\")\n",
    "    base   = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}.xlsx\")\n",
    "    if not os.path.exists(base): return base\n",
    "    i = 2\n",
    "    while True:\n",
    "        cand = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}_({i}).xlsx\")\n",
    "        if not os.path.exists(cand): return cand\n",
    "        i += 1\n",
    "\n",
    "EXPECTED_KEYS = {\n",
    "    \"fecha\":       [\"fecha\"],\n",
    "    \"pozo\":        [\"pozo\"],\n",
    "    \"zona\":        [\"zona\"],\n",
    "    \"bateria\":     [\"bateria\", \"batería\"],\n",
    "    \"m3\":          [\"m3 bruta\",\"m3\",\"m3_bruta\",\"m3bruta\",\"m 3 bruta\",\"m 3\",\"m3 bruto\",\"m3 recuperado\",\"m3 recupero\"],\n",
    "    \"carreras\":    [\"n de carreras\",\"n° de carreras\",\"nº de carreras\",\"no de carreras\",\"nro de carreras\",\"numero de carreras\",\"n° carreras\",\"n de carrera\",\"n carreras\"],\n",
    "    \"nivel_final\": [\"nivel final pozo\",\"nivel final\",\"nivel final del pozo\"],\n",
    "    \"obs_pozo\":    [\"observaciones del pozo\",\"observaciones\",\"comentarios\",\"comentario\"]\n",
    "}\n",
    "\n",
    "def _find_header_row(df_raw):\n",
    "    for i in range(min(200, len(df_raw))):\n",
    "        row_norm = [_norm(x) for x in df_raw.iloc[i,:].tolist()]\n",
    "        if not row_norm:\n",
    "            continue\n",
    "        colmap = {v:j for v,j in zip(row_norm, range(len(row_norm)))}\n",
    "        def has_any(keys): return any(k in colmap for k in keys)\n",
    "        if has_any(EXPECTED_KEYS[\"fecha\"]) and has_any(EXPECTED_KEYS[\"pozo\"]) and has_any(EXPECTED_KEYS[\"zona\"]) and has_any(EXPECTED_KEYS[\"bateria\"]):\n",
    "            return i, row_norm\n",
    "    return None, None\n",
    "\n",
    "# ---------- Nombres pozo ----------\n",
    "def load_pozo_dictionary(xlsx_path: str):\n",
    "    try:\n",
    "        ref = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer diccionario de pozos: {xlsx_path}\\n{e}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    cols = {c.lower().strip(): c for c in ref.columns}\n",
    "    if \"nombre_corto_pozo\" not in cols:\n",
    "        print(f\"\\n[AVISO] El diccionario no tiene la columna 'nombre_corto_pozo'. Columnas: {list(ref.columns)}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    c_pozo = cols[\"nombre_corto_pozo\"]\n",
    "    c_met  = cols.get(\"met_prod\")\n",
    "    c_n3   = cols.get(\"nivel_3\")\n",
    "    c_n5   = cols.get(\"nivel_5\")\n",
    "    c_est  = cols.get(\"estado\")\n",
    "\n",
    "    refv = ref.loc[ref[c_pozo].notna()].copy()\n",
    "    refv[c_pozo] = refv[c_pozo].astype(str).str.strip()\n",
    "\n",
    "    of_list  = refv[c_pozo].tolist()\n",
    "    met_vals = refv[c_met].astype(str).str.strip() if c_met else np.nan\n",
    "    n3_vals  = refv[c_n3].astype(str).str.strip()  if c_n3 else np.nan\n",
    "    n5_vals  = refv[c_n5].astype(str).str.strip()  if c_n5 else np.nan\n",
    "    est_vals = refv[c_est].astype(str).str.strip() if c_est else np.nan\n",
    "\n",
    "    keys, letters_, digits_canon_, digits_len_ = [], [], [], []\n",
    "    for val in of_list:\n",
    "        k = _pozo_key(val)\n",
    "        L, Dcanon, Dlen = _letters_digits_from_key_both(k)\n",
    "        keys.append(k); letters_.append(L); digits_canon_.append(Dcanon); digits_len_.append(Dlen)\n",
    "\n",
    "    dict_df = pd.DataFrame({\n",
    "        \"oficial\": of_list,\n",
    "        \"key\": keys,\n",
    "        \"letters\": letters_,\n",
    "        \"digits_canon\": digits_canon_,\n",
    "        \"digits_len\": digits_len_,\n",
    "        \"met_prod\": list(met_vals) if isinstance(met_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_3\":  list(n3_vals)  if isinstance(n3_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_5\":  list(n5_vals)  if isinstance(n5_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"estado\":   list(est_vals) if isinstance(est_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "    })\n",
    "\n",
    "    key2off = {}\n",
    "    for k, off in zip(dict_df[\"key\"], dict_df[\"oficial\"]):\n",
    "        if k and k not in key2off:\n",
    "            key2off[k] = off\n",
    "    return key2off, dict_df\n",
    "\n",
    "def apply_pozo_normalization(df: pd.DataFrame, key2off: dict, dict_df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"POZO_ORIG\"] = df[\"POZO\"].astype(str).str.strip()\n",
    "    df[\"POZO_PreCanon\"] = df[\"POZO_ORIG\"].apply(_canon_prefix_pozo)\n",
    "    df[\"__POZO_KEY\"] = df[\"POZO_PreCanon\"].apply(_pozo_key)\n",
    "\n",
    "    parts = df[\"__POZO_KEY\"].apply(_letters_digits_from_key_both)\n",
    "    df[\"__KEY_LET\"], df[\"__KEY_DIG_CANON\"], df[\"__KEY_DIG_LEN\"] = zip(*parts)\n",
    "\n",
    "    df[\"POZO_MATCH\"]   = None\n",
    "    df[\"MATCH_TIPO\"]   = \"NO\"\n",
    "    df[\"MATCH_SCORE\"]  = np.nan\n",
    "    df[\"LETTER_SCORE\"] = np.nan\n",
    "    df[\"APLICADO\"]     = \"NO\"\n",
    "    df[\"ALERTA_NORM\"]  = \"\"\n",
    "    df[\"VALIDO_POZO\"]  = True\n",
    "\n",
    "    invalid_mask = (df[\"__KEY_LET\"].str.len()==0) | (df[\"__KEY_DIG_LEN\"]==0)\n",
    "    if invalid_mask.any():\n",
    "        df.loc[invalid_mask, \"ALERTA_NORM\"] = \"SIN_LETRAS_O_DIGITOS\"\n",
    "        df.loc[invalid_mask, \"VALIDO_POZO\"] = False\n",
    "\n",
    "    valid_mask = ~invalid_mask\n",
    "    exact_mask = valid_mask & df[\"__POZO_KEY\"].isin(key2off.keys())\n",
    "    df.loc[exact_mask, \"POZO_MATCH\"]   = df.loc[exact_mask, \"__POZO_KEY\"].map(key2off)\n",
    "    df.loc[exact_mask, \"MATCH_TIPO\"]   = \"EXACTO\"\n",
    "    df.loc[exact_mask, \"MATCH_SCORE\"]  = 100\n",
    "    df.loc[exact_mask, \"LETTER_SCORE\"] = 100\n",
    "    df.loc[exact_mask, \"APLICADO\"]     = \"SI\"\n",
    "\n",
    "    pending = df[valid_mask & (~exact_mask)].index.tolist()\n",
    "    if pending and not dict_df.empty:\n",
    "        dict_by_spec = {}\n",
    "        for spec, sub in dict_df.groupby([\"digits_canon\",\"digits_len\"]):\n",
    "            dict_by_spec[spec] = sub\n",
    "\n",
    "        for idx in pending:\n",
    "            key_u   = df.at[idx, \"__POZO_KEY\"]\n",
    "            let_u   = df.at[idx, \"__KEY_LET\"]\n",
    "            digc_u  = df.at[idx, \"__KEY_DIG_CANON\"]\n",
    "            digl_u  = int(df.at[idx, \"__KEY_DIG_LEN\"])\n",
    "\n",
    "            cand_df = dict_by_spec.get((digc_u, digl_u), pd.DataFrame())\n",
    "            best_off, best_score, best_lscore = None, -1, -1\n",
    "\n",
    "            if cand_df is not None and not cand_df.empty:\n",
    "                for row in cand_df.itertuples():\n",
    "                    kk = row.key\n",
    "                    ll = row.letters\n",
    "                    sc_key = _fuzzy_score(key_u, kk)\n",
    "                    sc_let = _ratio_score(let_u, ll)\n",
    "                    if sc_let < LETTERS_SIMILARITY_MIN:\n",
    "                        continue\n",
    "                    if sc_key > best_score or (sc_key == best_score and sc_let > best_lscore):\n",
    "                        best_score = sc_key\n",
    "                        best_lscore = sc_let\n",
    "                        best_off   = row.oficial\n",
    "\n",
    "            if best_off is not None:\n",
    "                df.at[idx, \"POZO_MATCH\"]   = best_off\n",
    "                df.at[idx, \"MATCH_TIPO\"]   = \"SUGERIDO\"\n",
    "                df.at[idx, \"MATCH_SCORE\"]  = int(best_score)\n",
    "                df.at[idx, \"LETTER_SCORE\"] = int(best_lscore)\n",
    "            else:\n",
    "                df.at[idx, \"ALERTA_NORM\"] = \"SIN MATCH EN DICCIONARIO\"\n",
    "\n",
    "    # Reemplazos\n",
    "    df[\"POZO\"] = df[\"POZO_MATCH\"].where(df[\"POZO_MATCH\"].notna(), df[\"POZO\"])\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    df = df.merge(meta_first, how=\"left\", left_on=\"POZO\", right_index=True)\n",
    "\n",
    "    # ZONA sólo si hubo match; sino, vacío\n",
    "    if \"nivel_3\" in df.columns:\n",
    "        df.loc[df[\"POZO_MATCH\"].isna(), \"nivel_3\"] = \"\"\n",
    "        df[\"ZONA\"] = np.where(df[\"POZO_MATCH\"].notna(), df[\"nivel_3\"].fillna(\"\"), \"\")\n",
    "\n",
    "    # BATERIA si hay nivel_5\n",
    "    if \"nivel_5\" in df.columns:\n",
    "        df[\"BATERIA\"] = np.where(\n",
    "            df[\"nivel_5\"].notna() & (df[\"nivel_5\"].astype(str).str.strip()!=\"\"),\n",
    "            df[\"nivel_5\"], df[\"BATERIA\"]\n",
    "        )\n",
    "\n",
    "    df[\"__ZONA_NORM\"]    = df[\"ZONA\"].apply(_norm)\n",
    "    df[\"__BATERIA_NORM\"] = df[\"BATERIA\"].apply(_norm)\n",
    "\n",
    "    norm_table = (df[[\"POZO_ORIG\",\"POZO_PreCanon\",\"__POZO_KEY\",\n",
    "                      \"__KEY_LET\",\"__KEY_DIG_CANON\",\"__KEY_DIG_LEN\",\n",
    "                      \"POZO_MATCH\",\"MATCH_TIPO\",\"MATCH_SCORE\",\"LETTER_SCORE\",\n",
    "                      \"APLICADO\",\"ALERTA_NORM\",\"VALIDO_POZO\",\n",
    "                      \"met_prod\",\"nivel_3\",\"nivel_5\"]]\n",
    "                  .drop_duplicates()\n",
    "                  .rename(columns={\n",
    "                      \"POZO_ORIG\":\"Pozo_Original\",\n",
    "                      \"POZO_PreCanon\":\"Pozo_PreCanon\",\n",
    "                      \"__POZO_KEY\":\"Clave_Normalizada\",\n",
    "                      \"__KEY_LET\":\"Letras\",\n",
    "                      \"__KEY_DIG_CANON\":\"Digitos_Canon\",\n",
    "                      \"__KEY_DIG_LEN\":\"Digitos_Len\",\n",
    "                      \"POZO_MATCH\":\"Match_Oficial\",\n",
    "                      \"MATCH_TIPO\":\"Match_Tipo\",\n",
    "                      \"MATCH_SCORE\":\"Match_Score\",\n",
    "                      \"LETTER_SCORE\":\"Letter_Score\",\n",
    "                      \"APLICADO\":\"Aplicado\",\n",
    "                      \"ALERTA_NORM\":\"Alerta\",\n",
    "                      \"VALIDO_POZO\":\"Valido\",\n",
    "                      \"met_prod\":\"met_prod\",\n",
    "                      \"nivel_3\":\"nivel_3\",\n",
    "                      \"nivel_5\":\"nivel_5\"\n",
    "                  })\n",
    "                  .sort_values([\"Valido\",\"Aplicado\",\"Match_Tipo\",\"Pozo_Original\"], ascending=[False, False, True, True]))\n",
    "\n",
    "    alert_table = norm_table[(norm_table[\"Valido\"]==False) | (norm_table[\"Aplicado\"]==\"NO\") | (norm_table[\"Match_Tipo\"]==\"NO\")].copy()\n",
    "    return df, alert_table, norm_table\n",
    "\n",
    "def read_historial(xlsx_path, sheet_hist=None):\n",
    "    xl = pd.ExcelFile(xlsx_path)\n",
    "    sheets = [sheet_hist] if (sheet_hist and sheet_hist in xl.sheet_names) else xl.sheet_names\n",
    "    for sh in sheets:\n",
    "        raw = xl.parse(sh, header=None)\n",
    "        idx, header_norm = _find_header_row(raw)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        data = raw.iloc[idx:, :].copy()\n",
    "        true_headers = data.iloc[0,:].astype(str).tolist()\n",
    "        data = data.iloc[1:,:]\n",
    "        data.columns = true_headers\n",
    "\n",
    "        name_map = {c: _norm(c) for c in data.columns}\n",
    "        def find_col(candidates):\n",
    "            for c, n in name_map.items():\n",
    "                if n in candidates:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        c_fecha       = find_col(set(EXPECTED_KEYS[\"fecha\"]))\n",
    "        c_pozo        = find_col(set(EXPECTED_KEYS[\"pozo\"]))\n",
    "        c_zona        = find_col(set(EXPECTED_KEYS[\"zona\"]))\n",
    "        c_bateria     = find_col(set(EXPECTED_KEYS[\"bateria\"]))\n",
    "        c_m3          = find_col(set(EXPECTED_KEYS[\"m3\"]))\n",
    "        c_carr        = find_col(set(EXPECTED_KEYS[\"carreras\"]))\n",
    "        c_nivel_final = find_col(set(EXPECTED_KEYS[\"nivel_final\"]))\n",
    "        c_obs         = find_col(set(EXPECTED_KEYS[\"obs_pozo\"]))\n",
    "\n",
    "        if not (c_fecha and c_pozo and c_zona and c_bateria):\n",
    "            continue\n",
    "\n",
    "        use_cols = [c_fecha, c_pozo, c_zona, c_bateria]\n",
    "        headers  = [\"FECHA\",\"POZO\",\"ZONA\",\"BATERIA\"]\n",
    "        if c_m3:            use_cols.append(c_m3);            headers.append(\"M3\")\n",
    "        if c_carr:          use_cols.append(c_carr);          headers.append(\"CARRERAS\")\n",
    "        if c_nivel_final:   use_cols.append(c_nivel_final);   headers.append(\"NIVEL_FINAL\")\n",
    "        if c_obs:           use_cols.append(c_obs);           headers.append(\"OBS_POZO\")\n",
    "\n",
    "        df = data[use_cols].copy()\n",
    "        df.columns = headers\n",
    "\n",
    "        df[\"FECHA\"] = pd.to_datetime(df[\"FECHA\"], errors=\"coerce\")\n",
    "        if \"M3\" not in df.columns: df[\"M3\"] = np.nan\n",
    "        else: df[\"M3\"] = pd.to_numeric(df[\"M3\"], errors=\"coerce\")\n",
    "\n",
    "        if \"CARRERAS\" not in df.columns: df[\"CARRERAS\"] = np.nan\n",
    "        else: df[\"CARRERAS\"] = pd.to_numeric(df[\"CARRERAS\"], errors=\"coerce\")\n",
    "\n",
    "        if \"NIVEL_FINAL\" not in df.columns:\n",
    "            df[\"NIVEL_FINAL\"] = None\n",
    "        if \"OBS_POZO\" not in df.columns:\n",
    "            df[\"OBS_POZO\"] = None\n",
    "\n",
    "        for col in [\"POZO\",\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\",\"OBS_POZO\"]:\n",
    "            df[col] = df[col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "        df = df.dropna(subset=[\"FECHA\",\"POZO\"]).sort_values([\"POZO\",\"FECHA\"])\n",
    "        return df\n",
    "\n",
    "    raise ValueError(\"No pude detectar FECHA/POZO/ZONA/BATERÍA en ninguna hoja del Excel.\")\n",
    "\n",
    "def read_exclusions_from_sheet(xlsx_path):\n",
    "    excl = set()\n",
    "    try:\n",
    "        xl = pd.ExcelFile(xlsx_path)\n",
    "        if \"ExcluirPozos\" in xl.sheet_names:\n",
    "            e = xl.parse(\"ExcluirPozos\")\n",
    "            e.columns = [str(c).strip().lower() for c in e.columns]\n",
    "            if \"pozo\" in e.columns:\n",
    "                if \"excluir\" in e.columns:\n",
    "                    excl = set(e.loc[e[\"excluir\"].astype(str).str.upper().isin(\n",
    "                        [\"SI\",\"SÍ\",\"YES\",\"1\",\"TRUE\"]), \"pozo\"].astype(str).str.strip())\n",
    "                else:\n",
    "                    excl = set(e[\"pozo\"].astype(str).str.strip())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return excl\n",
    "\n",
    "# ==========================\n",
    "# Frecuencias / r_m3_d\n",
    "# ==========================\n",
    "def _count_trailing_zeros_with_carr(g):\n",
    "    cnt = 0\n",
    "    for _, row in g.sort_values(\"FECHA\").iloc[::-1].iterrows():\n",
    "        m3 = row.get(\"M3\", np.nan)\n",
    "        car = row.get(\"CARRERAS\", np.nan)\n",
    "        if pd.notna(m3) and float(m3) == 0.0 and pd.notna(car) and float(car) > 0:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    return cnt\n",
    "\n",
    "def compute_frecuencias(df, params):\n",
    "    v_target = params[\"m3_por_visita_objetivo\"]\n",
    "    min_d    = params[\"min_dias_freq\"]\n",
    "    max_d    = params[\"max_dias_freq\"]\n",
    "    k        = int(params[\"k_visitas\"])\n",
    "    one_days = int(params.get(\"dias_asumidos_una_visita\", 7))\n",
    "    freq_cero_ultimo = int(params.get(\"freq_dias_ultimo_cero_valido\", 30))\n",
    "\n",
    "    out = []\n",
    "    for pozo, g0 in df.groupby(\"POZO\", sort=False):\n",
    "        g = g0.sort_values(\"FECHA\").copy()\n",
    "\n",
    "        for col in [\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\"]:\n",
    "            if col in g.columns:\n",
    "                g[col] = g[col].replace({None: np.nan})\n",
    "                g[col] = g[col].ffill().bfill()\n",
    "\n",
    "        g[\"__ZONA_NORM\"]    = g[\"ZONA\"].apply(_norm)\n",
    "        g[\"__BATERIA_NORM\"] = g[\"BATERIA\"].apply(_norm)\n",
    "        g[\"__nf_norm\"]      = g[\"NIVEL_FINAL\"].apply(_norm) if \"NIVEL_FINAL\" in g.columns else \"\"\n",
    "\n",
    "        med_validas_all = g[g[\"M3\"].notna()].copy()\n",
    "\n",
    "        m3_eq0 = g[\"M3\"].fillna(0) == 0\n",
    "        carr   = g.get(\"CARRERAS\", pd.Series(index=g.index, dtype=float)).fillna(np.nan)\n",
    "        zero_cond_a = m3_eq0 & (carr.fillna(0) >= 1)\n",
    "        zero_cond_b = m3_eq0 & ((carr.isna()) | (carr.fillna(0) == 0)) & (g[\"__nf_norm\"] == \"surge\")\n",
    "        cond_cero_valido = zero_cond_a | zero_cond_b\n",
    "\n",
    "        validas_rate = g[(g[\"M3\"] > 0) | cond_cero_valido].copy()\n",
    "        zeros_tail = _count_trailing_zeros_with_carr(g)\n",
    "\n",
    "        ultima_med = med_validas_all[\"FECHA\"].max() if not med_validas_all.empty else pd.NaT\n",
    "        ultima_exi = g.loc[g[\"M3\"]>0, \"FECHA\"].max() if \"M3\" in g.columns and not g[g[\"M3\"]>0].empty else pd.NaT\n",
    "\n",
    "        last_zero_valido = False\n",
    "        if not med_validas_all.empty:\n",
    "            idx_last = med_validas_all[\"FECHA\"].idxmax()\n",
    "            m3_last  = g.at[idx_last, \"M3\"]\n",
    "            if pd.notna(m3_last) and float(m3_last) == 0.0:\n",
    "                try:\n",
    "                    last_zero_valido = bool(cond_cero_valido.loc[idx_last])\n",
    "                except Exception:\n",
    "                    last_zero_valido = False\n",
    "\n",
    "        alerta = \"\"\n",
    "        if last_zero_valido:\n",
    "            alerta = f\"ULTIMA_M3_0_VALIDO -> FREQ {freq_cero_ultimo}D\"\n",
    "        elif pd.notna(ultima_med):\n",
    "            if zeros_tail > 0:\n",
    "                alerta = f\"ALERTA: {zeros_tail} cero(s) consecutivo(s) con Carreras>0\"\n",
    "\n",
    "        # r_m3_d\n",
    "        r = np.nan\n",
    "        if not validas_rate.empty:\n",
    "            v = validas_rate.copy()\n",
    "            v[\"delta_d\"] = v[\"FECHA\"].diff().dt.days\n",
    "            v.loc[v[\"delta_d\"] <= 0, \"delta_d\"] = np.nan\n",
    "            v[\"rate\"] = v[\"M3\"].fillna(0) / v[\"delta_d\"]\n",
    "            rates = v[\"rate\"].dropna()\n",
    "            if len(rates) >= 1:\n",
    "                r = rates.tail(min(k, len(rates))).mean()\n",
    "            else:\n",
    "                row = v.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "        else:\n",
    "            if len(med_validas_all) == 1:\n",
    "                row = med_validas_all.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "\n",
    "        # FRECUENCIA\n",
    "        if last_zero_valido:\n",
    "            delta = int(freq_cero_ultimo)\n",
    "        else:\n",
    "            if pd.isna(r):      delta = 7\n",
    "            elif r <= 0:        delta = max_d\n",
    "            else:\n",
    "                delta = max(min_d, min(max_d, float(v_target)/float(r)))\n",
    "                delta = int(7 * round(delta / 7.0))\n",
    "                if delta < 7:\n",
    "                    delta = 7\n",
    "\n",
    "        prox = (ultima_med + pd.Timedelta(days=int(delta))) if pd.notna(ultima_med) else pd.Timestamp(next_monday())\n",
    "\n",
    "        out.append({\n",
    "            \"POZO\": pozo,\n",
    "            \"ZONA\": g[\"ZONA\"].iloc[-1],\n",
    "            \"BATERIA\": g[\"BATERIA\"].iloc[-1],\n",
    "            \"ZONA_NORM\": g[\"__ZONA_NORM\"].iloc[-1],\n",
    "            \"BATERIA_NORM\": g[\"__BATERIA_NORM\"].iloc[-1],\n",
    "            \"r_m3_d\": r,\n",
    "            \"ultima_medicion\": ultima_med,\n",
    "            \"ultima_exitosa\": ultima_exi,\n",
    "            \"delta_star_dias\": int(delta),\n",
    "            \"proxima_visita_base\": prox,\n",
    "            \"ceros_consec\": zeros_tail,\n",
    "            \"alerta\": alerta\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# ==========================\n",
    "# Coordenadas\n",
    "# ==========================\n",
    "def _to_float_maybe_comma(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if s == \"\": return np.nan\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def read_coords(xlsx_path):\n",
    "    try:\n",
    "        cdf = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer coordenadas: {xlsx_path}\\n{e}\\n\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    cols_map = {c.lower().strip(): c for c in cdf.columns}\n",
    "    c_pozo = cols_map.get(\"pozo\")\n",
    "    for k in [\"geo_latitude\",\"latitude\",\"lat\"]:\n",
    "        if k in cols_map:\n",
    "            c_lat = cols_map[k]; break\n",
    "    else:\n",
    "        c_lat = None\n",
    "    for k in [\"geo_longitude\",\"longitude\",\"lon\",\"long\"]:\n",
    "        if k in cols_map:\n",
    "            c_lon = cols_map[k]; break\n",
    "    else:\n",
    "        c_lon = None\n",
    "\n",
    "    if not (c_pozo and c_lat and c_lon):\n",
    "        print(f\"[AVISO] Coordenadas: columnas esperadas 'POZO','GEO_LATITUDE','GEO_LONGITUDE'. Columnas encontradas: {list(cdf.columns)}\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "\n",
    "    out = cdf[[c_pozo, c_lat, c_lon]].copy()\n",
    "    out.columns = [\"POZO\",\"LAT\",\"LON\"]\n",
    "    out[\"POZO\"] = out[\"POZO\"].astype(str).str.strip()\n",
    "    out[\"LAT\"] = out[\"LAT\"].apply(_to_float_maybe_comma)\n",
    "    out[\"LON\"] = out[\"LON\"].apply(_to_float_maybe_comma)\n",
    "    out = out.dropna(subset=[\"POZO\"])\n",
    "    out = out.drop_duplicates(subset=[\"POZO\"], keep=\"last\")\n",
    "    return out\n",
    "\n",
    "# ==========================\n",
    "# Candidatos y utilidades\n",
    "# ==========================\n",
    "def build_candidates_with_coords(freq, week_start, week_end, excl_pozos,\n",
    "                                 zonas_norm_incluidas, coords_df,\n",
    "                                 allowed_bats_by_zone_norm=None,\n",
    "                                 next_due_map=None):\n",
    "    F = freq.copy()\n",
    "\n",
    "    # due_date base (permitimos override con next_due_map)\n",
    "    F[\"due_date\"] = F[\"proxima_visita_base\"]\n",
    "    if next_due_map:\n",
    "        F[\"due_date\"] = F[\"POZO\"].map(next_due_map).fillna(F[\"due_date\"])\n",
    "\n",
    "    F[\"overdue_d\"] = (pd.Timestamp(week_start) - pd.to_datetime(F[\"due_date\"])).dt.days\n",
    "    F[\"is_overdue\"] = F[\"overdue_d\"] > 0\n",
    "\n",
    "    # prioridad\n",
    "    F[\"__v\"] = F[\"r_m3_d\"].astype(float)\n",
    "\n",
    "    # Filtro por ZONA (normalizada)\n",
    "    if \"ZONA_NORM\" in F.columns and zonas_norm_incluidas:\n",
    "        F = F[F[\"ZONA_NORM\"].isin(zonas_norm_incluidas)].copy()\n",
    "\n",
    "    # Sub-filtro por BATERÍA (si corresponde)\n",
    "    if allowed_bats_by_zone_norm:\n",
    "        mask = pd.Series(True, index=F.index)\n",
    "        for zn in zonas_norm_incluidas:\n",
    "            bats = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats is not None:\n",
    "                mask &= ~ (F[\"ZONA_NORM\"] == zn) | (F[\"BATERIA_NORM\"].isin(bats))\n",
    "        F = F[mask].copy()\n",
    "\n",
    "    # Exclusiones\n",
    "    if excl_pozos:\n",
    "        F = F[~F[\"POZO\"].isin(excl_pozos)].copy()\n",
    "\n",
    "    # Potencial mínimo y BATERÍA no vacía\n",
    "    F = F[F[\"r_m3_d\"].fillna(0) > RM3D_MIN].copy()\n",
    "    F = F[F[\"BATERIA\"].notna() & (F[\"BATERIA\"].astype(str).str.strip() != \"\")].copy()\n",
    "\n",
    "    # Excluir pozos con comentario no vacío en Frecuencias\n",
    "    if \"comentario\" in F.columns:\n",
    "        F[\"__comentario_txt\"] = F[\"comentario\"].astype(str).fillna(\"\").str.strip()\n",
    "        F = F[F[\"__comentario_txt\"] == \"\"].copy()\n",
    "        F.drop(columns=[\"__comentario_txt\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Merge coordenadas\n",
    "    coords_df = coords_df if coords_df is not None else pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    F = F.merge(coords_df, how=\"left\", on=\"POZO\")\n",
    "    F[\"has_coords\"] = F[\"LAT\"].notna() & F[\"LON\"].notna()\n",
    "\n",
    "    # Orden base\n",
    "    F = F.sort_values(by=[\"is_overdue\",\"__v\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    return F\n",
    "\n",
    "def _v_est_for_day(row, day_date):\n",
    "    r = row.get(\"r_m3_d\", np.nan)\n",
    "    u = row.get(\"ultima_medicion\", pd.NaT)\n",
    "    if pd.isna(u) or pd.isna(r) or r <= 0:\n",
    "        return 0.0\n",
    "    dd = max(0, (pd.Timestamp(day_date) - pd.Timestamp(u)).days)\n",
    "    return max(0.0, float(r) * float(dd))\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "            return np.nan\n",
    "        R = 6371.0088\n",
    "        p1 = math.radians(float(lat1)); p2 = math.radians(float(lat2))\n",
    "        dphi = math.radians(float(lat2) - float(lat1))\n",
    "        dlmb = math.radians(float(lon2) - float(lon1))\n",
    "        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "        return 2*R*math.asin(math.sqrt(a))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ==========================\n",
    "# NUEVA LÓGICA DE CLÚSTERES (según prompt)\n",
    "# ==========================\n",
    "def _bbox_filter(df, lat0, lon0, rad_km):\n",
    "    \"\"\"Bounding-box previo a haversine para acotar vecinos.\"\"\"\n",
    "    if pd.isna(lat0) or pd.isna(lon0) or df.empty:\n",
    "        return df.iloc[0:0]\n",
    "    dlat = rad_km / 110.574\n",
    "    dlon = rad_km / (111.320 * max(0.1, math.cos(math.radians(float(lat0)))))\n",
    "    return df[(df[\"LAT\"].between(lat0 - dlat, lat0 + dlat)) &\n",
    "              (df[\"LON\"].between(lon0 - dlon, lon0 + dlon))].copy()\n",
    "\n",
    "def _cluster_centroid(lat_list, lon_list):\n",
    "    if not lat_list or not lon_list:\n",
    "        return (np.nan, np.nan)\n",
    "    return float(np.mean(lat_list)), float(np.mean(lon_list))\n",
    "\n",
    "def _validate_cluster_by_centroid(lat_list, lon_list, radius_km):\n",
    "    c_lat, c_lon = _cluster_centroid(lat_list, lon_list)\n",
    "    if pd.isna(c_lat) or pd.isna(c_lon):\n",
    "        return False, (np.nan, np.nan), np.inf\n",
    "    dmax = 0.0\n",
    "    for la, lo in zip(lat_list, lon_list):\n",
    "        d = haversine_km(c_lat, c_lon, la, lo)\n",
    "        if pd.isna(d) or d > radius_km + 1e-9:\n",
    "            return False, (c_lat, c_lon), np.inf\n",
    "        dmax = max(dmax, d)\n",
    "    return True, (c_lat, c_lon), dmax\n",
    "\n",
    "def build_all_clusters(\n",
    "    cands: pd.DataFrame,\n",
    "    K: int,\n",
    "    radius_km: float,\n",
    "    score_mode: str = \"rm3d\",\n",
    "    top_seeds: int = 30\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve DF con:\n",
    "    ['ClusterID','POZOS','Centroide_LAT','Centroide_LON','Score','ZONA','BATERIAS']\n",
    "    - Exactamente K pozos por clúster\n",
    "    - Validación: todos a <= radius_km del CENTROIDE\n",
    "    - Overlap permitido en generación\n",
    "    - Semillas: mejores 'top_seeds' por __v\n",
    "    - Elimina duplicados exactos (mismo conjunto de pozos)\n",
    "    \"\"\"\n",
    "    if cands.empty:\n",
    "        return pd.DataFrame(columns=[\"ClusterID\",\"POZOS\",\"Centroide_LAT\",\"Centroide_LON\",\"Score\",\"ZONA\",\"BATERIAS\"])\n",
    "\n",
    "    # trabajar solo con pozos con coords\n",
    "    base = cands[cands[\"has_coords\"]].copy()\n",
    "    if base.empty:\n",
    "        return pd.DataFrame(columns=[\"ClusterID\",\"POZOS\",\"Centroide_LAT\",\"Centroide_LON\",\"Score\",\"ZONA\",\"BATERIAS\"])\n",
    "\n",
    "    base = base.sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    seeds = base.head(max(1, int(top_seeds))).copy()\n",
    "\n",
    "    clusters = []\n",
    "    seen_sets = set()  # para deduplicar por conjunto de pozos\n",
    "    for _, seed in seeds.iterrows():\n",
    "        s_lat, s_lon = seed[\"LAT\"], seed[\"LON\"]\n",
    "        neigh = _bbox_filter(base, s_lat, s_lon, radius_km)\n",
    "        if neigh.empty:\n",
    "            continue\n",
    "        # Orden por valor y cercanía a la semilla\n",
    "        neigh = neigh.copy()\n",
    "        neigh[\"__dist_seed\"] = neigh.apply(lambda r: haversine_km(s_lat, s_lon, r[\"LAT\"], r[\"LON\"]), axis=1)\n",
    "        neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "        neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "        # Tomar candidatos top K alrededor de la semilla (semilla incluida)\n",
    "        if seed[\"POZO\"] not in neigh[\"POZO\"].values:\n",
    "            # asegurar que la semilla esté\n",
    "            neigh = pd.concat([pd.DataFrame([seed]), neigh], ignore_index=True)\n",
    "            neigh = neigh.drop_duplicates(subset=[\"POZO\"], keep=\"first\")\n",
    "\n",
    "        if len(neigh) < K:\n",
    "            # no alcanza tamaño K dentro del radio de la semilla\n",
    "            continue\n",
    "\n",
    "        # Probar ventana de los top K mejor valuados dentro del radio\n",
    "        topk = neigh.head(K).copy()\n",
    "        pozos = tuple(topk[\"POZO\"].tolist())\n",
    "        lats  = topk[\"LAT\"].tolist()\n",
    "        lons  = topk[\"LON\"].tolist()\n",
    "\n",
    "        ok, (c_lat, c_lon), dmax = _validate_cluster_by_centroid(lats, lons, radius_km)\n",
    "        if not ok:\n",
    "            # Intentar ajustar: expandir lista ordenada y mover una ventana sobre los N mejores vecinos\n",
    "            N = min(len(neigh), K + 10)  # ventana corta para evitar combinatoria\n",
    "            window = neigh.head(N).copy()\n",
    "            found = False\n",
    "            # estrategia greedy: fijar semilla y tomar los K-1 mejores por __v que cumplan centroide\n",
    "            # probando reemplazos simples si no valida\n",
    "            for i in range(0, N-K+1):\n",
    "                cand = window.iloc[i:i+K]\n",
    "                lats2 = cand[\"LAT\"].tolist(); lons2 = cand[\"LON\"].tolist()\n",
    "                ok2, (c_lat2, c_lon2), _ = _validate_cluster_by_centroid(lats2, lons2, radius_km)\n",
    "                if ok2:\n",
    "                    topk = cand.copy()\n",
    "                    c_lat, c_lon = c_lat2, c_lon2\n",
    "                    pozos = tuple(topk[\"POZO\"].tolist())\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                continue  # no se pudo validar centroide\n",
    "\n",
    "        # dedupe exacto por set\n",
    "        key_set = frozenset(pozos)\n",
    "        if key_set in seen_sets:\n",
    "            continue\n",
    "        seen_sets.add(key_set)\n",
    "\n",
    "        # Score: rm3d o vest (hook)\n",
    "        if score_mode == \"vest\":\n",
    "            # si se usa vest, en generación no sabemos el día; dejamos rm3d como aproximación\n",
    "            score = float(topk[\"r_m3_d\"].fillna(0).sum())\n",
    "        else:\n",
    "            score = float(topk[\"r_m3_d\"].fillna(0).sum())\n",
    "\n",
    "        # ZONA/BATERIAS: mayoritaria (o homogénea si ya lo está)\n",
    "        zona_mode = topk[\"ZONA\"].mode()\n",
    "        zona_val = zona_mode.iloc[0] if not zona_mode.empty else \"\"\n",
    "        bats = tuple(sorted(set(str(x) for x in topk[\"BATERIA\"].fillna(\"\").astype(str))))\n",
    "\n",
    "        clusters.append({\n",
    "            \"ClusterID\": f\"C{len(seen_sets):05d}\",\n",
    "            \"POZOS\": pozos,\n",
    "            \"Centroide_LAT\": float(c_lat),\n",
    "            \"Centroide_LON\": float(c_lon),\n",
    "            \"Score\": score,\n",
    "            \"ZONA\": zona_val,\n",
    "            \"BATERIAS\": bats\n",
    "        })\n",
    "\n",
    "    cldf = pd.DataFrame(clusters)\n",
    "    if cldf.empty:\n",
    "        return cldf\n",
    "    cldf = cldf.sort_values(\"Score\", ascending=False).reset_index(drop=True)\n",
    "    return cldf\n",
    "\n",
    "\n",
    "def select_clusters_for_day(\n",
    "    clusters_df: pd.DataFrame,\n",
    "    used_today: set[str],\n",
    "    cap_pozos: int,\n",
    "    backfill_nearest: bool,\n",
    "    umbral_km_backfill: float,\n",
    "    clusters_por_dia_max: Optional[int] = None,\n",
    "    K: int = 5\n",
    ") -> list[dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Devuelve lista de dicts: {'POZOS', 'ClusterID', 'Centroide_LAT', 'Centroide_LON', 'Score'}\n",
    "    - Greedy por Score desc.\n",
    "    - No repetir pozos del día.\n",
    "    - Respetar clusters_por_dia_max y cap_pozos (multiplo de K).\n",
    "    - Si backfill_nearest=True: exigir distancia del centroide nuevo al centroide acumulado ≤ umbral.\n",
    "    \"\"\"\n",
    "    if clusters_df is None or clusters_df.empty:\n",
    "        return []\n",
    "\n",
    "    selected = []\n",
    "    pozos_usados = set(used_today)\n",
    "    cap_left = int(cap_pozos)\n",
    "    max_clusters = int(clusters_por_dia_max) if clusters_por_dia_max is not None else None\n",
    "\n",
    "    # centroide acumulado del día (promedio incremental)\n",
    "    c_lat_acc, c_lon_acc, n_acc = (np.nan, np.nan, 0)\n",
    "\n",
    "    def _update_centroid_acc(lat, lon):\n",
    "        nonlocal c_lat_acc, c_lon_acc, n_acc\n",
    "        if pd.isna(lat) or pd.isna(lon): \n",
    "            return\n",
    "        if n_acc == 0:\n",
    "            c_lat_acc, c_lon_acc, n_acc = float(lat), float(lon), 1\n",
    "        else:\n",
    "            c_lat_acc = (c_lat_acc*n_acc + float(lat)) / (n_acc + 1)\n",
    "            c_lon_acc = (c_lon_acc*n_acc + float(lon)) / (n_acc + 1)\n",
    "            n_acc += 1\n",
    "\n",
    "    for _, row in clusters_df.iterrows():\n",
    "        if cap_left < K:\n",
    "            break\n",
    "        if max_clusters is not None and len(selected) >= max_clusters:\n",
    "            break\n",
    "\n",
    "        pozos = set(row[\"POZOS\"])\n",
    "        if pozos & pozos_usados:\n",
    "            # contiene pozo ya tomado hoy\n",
    "            continue\n",
    "\n",
    "        if backfill_nearest and len(selected) >= 1 and not (pd.isna(c_lat_acc) or pd.isna(c_lon_acc)):\n",
    "            dcc = haversine_km(c_lat_acc, c_lon_acc, row[\"Centroide_LAT\"], row[\"Centroide_LON\"])\n",
    "            if pd.isna(dcc) or dcc > float(umbral_km_backfill) + 1e-9:\n",
    "                continue\n",
    "\n",
    "        selected.append({\n",
    "            \"POZOS\": list(row[\"POZOS\"]),\n",
    "            \"ClusterID\": row[\"ClusterID\"],\n",
    "            \"Centroide_LAT\": float(row[\"Centroide_LAT\"]),\n",
    "            \"Centroide_LON\": float(row[\"Centroide_LON\"]),\n",
    "            \"Score\": float(row[\"Score\"])\n",
    "        })\n",
    "        pozos_usados |= pozos\n",
    "        cap_left -= K\n",
    "        _update_centroid_acc(row[\"Centroide_LAT\"], row[\"Centroide_LON\"])\n",
    "\n",
    "    return selected\n",
    "\n",
    "# ==========================\n",
    "# ASIGNACIÓN SEMANAL ROUND-ROBIN (usando clústeres precomputados)\n",
    "# ==========================\n",
    "def assign_week_round_robin_by_zone(cand_all, team_ids, params, week_start, week_end, radius_km):\n",
    "    \"\"\"\n",
    "    Reparte por día/equipo en una zona, eligiendo clústeres precomputados (no pozos sueltos).\n",
    "    Reglas duras:\n",
    "    - Clúster tamaño exacto K\n",
    "    - Todos los pozos del clúster a ≤ radius_km del centroide (ya validado en build_all_clusters)\n",
    "    - No repetir POZO en el mismo día (entre equipos de la misma zona)\n",
    "    \"\"\"\n",
    "    dias   = int(params[\"dias_por_semana\"])\n",
    "    cap_pz = int(params[\"max_pozos_dia_equipo\"])\n",
    "    K      = int(params.get(\"max_pozos_por_cluster\", 4))\n",
    "    backfill_nearest = bool(params.get(\"backfill_nearest_cluster\", True))\n",
    "    umbral_backfill  = float(params.get(\"umbral_km_backfill\", 5.0))\n",
    "    clusters_por_dia_max = params.get(\"clusters_por_dia_max\", None)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # NUEVO: pozos ya usados en la semana (para no repetirlos lunes, martes, ...)\n",
    "    used_week = set()  # <<<\n",
    "\n",
    "    for d in range(dias):\n",
    "        day_date = pd.Timestamp(week_start) + pd.Timedelta(days=d)\n",
    "\n",
    "        # Ventana por DÍA (no por fin de semana) y excluir lo ya usado en la semana\n",
    "        pool_day = cand_all[~cand_all[\"POZO\"].isin(used_week)].copy()  # <<<\n",
    "        in_window = (pd.to_datetime(pool_day[\"due_date\"]) <= pd.Timestamp(day_date)) | pool_day[\"is_overdue\"]\n",
    "        pool_day = pool_day[in_window].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "\n",
    "        # Precomputar TODOS los clústeres de este día y zona (overlap permitido)\n",
    "        clusters_df = build_all_clusters(\n",
    "            cands=pool_day,\n",
    "            K=K,\n",
    "            radius_km=radius_km,\n",
    "            score_mode=\"rm3d\",\n",
    "            top_seeds=int(params.get(\"top_semillas_eval\", 30))\n",
    "        )\n",
    "        if clusters_df.empty:\n",
    "            # no hay clúster válido → ese día pueden quedar huecos\n",
    "            continue\n",
    "\n",
    "        # Greedy por equipo, sin repetir pozos el mismo día entre equipos\n",
    "        used_today = set()\n",
    "        for eq in sorted(team_ids):\n",
    "            chosen = select_clusters_for_day(\n",
    "                clusters_df=clusters_df,\n",
    "                used_today=used_today,\n",
    "                cap_pozos=cap_pz,\n",
    "                backfill_nearest=backfill_nearest,\n",
    "                umbral_km_backfill=umbral_backfill,     # ojo: si tu var se llama umbral_km_backfill, usa ese nombre\n",
    "                clusters_por_dia_max=clusters_por_dia_max,\n",
    "                K=K\n",
    "            )\n",
    "            if not chosen:\n",
    "                continue\n",
    "\n",
    "            # Materializar filas del plan a partir de los clústeres seleccionados\n",
    "            ord_idx = 1\n",
    "            for cluster in chosen:\n",
    "                pozos = cluster[\"POZOS\"]\n",
    "                c_lat = cluster[\"Centroide_LAT\"]\n",
    "                c_lon = cluster[\"Centroide_LON\"]\n",
    "                cid   = cluster[\"ClusterID\"]\n",
    "\n",
    "                # Traer filas originales para info r_m3_d, zona, batería, ultima_medicion\n",
    "                info = pool_day[pool_day[\"POZO\"].isin(pozos)].copy()\n",
    "                info = info.set_index(\"POZO\")\n",
    "\n",
    "                # asserts (criterios de aceptación)\n",
    "                assert len(pozos) == K, f\"Cluster {cid} no tiene tamaño K={K}\"\n",
    "                # distancias al centroide\n",
    "                dists = []\n",
    "                for pz in pozos:\n",
    "                    la = info.at[pz, \"LAT\"]; lo = info.at[pz, \"LON\"]\n",
    "                    d = haversine_km(c_lat, c_lon, la, lo)\n",
    "                    dists.append(d)\n",
    "                    assert (not pd.isna(d)) and d <= radius_km + 1e-6, f\"Pozo {pz} excede radio al centroide en cluster {cid}\"\n",
    "                max_d = float(np.max(dists))  # (no lo usamos pero te queda para log)\n",
    "\n",
    "                # Orden dentro del cluster: por cercanía al centroide, opcional\n",
    "                pozos_sorted = sorted(pozos, key=lambda p: haversine_km(c_lat, c_lon, info.at[p, \"LAT\"], info.at[p, \"LON\"]))\n",
    "\n",
    "                for pz in pozos_sorted:\n",
    "                    rec = info.loc[pz]\n",
    "                    try:\n",
    "                        v_est = _v_est_for_day({\"r_m3_d\": rec.get(\"r_m3_d\", np.nan),\n",
    "                                                \"ultima_medicion\": rec.get(\"ultima_medicion\", pd.NaT)}, day_date)\n",
    "                    except Exception:\n",
    "                        v_est = 0.0\n",
    "\n",
    "                    rows.append({\n",
    "                        \"Plan_Fecha\": day_date.date(),\n",
    "                        \"Semana_ISO\": day_date.isocalendar()[1],\n",
    "                        \"Equipo\": int(eq),\n",
    "                        \"Dia_Idx\": d+1,\n",
    "                        \"Orden\": ord_idx,\n",
    "                        \"ZONA\": rec.get(\"ZONA\",\"\"),\n",
    "                        \"BATERIA\": rec.get(\"BATERIA\",\"\"),\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": float(rec.get(\"__v\", rec.get(\"r_m3_d\", np.nan))),\n",
    "                        \"Vol_Estimado_m3\": round(float(v_est), 2),\n",
    "                        \"Seed_POZO\": \"\",  # ya no trabajamos por semilla en asignación\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": round(float(haversine_km(c_lat, c_lon, rec.get(\"LAT\"), rec.get(\"LON\"))), 3) if not (pd.isna(rec.get(\"LAT\")) or pd.isna(rec.get(\"LON\"))) else None,\n",
    "                        \"ultima_medicion\": rec.get(\"ultima_medicion\", pd.NaT),\n",
    "                        # Nuevas columnas informativas del cluster:\n",
    "                        \"ClusterID\": cid,\n",
    "                        \"Centroide_LAT\": c_lat,\n",
    "                        \"Centroide_LON\": c_lon,\n",
    "                    })\n",
    "                    ord_idx += 1\n",
    "\n",
    "                # Marcar pozos usados hoy y para el resto de la semana\n",
    "                used_today.update(pozos)\n",
    "                used_week.update(pozos)  # <<<  clave para que no se repitan en martes/miércoles/etc.\n",
    "\n",
    "        # verificación de no duplicación diaria\n",
    "        if rows:\n",
    "            plan_day = pd.DataFrame(rows)\n",
    "            same_day = plan_day[plan_day[\"Plan_Fecha\"] == day_date.date()]\n",
    "            if not same_day.empty:\n",
    "                dup = same_day.groupby([\"Plan_Fecha\",\"POZO\"]).size().max()\n",
    "                assert int(dup) == 1, \"Un pozo se repite el mismo día (violación de regla).\"\n",
    "\n",
    "    cols = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "            \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "            \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\",\n",
    "            \"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\"]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "# (Se elimina la versión anterior _fill_day_star_clusters: ahora ya no se usa.)\n",
    "\n",
    "def ensure_annual_coverage_zone_locked(all_pozos_df, plan, params, start_date, equipo_to_zona,\n",
    "                                       allowed_bats_by_zone_norm=None, r_by_pozo=None):\n",
    "    cap_pz = params[\"max_pozos_dia_equipo\"]\n",
    "\n",
    "    keys = []\n",
    "    for w in range(params[\"semanas_plan\"]):\n",
    "        w_start = start_date + timedelta(weeks=w)\n",
    "        for d in range(params[\"dias_por_semana\"]):\n",
    "            f = w_start + timedelta(days=d)\n",
    "            for e in equipo_to_zona.keys():\n",
    "                keys.append((e, f))\n",
    "\n",
    "    if not plan.empty:\n",
    "        plan[\"__key\"] = plan[\"Equipo\"].astype(int).astype(str) + \"|\" + plan[\"Plan_Fecha\"].astype(str)\n",
    "        used_counts = plan.groupby(\"__key\")[\"POZO\"].count().to_dict()\n",
    "    else:\n",
    "        used_counts = {}\n",
    "\n",
    "    planned = set(plan[\"POZO\"].unique()) if not plan.empty else set()\n",
    "    missing_df = all_pozos_df[~all_pozos_df[\"POZO\"].isin(planned)].copy()\n",
    "    missing_df = missing_df[missing_df[\"BATERIA\"].notna() & (missing_df[\"BATERIA\"].astype(str).str.strip()!=\"\")].copy()\n",
    "\n",
    "    add = []\n",
    "    for _, row in missing_df.iterrows():\n",
    "        pz = row[\"POZO\"]; z = row[\"ZONA\"]\n",
    "        bat = row.get(\"BATERIA\", \"\")\n",
    "\n",
    "        if not isinstance(bat, str) or bat.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            zn = _norm(z)\n",
    "            bats_allowed = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats_allowed is not None:\n",
    "                if _norm(bat) not in bats_allowed:\n",
    "                    continue\n",
    "\n",
    "        if r_by_pozo is not None:\n",
    "            r_val = float(r_by_pozo.get(pz, np.nan))\n",
    "            if not (r_val > RM3D_MIN):\n",
    "                continue\n",
    "\n",
    "        target_teams = [e for e, zona in equipo_to_zona.items() if zona == z]\n",
    "        if not target_teams:\n",
    "            continue\n",
    "        placed = False\n",
    "        for e in target_teams:\n",
    "            for (ee, f) in keys:\n",
    "                if ee != e:\n",
    "                    continue\n",
    "                key = f\"{e}|{f}\"\n",
    "                cnt = used_counts.get(key, 0)\n",
    "                if cnt < cap_pz:\n",
    "                    add.append({\n",
    "                        \"Plan_Fecha\": f,\n",
    "                        \"Semana_ISO\": f.isocalendar()[1],\n",
    "                        \"Equipo\": int(e),\n",
    "                        \"Dia_Idx\": f.weekday()+1,\n",
    "                        \"Orden\": cnt+1,\n",
    "                        \"ZONA\": z,\n",
    "                        \"BATERIA\": bat,\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": np.nan,\n",
    "                        \"Vol_Estimado_m3\": 0.0,\n",
    "                        \"Seed_POZO\": \"\",\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": None,\n",
    "                        \"ultima_medicion\": pd.NaT,\n",
    "                        \"ClusterID\": \"\",\n",
    "                        \"Centroide_LAT\": np.nan,\n",
    "                        \"Centroide_LON\": np.nan,\n",
    "                    })\n",
    "                    used_counts[key] = cnt+1\n",
    "                    placed = True\n",
    "                    break\n",
    "            if placed:\n",
    "                break\n",
    "\n",
    "    if add:\n",
    "        plan = pd.concat([plan, pd.DataFrame(add)], ignore_index=True)                 .sort_values([\"Plan_Fecha\",\"Equipo\",\"Orden\"])\n",
    "    return plan\n",
    "\n",
    "def build_alertas_abm(freq_df: pd.DataFrame, norm_table: pd.DataFrame, dict_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = freq_df[[\"POZO\",\"ZONA\",\"BATERIA\",\"ultima_medicion\",\"ultima_exitosa\"]].copy()\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"estado\",\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    base = base.merge(meta_first[[\"estado\",\"met_prod\"]], left_on=\"POZO\", right_index=True, how=\"left\")\n",
    "\n",
    "    out = base.copy()\n",
    "    for c in [\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "        out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "    out = out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ============================================\n",
    "# HARNES PARA JUPYTER\n",
    "# ============================================\n",
    "def run_pipeline_jupyter(\n",
    "    input_file,\n",
    "    nombres_pozo_file,\n",
    "    coords_file,\n",
    "    *,\n",
    "    semanas_plan=2,\n",
    "    equipos_activos=2,\n",
    "    dias_por_semana=5,\n",
    "    max_pozos_dia_equipo=10,\n",
    "    K_max_pozos_por_cluster=5,\n",
    "    clusters_por_dia_max=None,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,\n",
    "    baterias_por_zona=None,      # {\"las heras cg - canadon escondida\": {\"swabing ce\",\"ce 04\"}}\n",
    "    pozos_excluir=None,\n",
    "    escribir_excel=False\n",
    "):\n",
    "    global INPUT_FILE, NOMBRES_POZO_FILE, COORDS_FILE, RADIUS_KM, RM3D_MIN, DEFAULTS\n",
    "    INPUT_FILE       = input_file\n",
    "    NOMBRES_POZO_FILE= nombres_pozo_file\n",
    "    COORDS_FILE      = coords_file\n",
    "    RADIUS_KM        = float(radius_km)\n",
    "    RM3D_MIN         = float(rm3d_min)\n",
    "\n",
    "    DEFAULTS = DEFAULTS.copy()\n",
    "    DEFAULTS.update({\n",
    "        \"equipos_activos\": int(equipos_activos),\n",
    "        \"dias_por_semana\": int(dias_por_semana),\n",
    "        \"semanas_plan\": int(semanas_plan),\n",
    "        \"max_pozos_dia_equipo\": int(max_pozos_dia_equipo),\n",
    "        \"max_pozos_por_cluster\": int(K_max_pozos_por_cluster),\n",
    "        \"clusters_por_dia_max\": clusters_por_dia_max,\n",
    "        \"backfill_nearest_cluster\": bool(backfill_nearest),\n",
    "        \"umbral_km_backfill\": float(umbral_km_backfill),\n",
    "    })\n",
    "\n",
    "    # 1) Lee historial (Excel del usuario)\n",
    "    df = read_historial(INPUT_FILE, SHEET_HIST)\n",
    "\n",
    "    # 2) Normalización por diccionario\n",
    "    key2off, dict_df = load_pozo_dictionary(NOMBRES_POZO_FILE)\n",
    "    df_norm, alert_table, norm_table = apply_pozo_normalization(df, key2off, dict_df)\n",
    "\n",
    "    # 3) Filtra inválidos\n",
    "    df = df_norm[df_norm[\"VALIDO_POZO\"] == True].copy()\n",
    "\n",
    "    # 4) Filtro por ZONA (si se pide explícito)\n",
    "    if zonas_incluir:\n",
    "        zonas_incluir = set(zonas_incluir)\n",
    "        znorm = {_norm(z) for z in zonas_incluir}\n",
    "        df = df[df[\"__ZONA_NORM\"].isin(znorm)].copy()\n",
    "        zonas_labels = zonas_incluir\n",
    "        zonas_norm   = znorm\n",
    "    else:\n",
    "        mask_valid = df[\"ZONA\"].notna() & (df[\"ZONA\"].astype(str).str.strip() != \"\")\n",
    "        zonas_labels = set(df.loc[mask_valid, \"ZONA\"].astype(str))\n",
    "        zonas_norm   = set(df.loc[mask_valid, \"__ZONA_NORM\"].astype(str))\n",
    "\n",
    "    # 5) Sub-filtro de baterías (si lo pasaste por parámetro)\n",
    "    if baterias_por_zona:\n",
    "        allowed_bats_by_zone_norm = {zn: set(baterias_por_zona[zn]) if baterias_por_zona[zn] is not None else None\n",
    "                                     for zn in baterias_por_zona}\n",
    "    else:\n",
    "        allowed_bats_by_zone_norm = {zn: None for zn in zonas_norm}\n",
    "\n",
    "    # 6) Exclusiones (si te pasan un set)\n",
    "    excl_total = set(pozos_excluir or [])\n",
    "\n",
    "    # 7) Frecuencias\n",
    "    params = DEFAULTS.copy()\n",
    "    freq = compute_frecuencias(df, params)\n",
    "\n",
    "    # Comentarios desde OBS cuando ultima_medicion != ultima_exitosa\n",
    "    df_obs = df[[\"POZO\", \"FECHA\", \"OBS_POZO\"]].copy() if \"OBS_POZO\" in df.columns else pd.DataFrame(columns=[\"POZO\",\"FECHA\",\"OBS_POZO\"])\n",
    "    df_obs[\"FECHA_DATE\"] = pd.to_datetime(df_obs[\"FECHA\"], errors=\"coerce\").dt.date\n",
    "    df_obs = (df_obs.dropna(subset=[\"FECHA_DATE\"])\n",
    "                    .sort_values([\"POZO\",\"FECHA_DATE\"])\n",
    "                    .drop_duplicates(subset=[\"POZO\",\"FECHA_DATE\"], keep=\"last\"))\n",
    "    obs_map = {(r.POZO, r.FECHA_DATE): (str(r.OBS_POZO).strip() if pd.notna(r.OBS_POZO) else \"\")\n",
    "               for r in df_obs.itertuples(index=False)}\n",
    "    freq[\"__UMED_DATE\"] = pd.to_datetime(freq[\"ultima_medicion\"], errors=\"coerce\").dt.date\n",
    "    freq[\"__UEXI_DATE\"] = pd.to_datetime(freq[\"ultima_exitosa\"], errors=\"coerce\").dt.date\n",
    "    freq[\"comentario\"] = [obs_map.get((pz, fmed), \"\") for pz, fmed in zip(freq[\"POZO\"], freq[\"__UMED_DATE\"])]\n",
    "    mask_both_valid = freq[\"__UMED_DATE\"].notna() & freq[\"__UEXI_DATE\"].notna()\n",
    "    mask_diff = mask_both_valid & (freq[\"__UMED_DATE\"] != freq[\"__UEXI_DATE\"])\n",
    "    freq.loc[~mask_diff, \"comentario\"] = \"\"\n",
    "    freq.drop(columns=[\"__UMED_DATE\",\"__UEXI_DATE\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # 8) Coordenadas\n",
    "    coords_df = read_coords(COORDS_FILE)\n",
    "\n",
    "    # 9) Mapas auxiliares\n",
    "    delta_by_pozo = freq.set_index(\"POZO\")[\"delta_star_dias\"].to_dict()\n",
    "    r_by_pozo     = freq.set_index(\"POZO\")[\"r_m3_d\"].to_dict()\n",
    "\n",
    "    # 10) Semanas a planificar\n",
    "    start = next_monday(date.today())\n",
    "    weeks = [(start + timedelta(weeks=i), start + timedelta(weeks=i, days=6)) for i in range(params[\"semanas_plan\"])]\n",
    "\n",
    "    # 11) Equipos -> ZONA (fijo)\n",
    "    zonas_list = sorted(zonas_labels)\n",
    "    if not zonas_list:\n",
    "        raise ValueError(\"No hay ZONAS válidas (todas vacías).\")\n",
    "\n",
    "    equipo_to_zona = {}\n",
    "    for i in range(1, params[\"equipos_activos\"]+1):\n",
    "        zona_asignada = zonas_list[min(i-1, len(zonas_list)-1)]\n",
    "        equipo_to_zona[i] = zona_asignada\n",
    "\n",
    "    # 12) Plan semanal por ZONA usando la versión V2 (clústeres)\n",
    "    plan_all = []\n",
    "    next_due = {row.POZO: row.proxima_visita_base for row in freq.itertuples()}\n",
    "    zone_to_teams = {}\n",
    "    for eq, zona_label in equipo_to_zona.items():\n",
    "        zone_to_teams.setdefault(zona_label, []).append(eq)\n",
    "\n",
    "    for (w_start, w_end) in weeks:\n",
    "        for zona_label, team_list in zone_to_teams.items():\n",
    "            zona_norm_label = _norm(zona_label)\n",
    "            cand_all = build_candidates_with_coords(\n",
    "                freq=freq,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                excl_pozos=excl_total,\n",
    "                zonas_norm_incluidas={zona_norm_label},\n",
    "                coords_df=coords_df,\n",
    "                allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "                next_due_map=next_due\n",
    "            )\n",
    "            if cand_all.empty:\n",
    "                continue\n",
    "\n",
    "            cand_zone = cand_all[[  # mantener las columnas necesarias\n",
    "                \"POZO\",\"ZONA\",\"BATERIA\",\"due_date\",\"is_overdue\",\"__v\",\n",
    "                \"LAT\",\"LON\",\"has_coords\",\"r_m3_d\",\"ultima_medicion\"\n",
    "            ]].copy()\n",
    "\n",
    "            plan_week_zone = assign_week_round_robin_by_zone(\n",
    "                cand_all=cand_zone,\n",
    "                team_ids=sorted(team_list),\n",
    "                params=params,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                radius_km=RADIUS_KM\n",
    "            )\n",
    "\n",
    "            if not plan_week_zone.empty:\n",
    "                plan_all.append(plan_week_zone)\n",
    "                # actualizar next_due por pozo asignado\n",
    "                for pz, fcal in plan_week_zone[[\"POZO\",\"Plan_Fecha\"]].drop_duplicates().itertuples(index=False):\n",
    "                    dd = int(delta_by_pozo.get(pz, params[\"min_dias_freq\"]))\n",
    "                    next_due[pz] = pd.Timestamp(fcal) + pd.Timedelta(days=dd)\n",
    "\n",
    "    plan = (pd.concat(plan_all, ignore_index=True)\n",
    "            if plan_all else\n",
    "            pd.DataFrame(columns=[\n",
    "                \"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\"ZONA\",\"BATERIA\",\n",
    "                \"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\"Seed_POZO\",\"Dist_km_semilla\",\n",
    "                \"Dist_km_centroid\",\"ultima_medicion\",\"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\",\"Cluster_Score\"\n",
    "            ]))\n",
    "\n",
    "    # 13) Cobertura anual reforzada (opcional) — mantiene tu lógica original (no forma clúster)\n",
    "    if not freq.empty:\n",
    "        eligible_mask = (freq[\"ZONA\"].isin(zonas_labels)) & (freq[\"r_m3_d\"].fillna(0) > RM3D_MIN)\n",
    "        if \"comentario\" in freq.columns:\n",
    "            eligible_mask &= (freq[\"comentario\"].astype(str).fillna(\"\").str.strip() == \"\")\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            for zn, bats in allowed_bats_by_zone_norm.items():\n",
    "                if bats is not None:\n",
    "                    eligible_mask &= (~(freq[\"ZONA_NORM\"] == zn)) | (freq[\"BATERIA_NORM\"].isin(bats))\n",
    "\n",
    "        all_pozos_in_zonas = freq.loc[eligible_mask, [\"POZO\",\"ZONA\",\"BATERIA\"]].drop_duplicates().copy()\n",
    "        all_pozos_in_zonas = all_pozos_in_zonas[\n",
    "            all_pozos_in_zonas[\"BATERIA\"].notna() & (all_pozos_in_zonas[\"BATERIA\"].astype(str).str.strip() != \"\")\n",
    "        ].copy()\n",
    "\n",
    "        # usa el filler original (sin clúster) SOLO para cubrir huecos anuales\n",
    "     #   plan = ensure_annual_coverage_zone_locked(\n",
    "      #      all_pozos_df=all_pozos_in_zonas,\n",
    "       #     plan=plan,\n",
    "        #    params=params,\n",
    "         #   start_date=start,\n",
    "          #  equipo_to_zona=equipo_to_zona,\n",
    "           # allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "            #r_by_pozo=r_by_pozo\n",
    "       # )\n",
    "\n",
    "    # 14) Export opcional (agrego columnas nuevas de clúster)\n",
    "    out_xlsx = None\n",
    "    if escribir_excel:\n",
    "        out_xlsx = unique_output_path(INPUT_FILE)\n",
    "        coords_all = read_coords(COORDS_FILE)\n",
    "        with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "            # Frecuencias\n",
    "            freq_out = freq.copy()\n",
    "            for c in [\"proxima_visita_base\",\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "                freq_out[c] = pd.to_datetime(freq_out[c], errors=\"coerce\").dt.date\n",
    "            freq_out = freq_out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"])\n",
    "            cols_pref = [\"POZO\",\"ZONA\",\"BATERIA\",\"ZONA_NORM\",\"BATERIA_NORM\",\"r_m3_d\",\n",
    "                         \"ultima_medicion\",\"ultima_exitosa\",\"delta_star_dias\",\"comentario\",\n",
    "                         \"proxima_visita_base\",\"ceros_consec\",\"alerta\"]\n",
    "            cols_final = [c for c in cols_pref if c in freq_out.columns] + \\\n",
    "                         [c for c in freq_out.columns if c not in cols_pref]\n",
    "            freq_out = freq_out[cols_final]\n",
    "            freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
    "\n",
    "            # Plan por equipo + Km_al_siguiente\n",
    "            cols_plan = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "                         \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "                         \"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\",\"Cluster_Score\",\n",
    "                         \"Dist_km_centroid\"]\n",
    "            for eq in range(1, params[\"equipos_activos\"]+1):\n",
    "                pe = plan.loc[plan[\"Equipo\"]==eq].copy()\n",
    "                if pe.empty:\n",
    "                    pe = pd.DataFrame(columns=cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"])\n",
    "                else:\n",
    "                    pe = pe.sort_values([\"Plan_Fecha\",\"Dia_Idx\",\"Orden\",\"POZO\"]).copy()\n",
    "                    pe = pe.merge(coords_all, how=\"left\", on=\"POZO\")\n",
    "                    pe[\"LAT_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LAT\"].shift(-1)\n",
    "                    pe[\"LON_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LON\"].shift(-1)\n",
    "                    def _leg_km(row):\n",
    "                        if (pd.isna(row.get(\"LAT\")) or pd.isna(row.get(\"LON\")) or\n",
    "                            pd.isna(row.get(\"LAT_next\")) or pd.isna(row.get(\"LON_next\"))):\n",
    "                            return None\n",
    "                        return round(float(haversine_km(row[\"LAT\"], row[\"LON\"],\n",
    "                                                        row[\"LAT_next\"], row[\"LON_next\"])), 3)\n",
    "                    pe[\"Km_al_siguiente\"] = pe.apply(_leg_km, axis=1)\n",
    "                    pe.drop(columns=[\"LAT\",\"LON\",\"LAT_next\",\"LON_next\"], inplace=True, errors=\"ignore\")\n",
    "                    pe[\"Ejecutado\"] = \"\"\n",
    "                    for c in cols_plan:\n",
    "                        if c not in pe.columns: pe[c] = \"\"\n",
    "                    pe = pe[cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"]]\n",
    "                pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
    "\n",
    "            # Auxiliares\n",
    "            pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n",
    "\n",
    "    # ====== Asserts/chequeos mínimos ======\n",
    "    # ====== Asserts/chequeos mínimos ======\n",
    "    if not plan.empty:\n",
    "        K_chk = int(params.get(\"max_pozos_por_cluster\", 5))\n",
    "\n",
    "        # ✅ Validar SOLO clústeres reales (ClusterID no vacío)\n",
    "        mask_real = plan[\"ClusterID\"].notna() & (plan[\"ClusterID\"].astype(str).str.strip() != \"\")\n",
    "        gsize = (plan.loc[mask_real]\n",
    "                 .groupby([\"Plan_Fecha\",\"Equipo\",\"ClusterID\"])[\"POZO\"]\n",
    "                 .count())\n",
    "\n",
    "        if not gsize.empty:\n",
    "            assert (gsize % K_chk == 0).all(), \"Hay clústeres asignados que no cumplen tamaño K exacto.\"\n",
    "\n",
    "        # ✅ No duplicación diaria (ningún pozo se repite en el mismo día)\n",
    "        dupmax = plan.groupby([\"Plan_Fecha\",\"POZO\"]).size().max()\n",
    "        assert int(dupmax) == 1, \"Un pozo aparece más de una vez en el mismo día.\"\n",
    "\n",
    "        # ✅ Radio cumplido (tolerancia numérica)\n",
    "        if \"Dist_km_centroid\" in plan.columns and plan[\"Dist_km_centroid\"].notna().any():\n",
    "            assert float(plan[\"Dist_km_centroid\"].fillna(0).max()) <= float(RADIUS_KM) + 1e-6, \\\n",
    "                \"Distancia a centroide excede el radio.\"\n",
    "\n",
    "    return plan, freq, out_xlsx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# RUNNER (EDITÁ TUS RUTAS Y PARÁMETROS ACÁ)\n",
    "# ============================================\n",
    "\n",
    "INPUT_FILE = r\"C:\\Users\\ry16123\\Downloads\\Ultimo (ORIGINAL) TABLERO PRODUCCIÓN FLUG S.A 2025 (1).xlsx\"\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "plan, freq, out_xlsx = run_pipeline_jupyter(\n",
    "    input_file=INPUT_FILE,\n",
    "    nombres_pozo_file=NOMBRES_POZO_FILE,\n",
    "    coords_file=COORDS_FILE,\n",
    "    semanas_plan=2,                 # probá corto para iterar rápido\n",
    "    equipos_activos=2,              # cantidad de equipos\n",
    "    dias_por_semana=5,              # 5 ó 6\n",
    "    max_pozos_dia_equipo=5,\n",
    "    K_max_pozos_por_cluster=5,      # tamaño máximo de clúster\n",
    "    clusters_por_dia_max=2,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,             # o lista como [\"Las Heras CG - Canadon Escondida\"]\n",
    "    baterias_por_zona=None,         # dict normalizado (keys en _norm) o None\n",
    "    pozos_excluir=set(),            # ej.: {\"BB-100\"}\n",
    "    escribir_excel=True            # poné True si querés exportar el Excel\n",
    ")\n",
    "\n",
    "# Mostrar un vistazo rápido\n",
    "display(freq.head(10))\n",
    "display(plan.head(30))\n",
    "print(\"Excel generado:\", out_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eca2e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\CursoML-UDEMY\\env\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ry16123\\CursoML-UDEMY\\env\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_2860\\3206594485.py:1288: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_2860\\3206594485.py:1316: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_2860\\3206594485.py:1316: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_2860\\3206594485.py:1319: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POZO</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>ZONA_NORM</th>\n",
       "      <th>BATERIA_NORM</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ultima_exitosa</th>\n",
       "      <th>delta_star_dias</th>\n",
       "      <th>proxima_visita_base</th>\n",
       "      <th>ceros_consec</th>\n",
       "      <th>alerta</th>\n",
       "      <th>comentario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BB-101</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BB-111</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BB-133</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB-170</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-12-23</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>NO CONTACTA NIVEL A 1500 MTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB-21</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB-50</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BB-80</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>BB 02</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>bb 02</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>42</td>\n",
       "      <td>2025-09-18</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BB-91</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BB.a-104</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>NO SE PUEDE AFLOJAR TAPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BB.a-75</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>las heras cg canadon escondida</td>\n",
       "      <td>swabing ce</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-11-19</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       POZO                              ZONA     BATERIA  \\\n",
       "0    BB-101  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "1    BB-111  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "2    BB-133  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "3    BB-170  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "4     BB-21  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "5     BB-50  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "6     BB-80  Las Heras CG - Canadon Escondida       BB 02   \n",
       "7     BB-91  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "8  BB.a-104  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "9   BB.a-75  Las Heras CG - Canadon Escondida  Swabing CE   \n",
       "\n",
       "                        ZONA_NORM BATERIA_NORM    r_m3_d ultima_medicion  \\\n",
       "0  las heras cg canadon escondida   swabing ce  0.035714      2025-08-25   \n",
       "1  las heras cg canadon escondida   swabing ce  0.428571      2025-07-01   \n",
       "2  las heras cg canadon escondida   swabing ce  0.012346      2025-10-20   \n",
       "3  las heras cg canadon escondida   swabing ce  0.026374      2025-10-28   \n",
       "4  las heras cg canadon escondida   swabing ce  0.015564      2025-05-12   \n",
       "5  las heras cg canadon escondida   swabing ce  0.001059      2025-10-09   \n",
       "6  las heras cg canadon escondida        bb 02  0.050000      2025-08-07   \n",
       "7  las heras cg canadon escondida   swabing ce  0.003300      2025-10-20   \n",
       "8  las heras cg canadon escondida   swabing ce  0.285714      2025-10-15   \n",
       "9  las heras cg canadon escondida   swabing ce  0.012552      2025-09-24   \n",
       "\n",
       "  ultima_exitosa  delta_star_dias proxima_visita_base  ceros_consec alerta  \\\n",
       "0     2025-08-25               56          2025-10-20             0          \n",
       "1     2025-07-01                7          2025-07-08             0          \n",
       "2     2025-10-20               56          2025-12-15             0          \n",
       "3     2025-10-22               56          2025-12-23             0          \n",
       "4     2025-05-12               56          2025-07-07             0          \n",
       "5     2025-10-09               56          2025-12-04             0          \n",
       "6     2025-08-07               42          2025-09-18             0          \n",
       "7     2025-10-20               56          2025-12-15             0          \n",
       "8     2025-01-24                7          2025-10-22             0          \n",
       "9     2025-09-24               56          2025-11-19             0          \n",
       "\n",
       "                     comentario  \n",
       "0                                \n",
       "1                                \n",
       "2                                \n",
       "3  NO CONTACTA NIVEL A 1500 MTS  \n",
       "4                                \n",
       "5                                \n",
       "6                                \n",
       "7                                \n",
       "8      NO SE PUEDE AFLOJAR TAPA  \n",
       "9                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_Fecha</th>\n",
       "      <th>Semana_ISO</th>\n",
       "      <th>Equipo</th>\n",
       "      <th>Dia_Idx</th>\n",
       "      <th>Orden</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BATERIA</th>\n",
       "      <th>POZO</th>\n",
       "      <th>r_m3_d</th>\n",
       "      <th>Vol_Estimado_m3</th>\n",
       "      <th>Seed_POZO</th>\n",
       "      <th>Dist_km_semilla</th>\n",
       "      <th>Dist_km_centroid</th>\n",
       "      <th>ultima_medicion</th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>Centroide_LAT</th>\n",
       "      <th>Centroide_LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-586</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>9.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.490</td>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.401416</td>\n",
       "      <td>-68.571995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-226</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.15</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.401416</td>\n",
       "      <td>-68.571995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-1091</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.86</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.744</td>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.401416</td>\n",
       "      <td>-68.571995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-199</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.79</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.037</td>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.401416</td>\n",
       "      <td>-68.571995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-370(I)</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.92</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.489</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.464236</td>\n",
       "      <td>-68.557056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 10</td>\n",
       "      <td>CnE-826</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.608</td>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.464236</td>\n",
       "      <td>-68.557056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-839</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.40</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.743</td>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.464236</td>\n",
       "      <td>-68.557056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>ECE.x-1</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>2.69</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>C00002</td>\n",
       "      <td>-46.464236</td>\n",
       "      <td>-68.557056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-849</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.127</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.434831</td>\n",
       "      <td>-68.541859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-543</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>3.08</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.020</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.434831</td>\n",
       "      <td>-68.541859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-372</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.60</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.339</td>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.434831</td>\n",
       "      <td>-68.541859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-808</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.15</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>3.237</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>C00003</td>\n",
       "      <td>-46.434831</td>\n",
       "      <td>-68.541859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-282</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>2.18</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.244</td>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.443187</td>\n",
       "      <td>-68.645605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 06</td>\n",
       "      <td>CnE-431</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>18.15</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.246</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.443187</td>\n",
       "      <td>-68.645605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 06</td>\n",
       "      <td>CnE-211</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.44</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.616</td>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.443187</td>\n",
       "      <td>-68.645605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-599</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.60</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>3.542</td>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>C00001</td>\n",
       "      <td>-46.443187</td>\n",
       "      <td>-68.645605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-200</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>2.58</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.321</td>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.394539</td>\n",
       "      <td>-68.557119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 13</td>\n",
       "      <td>CnE-615</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.50</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.857</td>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.394539</td>\n",
       "      <td>-68.557119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-792</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>2.48</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.716</td>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.394539</td>\n",
       "      <td>-68.557119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-752</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>3.335</td>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>C00004</td>\n",
       "      <td>-46.394539</td>\n",
       "      <td>-68.557119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE.a-584</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.40</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.227</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>C00006</td>\n",
       "      <td>-46.459014</td>\n",
       "      <td>-68.518338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-732</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4.78</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.447</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>C00006</td>\n",
       "      <td>-46.459014</td>\n",
       "      <td>-68.518338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-736</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>4.19</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>C00006</td>\n",
       "      <td>-46.459014</td>\n",
       "      <td>-68.518338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-370</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.733</td>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>C00006</td>\n",
       "      <td>-46.459014</td>\n",
       "      <td>-68.518338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 15</td>\n",
       "      <td>CnE-778</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.09</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.777</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>C00012</td>\n",
       "      <td>-46.403788</td>\n",
       "      <td>-68.517639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-660</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>2.53</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.958</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>C00012</td>\n",
       "      <td>-46.403788</td>\n",
       "      <td>-68.517639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-295</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>2.00</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.509</td>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>C00012</td>\n",
       "      <td>-46.403788</td>\n",
       "      <td>-68.517639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 15</td>\n",
       "      <td>CnE-563</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.95</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.649</td>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>C00012</td>\n",
       "      <td>-46.403788</td>\n",
       "      <td>-68.517639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>CE 19</td>\n",
       "      <td>CnE-696</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>1.51</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.594</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>C00011</td>\n",
       "      <td>-46.396504</td>\n",
       "      <td>-68.611485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Las Heras CG - Canadon Escondida</td>\n",
       "      <td>Swabing CE</td>\n",
       "      <td>CnE-521</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>2.74</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.368</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>C00011</td>\n",
       "      <td>-46.396504</td>\n",
       "      <td>-68.611485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plan_Fecha  Semana_ISO  Equipo  Dia_Idx  Orden  \\\n",
       "0   2025-11-03          45       1        1      1   \n",
       "1   2025-11-03          45       1        1      2   \n",
       "2   2025-11-03          45       1        1      3   \n",
       "3   2025-11-03          45       1        1      4   \n",
       "4   2025-11-03          45       2        1      1   \n",
       "5   2025-11-03          45       2        1      2   \n",
       "6   2025-11-03          45       2        1      3   \n",
       "7   2025-11-03          45       2        1      4   \n",
       "8   2025-11-04          45       1        2      1   \n",
       "9   2025-11-04          45       1        2      2   \n",
       "10  2025-11-04          45       1        2      3   \n",
       "11  2025-11-04          45       1        2      4   \n",
       "12  2025-11-04          45       2        2      1   \n",
       "13  2025-11-04          45       2        2      2   \n",
       "14  2025-11-04          45       2        2      3   \n",
       "15  2025-11-04          45       2        2      4   \n",
       "16  2025-11-05          45       1        3      1   \n",
       "17  2025-11-05          45       1        3      2   \n",
       "18  2025-11-05          45       1        3      3   \n",
       "19  2025-11-05          45       1        3      4   \n",
       "20  2025-11-05          45       2        3      1   \n",
       "21  2025-11-05          45       2        3      2   \n",
       "22  2025-11-05          45       2        3      3   \n",
       "23  2025-11-05          45       2        3      4   \n",
       "24  2025-11-06          45       1        4      1   \n",
       "25  2025-11-06          45       1        4      2   \n",
       "26  2025-11-06          45       1        4      3   \n",
       "27  2025-11-06          45       1        4      4   \n",
       "28  2025-11-06          45       2        4      1   \n",
       "29  2025-11-06          45       2        4      2   \n",
       "\n",
       "                                ZONA     BATERIA        POZO    r_m3_d  \\\n",
       "0   Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-586  1.800000   \n",
       "1   Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-226  0.230769   \n",
       "2   Las Heras CG - Canadon Escondida  Swabing CE    CnE-1091  0.285714   \n",
       "3   Las Heras CG - Canadon Escondida  Swabing CE     CnE-199  0.357143   \n",
       "4   Las Heras CG - Canadon Escondida  Swabing CE  CnE-370(I)  0.230769   \n",
       "5   Las Heras CG - Canadon Escondida       CE 10     CnE-826  0.571429   \n",
       "6   Las Heras CG - Canadon Escondida  Swabing CE     CnE-839  0.200000   \n",
       "7   Las Heras CG - Canadon Escondida  Swabing CE     ECE.x-1  0.384615   \n",
       "8   Las Heras CG - Canadon Escondida  Swabing CE     CnE-849  0.200000   \n",
       "9   Las Heras CG - Canadon Escondida  Swabing CE     CnE-543  0.153846   \n",
       "10  Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-372  0.200000   \n",
       "11  Las Heras CG - Canadon Escondida  Swabing CE     CnE-808  0.230769   \n",
       "12  Las Heras CG - Canadon Escondida  Swabing CE     CnE-282  0.272727   \n",
       "13  Las Heras CG - Canadon Escondida       CE 06     CnE-431  0.050000   \n",
       "14  Las Heras CG - Canadon Escondida       CE 06     CnE-211  0.063492   \n",
       "15  Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-599  0.200000   \n",
       "16  Las Heras CG - Canadon Escondida  Swabing CE     CnE-200  0.129032   \n",
       "17  Las Heras CG - Canadon Escondida       CE 13     CnE-615  0.166667   \n",
       "18  Las Heras CG - Canadon Escondida  Swabing CE     CnE-792  0.130435   \n",
       "19  Las Heras CG - Canadon Escondida  Swabing CE     CnE-752  0.142857   \n",
       "20  Las Heras CG - Canadon Escondida  Swabing CE   CnE.a-584  0.100000   \n",
       "21  Las Heras CG - Canadon Escondida  Swabing CE     CnE-732  0.111111   \n",
       "22  Las Heras CG - Canadon Escondida  Swabing CE     CnE-736  0.190476   \n",
       "23  Las Heras CG - Canadon Escondida  Swabing CE     CnE-370  0.125000   \n",
       "24  Las Heras CG - Canadon Escondida       CE 15     CnE-778  0.090909   \n",
       "25  Las Heras CG - Canadon Escondida  Swabing CE     CnE-660  0.105263   \n",
       "26  Las Heras CG - Canadon Escondida  Swabing CE     CnE-295  0.071429   \n",
       "27  Las Heras CG - Canadon Escondida       CE 15     CnE-563  0.105263   \n",
       "28  Las Heras CG - Canadon Escondida       CE 19     CnE-696  0.035088   \n",
       "29  Las Heras CG - Canadon Escondida  Swabing CE     CnE-521  0.114286   \n",
       "\n",
       "    Vol_Estimado_m3 Seed_POZO Dist_km_semilla  Dist_km_centroid  \\\n",
       "0              9.00                      None             0.490   \n",
       "1              1.15                      None             0.612   \n",
       "2              4.86                      None             1.744   \n",
       "3              1.79                      None             2.037   \n",
       "4              0.92                      None             0.489   \n",
       "5              4.00                      None             0.608   \n",
       "6              1.40                      None             2.743   \n",
       "7              2.69                      None             2.885   \n",
       "8              4.00                      None             1.127   \n",
       "9              3.08                      None             2.020   \n",
       "10             3.60                      None             2.339   \n",
       "11             1.15                      None             3.237   \n",
       "12             2.18                      None             1.244   \n",
       "13            18.15                      None             2.246   \n",
       "14             0.44                      None             2.616   \n",
       "15             1.60                      None             3.542   \n",
       "16             2.58                      None             1.321   \n",
       "17             4.50                      None             1.857   \n",
       "18             2.48                      None             2.716   \n",
       "19             1.00                      None             3.335   \n",
       "20            18.40                      None             1.227   \n",
       "21             4.78                      None             1.447   \n",
       "22             4.19                      None             2.251   \n",
       "23             5.00                      None             2.733   \n",
       "24             2.09                      None             1.777   \n",
       "25             2.53                      None             1.958   \n",
       "26             2.00                      None             2.509   \n",
       "27             0.95                      None             2.649   \n",
       "28             1.51                      None             0.594   \n",
       "29             2.74                      None             1.368   \n",
       "\n",
       "   ultima_medicion ClusterID  Centroide_LAT  Centroide_LON  \n",
       "0       2025-10-29    C00001     -46.401416     -68.571995  \n",
       "1       2025-10-29    C00001     -46.401416     -68.571995  \n",
       "2       2025-10-17    C00001     -46.401416     -68.571995  \n",
       "3       2025-10-29    C00001     -46.401416     -68.571995  \n",
       "4       2025-10-30    C00002     -46.464236     -68.557056  \n",
       "5       2025-10-27    C00002     -46.464236     -68.557056  \n",
       "6       2025-10-27    C00002     -46.464236     -68.557056  \n",
       "7       2025-10-27    C00002     -46.464236     -68.557056  \n",
       "8       2025-10-15    C00003     -46.434831     -68.541859  \n",
       "9       2025-10-15    C00003     -46.434831     -68.541859  \n",
       "10      2025-10-17    C00003     -46.434831     -68.541859  \n",
       "11      2025-10-30    C00003     -46.434831     -68.541859  \n",
       "12      2025-10-27    C00001     -46.443187     -68.645605  \n",
       "13      2024-11-06    C00001     -46.443187     -68.645605  \n",
       "14      2025-10-28    C00001     -46.443187     -68.645605  \n",
       "15      2025-10-27    C00001     -46.443187     -68.645605  \n",
       "16      2025-10-16    C00004     -46.394539     -68.557119  \n",
       "17      2025-10-09    C00004     -46.394539     -68.557119  \n",
       "18      2025-10-17    C00004     -46.394539     -68.557119  \n",
       "19      2025-10-29    C00004     -46.394539     -68.557119  \n",
       "20      2025-05-05    C00006     -46.459014     -68.518338  \n",
       "21      2025-09-23    C00006     -46.459014     -68.518338  \n",
       "22      2025-10-14    C00006     -46.459014     -68.518338  \n",
       "23      2025-09-26    C00006     -46.459014     -68.518338  \n",
       "24      2025-10-14    C00012     -46.403788     -68.517639  \n",
       "25      2025-10-13    C00012     -46.403788     -68.517639  \n",
       "26      2025-10-09    C00012     -46.403788     -68.517639  \n",
       "27      2025-10-28    C00012     -46.403788     -68.517639  \n",
       "28      2025-09-24    C00011     -46.396504     -68.611485  \n",
       "29      2025-10-13    C00011     -46.396504     -68.611485  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel generado: C:\\Users\\ry16123\\Downloads\\CÑE   FLUG S.A 2025 2_CRONOGRAMA_20251031.xlsx\n"
     ]
    }
   ],
   "source": [
    "#ESTARIA FUNCIONANDO RELATIVAMENTE BIEN- PROBARLO\n",
    "\n",
    "# ============================================\n",
    "# Monocelda Jupyter: Planificador + Harness + Runner\n",
    "# ============================================\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, unicodedata, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# CONFIG por defecto (se sobreescriben en el runner)\n",
    "# ==========================\n",
    "INPUT_FILE  = r\"DIAGRAMA SW.xlsx\"   # Excel base (NO se modifica)\n",
    "SHEET_HIST  = None                  # None => autodetecta hoja/encabezados\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "# Radio en km para agrupar por cercanía\n",
    "RADIUS_KM = 3.0\n",
    "# Filtro mínimo de potencial\n",
    "RM3D_MIN = 0.1\n",
    "\n",
    "# Umbrales para fuzzy (si se usan)\n",
    "FUZZY_REPLACE_THRESHOLD = 85\n",
    "FUZZY_SUGGEST_THRESHOLD = 75\n",
    "LETTERS_SIMILARITY_MIN  = 80\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"equipos_activos\": 4,                 # 1..4\n",
    "    \"dias_por_semana\": 5,                 # 5 o 6\n",
    "    \"semanas_plan\": 2,                    # para probar rápido en Jupyter\n",
    "    \"k_visitas\": 1,                       # tasas (K=1 por pedido)\n",
    "    \"max_pozos_dia_equipo\": 10,           # cupo por día por equipo\n",
    "    \"max_pozos_por_cluster\": 4,           # tamaño de clúster (K fijo si usás lógica de clústeres fijos)\n",
    "    \"m3_por_visita_objetivo\": 2.0,        # informativo\n",
    "    \"min_dias_freq\": 7,                   # 1 semana\n",
    "    \"max_dias_freq\": 56,                  # 8 semanas\n",
    "    \"dias_asumidos_una_visita\": 7,        # para r si hay 1 sola visita\n",
    "    \"freq_dias_ultimo_cero_valido\": 30,\n",
    "\n",
    "    # Semillas a evaluar (si se usa lógica de semillas)\n",
    "    \"top_semillas_eval\": 30,\n",
    "\n",
    "    # Control de clústeres por día y backfill (si se usa lógica por semilla)\n",
    "    \"clusters_por_dia_max\": None,\n",
    "    \"backfill_nearest_cluster\": True,\n",
    "    \"umbral_km_backfill\": 5.0,\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Utils\n",
    "# ==========================\n",
    "def _norm(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = s.replace(\"³\", \"3\")\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip().replace(\"\\xa0\",\" \")\n",
    "    s = s.replace(\"_\",\" \").replace(\"-\",\" \").replace(\".\",\" \").replace(\"\\n\",\" \")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _pozo_key(s: str) -> str:\n",
    "    s = \"\" if s is None or (isinstance(s, float) and np.isnan(s)) else str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return \"\".join(ch for ch in s if ch.isalnum()).upper()\n",
    "\n",
    "def _canonical_digits(d: str) -> str:\n",
    "    d = (d or \"\").lstrip(\"0\")\n",
    "    return d if d != \"\" else \"0\"\n",
    "\n",
    "def _letters_digits_from_key_both(k: str):\n",
    "    raw_digits = \"\".join(re.findall(r\"\\d+\", k))\n",
    "    digits_canon = _canonical_digits(raw_digits)\n",
    "    letters = re.sub(r\"\\d+\", \"\", k)\n",
    "    return letters, digits_canon, len(raw_digits)\n",
    "\n",
    "def _ratio_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _fuzzy_score(a: str, b: str) -> int:\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return int(fuzz.partial_ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return int(round(difflib.SequenceMatcher(None, a, b).ratio()*100))\n",
    "\n",
    "def _canon_prefix_pozo(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return s\n",
    "    raw = str(s).strip()\n",
    "    raw_up = raw.upper()\n",
    "    if raw_up.startswith(\"CÑE\"):\n",
    "        return \"CNE\" + raw_up[3:]\n",
    "    raw_ascii = unicodedata.normalize(\"NFKD\", raw_up).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    if raw_ascii.startswith(\"CNE\"):\n",
    "        return raw_ascii\n",
    "    if raw_ascii.startswith(\"CN\"):\n",
    "        return \"CNE\" + raw_ascii[2:]\n",
    "    m = re.match(r\"^CE(\\d+)$\", raw_ascii)\n",
    "    if m:\n",
    "        return \"CNE\" + m.group(1)\n",
    "    return raw_ascii\n",
    "\n",
    "def next_monday(d=None):\n",
    "    d = d or date.today()\n",
    "    return d + timedelta(days=(7 - d.weekday()) % 7)  # 0=Lunes\n",
    "\n",
    "def unique_output_path(base_input_path: str) -> str:\n",
    "    folder = os.path.dirname(os.path.abspath(base_input_path))\n",
    "    stem   = os.path.splitext(os.path.basename(base_input_path))[0]\n",
    "    today  = datetime.now().strftime(\"%Y%m%d\")\n",
    "    base   = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}.xlsx\")\n",
    "    if not os.path.exists(base): return base\n",
    "    i = 2\n",
    "    while True:\n",
    "        cand = os.path.join(folder, f\"{stem}_CRONOGRAMA_{today}_({i}).xlsx\")\n",
    "        if not os.path.exists(cand): return cand\n",
    "        i += 1\n",
    "\n",
    "EXPECTED_KEYS = {\n",
    "    \"fecha\":       [\"fecha\"],\n",
    "    \"pozo\":        [\"pozo\"],\n",
    "    \"zona\":        [\"zona\"],\n",
    "    \"bateria\":     [\"bateria\", \"batería\"],\n",
    "    \"m3\":          [\"m3 bruta\",\"m3\",\"m3_bruta\",\"m3bruta\",\"m 3 bruta\",\"m 3\",\"m3 bruto\",\"m3 recuperado\",\"m3 recupero\"],\n",
    "    \"carreras\":    [\"n de carreras\",\"n° de carreras\",\"nº de carreras\",\"no de carreras\",\"nro de carreras\",\"numero de carreras\",\"n° carreras\",\"n de carrera\",\"n carreras\"],\n",
    "    \"nivel_final\": [\"nivel final pozo\",\"nivel final\",\"nivel final del pozo\"],\n",
    "    \"obs_pozo\":    [\"observaciones del pozo\",\"observaciones\",\"comentarios\",\"comentario\"]\n",
    "}\n",
    "\n",
    "def _find_header_row(df_raw):\n",
    "    for i in range(min(200, len(df_raw))):\n",
    "        row_norm = [_norm(x) for x in df_raw.iloc[i,:].tolist()]\n",
    "        if not row_norm:\n",
    "            continue\n",
    "        colmap = {v:j for v,j in zip(row_norm, range(len(row_norm)))}\n",
    "        def has_any(keys): return any(k in colmap for k in keys)\n",
    "        if has_any(EXPECTED_KEYS[\"fecha\"]) and has_any(EXPECTED_KEYS[\"pozo\"]) and has_any(EXPECTED_KEYS[\"zona\"]) and has_any(EXPECTED_KEYS[\"bateria\"]):\n",
    "            return i, row_norm\n",
    "    return None, None\n",
    "\n",
    "# ---------- Nombres pozo ----------\n",
    "def load_pozo_dictionary(xlsx_path: str):\n",
    "    try:\n",
    "        ref = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer diccionario de pozos: {xlsx_path}\\n{e}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    cols = {c.lower().strip(): c for c in ref.columns}\n",
    "    if \"nombre_corto_pozo\" not in cols:\n",
    "        print(f\"\\n[AVISO] El diccionario no tiene la columna 'nombre_corto_pozo'. Columnas: {list(ref.columns)}\\n\")\n",
    "        return {}, pd.DataFrame(columns=[\"oficial\",\"key\",\"letters\",\"digits_canon\",\"digits_len\",\"met_prod\",\"nivel_3\",\"nivel_5\",\"estado\"])\n",
    "\n",
    "    c_pozo = cols[\"nombre_corto_pozo\"]\n",
    "    c_met  = cols.get(\"met_prod\")\n",
    "    c_n3   = cols.get(\"nivel_3\")\n",
    "    c_n5   = cols.get(\"nivel_5\")\n",
    "    c_est  = cols.get(\"estado\")\n",
    "\n",
    "    refv = ref.loc[ref[c_pozo].notna()].copy()\n",
    "    refv[c_pozo] = refv[c_pozo].astype(str).str.strip()\n",
    "\n",
    "    of_list  = refv[c_pozo].tolist()\n",
    "    met_vals = refv[c_met].astype(str).str.strip() if c_met else np.nan\n",
    "    n3_vals  = refv[c_n3].astype(str).str.strip()  if c_n3 else np.nan\n",
    "    n5_vals  = refv[c_n5].astype(str).str.strip()  if c_n5 else np.nan\n",
    "    est_vals = refv[c_est].astype(str).str.strip() if c_est else np.nan\n",
    "\n",
    "    keys, letters_, digits_canon_, digits_len_ = [], [], [], []\n",
    "    for val in of_list:\n",
    "        k = _pozo_key(val)\n",
    "        L, Dcanon, Dlen = _letters_digits_from_key_both(k)\n",
    "        keys.append(k); letters_.append(L); digits_canon_.append(Dcanon); digits_len_.append(Dlen)\n",
    "\n",
    "    dict_df = pd.DataFrame({\n",
    "        \"oficial\": of_list,\n",
    "        \"key\": keys,\n",
    "        \"letters\": letters_,\n",
    "        \"digits_canon\": digits_canon_,\n",
    "        \"digits_len\": digits_len_,\n",
    "        \"met_prod\": list(met_vals) if isinstance(met_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_3\":  list(n3_vals)  if isinstance(n3_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"nivel_5\":  list(n5_vals)  if isinstance(n5_vals,  pd.Series) else [np.nan]*len(of_list),\n",
    "        \"estado\":   list(est_vals) if isinstance(est_vals, pd.Series) else [np.nan]*len(of_list),\n",
    "    })\n",
    "\n",
    "    key2off = {}\n",
    "    for k, off in zip(dict_df[\"key\"], dict_df[\"oficial\"]):\n",
    "        if k and k not in key2off:\n",
    "            key2off[k] = off\n",
    "    return key2off, dict_df\n",
    "\n",
    "def apply_pozo_normalization(df: pd.DataFrame, key2off: dict, dict_df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"POZO_ORIG\"] = df[\"POZO\"].astype(str).str.strip()\n",
    "    df[\"POZO_PreCanon\"] = df[\"POZO_ORIG\"].apply(_canon_prefix_pozo)\n",
    "    df[\"__POZO_KEY\"] = df[\"POZO_PreCanon\"].apply(_pozo_key)\n",
    "\n",
    "    parts = df[\"__POZO_KEY\"].apply(_letters_digits_from_key_both)\n",
    "    df[\"__KEY_LET\"], df[\"__KEY_DIG_CANON\"], df[\"__KEY_DIG_LEN\"] = zip(*parts)\n",
    "\n",
    "    df[\"POZO_MATCH\"]   = None\n",
    "    df[\"MATCH_TIPO\"]   = \"NO\"\n",
    "    df[\"MATCH_SCORE\"]  = np.nan\n",
    "    df[\"LETTER_SCORE\"] = np.nan\n",
    "    df[\"APLICADO\"]     = \"NO\"\n",
    "    df[\"ALERTA_NORM\"]  = \"\"\n",
    "    df[\"VALIDO_POZO\"]  = True\n",
    "\n",
    "    invalid_mask = (df[\"__KEY_LET\"].str.len()==0) | (df[\"__KEY_DIG_LEN\"]==0)\n",
    "    if invalid_mask.any():\n",
    "        df.loc[invalid_mask, \"ALERTA_NORM\"] = \"SIN_LETRAS_O_DIGITOS\"\n",
    "        df.loc[invalid_mask, \"VALIDO_POZO\"] = False\n",
    "\n",
    "    valid_mask = ~invalid_mask\n",
    "    exact_mask = valid_mask & df[\"__POZO_KEY\"].isin(key2off.keys())\n",
    "    df.loc[exact_mask, \"POZO_MATCH\"]   = df.loc[exact_mask, \"__POZO_KEY\"].map(key2off)\n",
    "    df.loc[exact_mask, \"MATCH_TIPO\"]   = \"EXACTO\"\n",
    "    df.loc[exact_mask, \"MATCH_SCORE\"]  = 100\n",
    "    df.loc[exact_mask, \"LETTER_SCORE\"] = 100\n",
    "    df.loc[exact_mask, \"APLICADO\"]     = \"SI\"\n",
    "\n",
    "    pending = df[valid_mask & (~exact_mask)].index.tolist()\n",
    "    if pending and not dict_df.empty:\n",
    "        dict_by_spec = {}\n",
    "        for spec, sub in dict_df.groupby([\"digits_canon\",\"digits_len\"]):\n",
    "            dict_by_spec[spec] = sub\n",
    "\n",
    "        for idx in pending:\n",
    "            key_u   = df.at[idx, \"__POZO_KEY\"]\n",
    "            let_u   = df.at[idx, \"__KEY_LET\"]\n",
    "            digc_u  = df.at[idx, \"__KEY_DIG_CANON\"]\n",
    "            digl_u  = int(df.at[idx, \"__KEY_DIG_LEN\"])\n",
    "\n",
    "            cand_df = dict_by_spec.get((digc_u, digl_u), pd.DataFrame())\n",
    "            best_off, best_score, best_lscore = None, -1, -1\n",
    "\n",
    "            if cand_df is not None and not cand_df.empty:\n",
    "                for row in cand_df.itertuples():\n",
    "                    kk = row.key\n",
    "                    ll = row.letters\n",
    "                    sc_key = _fuzzy_score(key_u, kk)\n",
    "                    sc_let = _ratio_score(let_u, ll)\n",
    "                    if sc_let < LETTERS_SIMILARITY_MIN:\n",
    "                        continue\n",
    "                    if sc_key > best_score or (sc_key == best_score and sc_let > best_lscore):\n",
    "                        best_score = sc_key\n",
    "                        best_lscore = sc_let\n",
    "                        best_off   = row.oficial\n",
    "\n",
    "            if best_off is not None:\n",
    "                df.at[idx, \"POZO_MATCH\"]   = best_off\n",
    "                df.at[idx, \"MATCH_TIPO\"]   = \"SUGERIDO\"\n",
    "                df.at[idx, \"MATCH_SCORE\"]  = int(best_score)\n",
    "                df.at[idx, \"LETTER_SCORE\"] = int(best_lscore)\n",
    "            else:\n",
    "                df.at[idx, \"ALERTA_NORM\"] = \"SIN MATCH EN DICCIONARIO\"\n",
    "\n",
    "    # Reemplazos\n",
    "    df[\"POZO\"] = df[\"POZO_MATCH\"].where(df[\"POZO_MATCH\"].notna(), df[\"POZO\"])\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    df = df.merge(meta_first, how=\"left\", left_on=\"POZO\", right_index=True)\n",
    "\n",
    "    # ZONA sólo si hubo match; sino, vacío\n",
    "    if \"nivel_3\" in df.columns:\n",
    "        df.loc[df[\"POZO_MATCH\"].isna(), \"nivel_3\"] = \"\"\n",
    "        df[\"ZONA\"] = np.where(df[\"POZO_MATCH\"].notna(), df[\"nivel_3\"].fillna(\"\"), \"\")\n",
    "\n",
    "    # BATERIA si hay nivel_5\n",
    "    if \"nivel_5\" in df.columns:\n",
    "        df[\"BATERIA\"] = np.where(\n",
    "            df[\"nivel_5\"].notna() & (df[\"nivel_5\"].astype(str).str.strip()!=\"\"),\n",
    "            df[\"nivel_5\"], df[\"BATERIA\"]\n",
    "        )\n",
    "\n",
    "    df[\"__ZONA_NORM\"]    = df[\"ZONA\"].apply(_norm)\n",
    "    df[\"__BATERIA_NORM\"] = df[\"BATERIA\"].apply(_norm)\n",
    "\n",
    "    norm_table = (df[[\"POZO_ORIG\",\"POZO_PreCanon\",\"__POZO_KEY\",\n",
    "                      \"__KEY_LET\",\"__KEY_DIG_CANON\",\"__KEY_DIG_LEN\",\n",
    "                      \"POZO_MATCH\",\"MATCH_TIPO\",\"MATCH_SCORE\",\"LETTER_SCORE\",\n",
    "                      \"APLICADO\",\"ALERTA_NORM\",\"VALIDO_POZO\",\n",
    "                      \"met_prod\",\"nivel_3\",\"nivel_5\"]]\n",
    "                  .drop_duplicates()\n",
    "                  .rename(columns={\n",
    "                      \"POZO_ORIG\":\"Pozo_Original\",\n",
    "                      \"POZO_PreCanon\":\"Pozo_PreCanon\",\n",
    "                      \"__POZO_KEY\":\"Clave_Normalizada\",\n",
    "                      \"__KEY_LET\":\"Letras\",\n",
    "                      \"__KEY_DIG_CANON\":\"Digitos_Canon\",\n",
    "                      \"__KEY_DIG_LEN\":\"Digitos_Len\",\n",
    "                      \"POZO_MATCH\":\"Match_Oficial\",\n",
    "                      \"MATCH_TIPO\":\"Match_Tipo\",\n",
    "                      \"MATCH_SCORE\":\"Match_Score\",\n",
    "                      \"LETTER_SCORE\":\"Letter_Score\",\n",
    "                      \"APLICADO\":\"Aplicado\",\n",
    "                      \"ALERTA_NORM\":\"Alerta\",\n",
    "                      \"VALIDO_POZO\":\"Valido\",\n",
    "                      \"met_prod\":\"met_prod\",\n",
    "                      \"nivel_3\":\"nivel_3\",\n",
    "                      \"nivel_5\":\"nivel_5\"\n",
    "                  })\n",
    "                  .sort_values([\"Valido\",\"Aplicado\",\"Match_Tipo\",\"Pozo_Original\"], ascending=[False, False, True, True]))\n",
    "\n",
    "    alert_table = norm_table[(norm_table[\"Valido\"]==False) | (norm_table[\"Aplicado\"]==\"NO\") | (norm_table[\"Match_Tipo\"]==\"NO\")].copy()\n",
    "    return df, alert_table, norm_table\n",
    "\n",
    "def read_historial(xlsx_path, sheet_hist=None):\n",
    "    xl = pd.ExcelFile(xlsx_path)\n",
    "    sheets = [sheet_hist] if (sheet_hist and sheet_hist in xl.sheet_names) else xl.sheet_names\n",
    "    for sh in sheets:\n",
    "        raw = xl.parse(sh, header=None)\n",
    "        idx, header_norm = _find_header_row(raw)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        data = raw.iloc[idx:, :].copy()\n",
    "        true_headers = data.iloc[0,:].astype(str).tolist()\n",
    "        data = data.iloc[1:,:]\n",
    "        data.columns = true_headers\n",
    "\n",
    "        name_map = {c: _norm(c) for c in data.columns}\n",
    "        def find_col(candidates):\n",
    "            for c, n in name_map.items():\n",
    "                if n in candidates:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        c_fecha       = find_col(set(EXPECTED_KEYS[\"fecha\"]))\n",
    "        c_pozo        = find_col(set(EXPECTED_KEYS[\"pozo\"]))\n",
    "        c_zona        = find_col(set(EXPECTED_KEYS[\"zona\"]))\n",
    "        c_bateria     = find_col(set(EXPECTED_KEYS[\"bateria\"]))\n",
    "        c_m3          = find_col(set(EXPECTED_KEYS[\"m3\"]))\n",
    "        c_carr        = find_col(set(EXPECTED_KEYS[\"carreras\"]))\n",
    "        c_nivel_final = find_col(set(EXPECTED_KEYS[\"nivel_final\"]))\n",
    "        c_obs         = find_col(set(EXPECTED_KEYS[\"obs_pozo\"]))\n",
    "\n",
    "        if not (c_fecha and c_pozo and c_zona and c_bateria):\n",
    "            continue\n",
    "\n",
    "        use_cols = [c_fecha, c_pozo, c_zona, c_bateria]\n",
    "        headers  = [\"FECHA\",\"POZO\",\"ZONA\",\"BATERIA\"]\n",
    "        if c_m3:            use_cols.append(c_m3);            headers.append(\"M3\")\n",
    "        if c_carr:          use_cols.append(c_carr);          headers.append(\"CARRERAS\")\n",
    "        if c_nivel_final:   use_cols.append(c_nivel_final);   headers.append(\"NIVEL_FINAL\")\n",
    "        if c_obs:           use_cols.append(c_obs);           headers.append(\"OBS_POZO\")\n",
    "\n",
    "        df = data[use_cols].copy()\n",
    "        df.columns = headers\n",
    "\n",
    "        df[\"FECHA\"] = pd.to_datetime(df[\"FECHA\"], errors=\"coerce\")\n",
    "        if \"M3\" not in df.columns: df[\"M3\"] = np.nan\n",
    "        else: df[\"M3\"] = pd.to_numeric(df[\"M3\"], errors=\"coerce\")\n",
    "\n",
    "        if \"CARRERAS\" not in df.columns: df[\"CARRERAS\"] = np.nan\n",
    "        else: df[\"CARRERAS\"] = pd.to_numeric(df[\"CARRERAS\"], errors=\"coerce\")\n",
    "\n",
    "        if \"NIVEL_FINAL\" not in df.columns:\n",
    "            df[\"NIVEL_FINAL\"] = None\n",
    "        if \"OBS_POZO\" not in df.columns:\n",
    "            df[\"OBS_POZO\"] = None\n",
    "\n",
    "        for col in [\"POZO\",\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\",\"OBS_POZO\"]:\n",
    "            df[col] = df[col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "        df = df.dropna(subset=[\"FECHA\",\"POZO\"]).sort_values([\"POZO\",\"FECHA\"])\n",
    "        return df\n",
    "\n",
    "    raise ValueError(\"No pude detectar FECHA/POZO/ZONA/BATERÍA en ninguna hoja del Excel.\")\n",
    "\n",
    "def read_exclusions_from_sheet(xlsx_path):\n",
    "    excl = set()\n",
    "    try:\n",
    "        xl = pd.ExcelFile(xlsx_path)\n",
    "        if \"ExcluirPozos\" in xl.sheet_names:\n",
    "            e = xl.parse(\"ExcluirPozos\")\n",
    "            e.columns = [str(c).strip().lower() for c in e.columns]\n",
    "            if \"pozo\" in e.columns:\n",
    "                if \"excluir\" in e.columns:\n",
    "                    excl = set(e.loc[e[\"excluir\"].astype(str).str.upper().isin(\n",
    "                        [\"SI\",\"SÍ\",\"YES\",\"1\",\"TRUE\"]), \"pozo\"].astype(str).str.strip())\n",
    "                else:\n",
    "                    excl = set(e[\"pozo\"].astype(str).str.strip())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return excl\n",
    "\n",
    "# ==========================\n",
    "# Frecuencias / r_m3_d\n",
    "# ==========================\n",
    "def _count_trailing_zeros_with_carr(g):\n",
    "    cnt = 0\n",
    "    for _, row in g.sort_values(\"FECHA\").iloc[::-1].iterrows():\n",
    "        m3 = row.get(\"M3\", np.nan)\n",
    "        car = row.get(\"CARRERAS\", np.nan)\n",
    "        if pd.notna(m3) and float(m3) == 0.0 and pd.notna(car) and float(car) > 0:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    return cnt\n",
    "\n",
    "def compute_frecuencias(df, params):\n",
    "    v_target = params[\"m3_por_visita_objetivo\"]\n",
    "    min_d    = params[\"min_dias_freq\"]\n",
    "    max_d    = params[\"max_dias_freq\"]\n",
    "    k        = int(params[\"k_visitas\"])\n",
    "    one_days = int(params.get(\"dias_asumidos_una_visita\", 7))\n",
    "    freq_cero_ultimo = int(params.get(\"freq_dias_ultimo_cero_valido\", 30))\n",
    "\n",
    "    out = []\n",
    "    for pozo, g0 in df.groupby(\"POZO\", sort=False):\n",
    "        g = g0.sort_values(\"FECHA\").copy()\n",
    "\n",
    "        for col in [\"ZONA\",\"BATERIA\",\"NIVEL_FINAL\"]:\n",
    "            if col in g.columns:\n",
    "                g[col] = g[col].replace({None: np.nan})\n",
    "                g[col] = g[col].ffill().bfill()\n",
    "\n",
    "        g[\"__ZONA_NORM\"]    = g[\"ZONA\"].apply(_norm)\n",
    "        g[\"__BATERIA_NORM\"] = g[\"BATERIA\"].apply(_norm)\n",
    "        g[\"__nf_norm\"]      = g[\"NIVEL_FINAL\"].apply(_norm) if \"NIVEL_FINAL\" in g.columns else \"\"\n",
    "\n",
    "        med_validas_all = g[g[\"M3\"].notna()].copy()\n",
    "\n",
    "        m3_eq0 = g[\"M3\"].fillna(0) == 0\n",
    "        carr   = g.get(\"CARRERAS\", pd.Series(index=g.index, dtype=float)).fillna(np.nan)\n",
    "        zero_cond_a = m3_eq0 & (carr.fillna(0) >= 1)\n",
    "        zero_cond_b = m3_eq0 & ((carr.isna()) | (carr.fillna(0) == 0)) & (g[\"__nf_norm\"] == \"surge\")\n",
    "        cond_cero_valido = zero_cond_a | zero_cond_b\n",
    "\n",
    "        validas_rate = g[(g[\"M3\"] > 0) | cond_cero_valido].copy()\n",
    "        zeros_tail = _count_trailing_zeros_with_carr(g)\n",
    "\n",
    "        ultima_med = med_validas_all[\"FECHA\"].max() if not med_validas_all.empty else pd.NaT\n",
    "        ultima_exi = g.loc[g[\"M3\"]>0, \"FECHA\"].max() if \"M3\" in g.columns and not g[g[\"M3\"]>0].empty else pd.NaT\n",
    "\n",
    "        last_zero_valido = False\n",
    "        if not med_validas_all.empty:\n",
    "            idx_last = med_validas_all[\"FECHA\"].idxmax()\n",
    "            m3_last  = g.at[idx_last, \"M3\"]\n",
    "            if pd.notna(m3_last) and float(m3_last) == 0.0:\n",
    "                try:\n",
    "                    last_zero_valido = bool(cond_cero_valido.loc[idx_last])\n",
    "                except Exception:\n",
    "                    last_zero_valido = False\n",
    "\n",
    "        alerta = \"\"\n",
    "        if last_zero_valido:\n",
    "            alerta = f\"ULTIMA_M3_0_VALIDO -> FREQ {freq_cero_ultimo}D\"\n",
    "        elif pd.notna(ultima_med):\n",
    "            if zeros_tail > 0:\n",
    "                alerta = f\"ALERTA: {zeros_tail} cero(s) consecutivo(s) con Carreras>0\"\n",
    "\n",
    "        # r_m3_d\n",
    "        r = np.nan\n",
    "        if not validas_rate.empty:\n",
    "            v = validas_rate.copy()\n",
    "            v[\"delta_d\"] = v[\"FECHA\"].diff().dt.days\n",
    "            v.loc[v[\"delta_d\"] <= 0, \"delta_d\"] = np.nan\n",
    "            v[\"rate\"] = v[\"M3\"].fillna(0) / v[\"delta_d\"]\n",
    "            rates = v[\"rate\"].dropna()\n",
    "            if len(rates) >= 1:\n",
    "                r = rates.tail(min(k, len(rates))).mean()\n",
    "            else:\n",
    "                row = v.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "        else:\n",
    "            if len(med_validas_all) == 1:\n",
    "                row = med_validas_all.iloc[-1]\n",
    "                m3 = float(row[\"M3\"]) if pd.notna(row[\"M3\"]) else 0.0\n",
    "                if m3 > 0:\n",
    "                    r = m3 / max(1, one_days)\n",
    "                else:\n",
    "                    r = np.nan\n",
    "\n",
    "        # FRECUENCIA\n",
    "        if last_zero_valido:\n",
    "            delta = int(freq_cero_ultimo)\n",
    "        else:\n",
    "            if pd.isna(r):      delta = 7\n",
    "            elif r <= 0:        delta = max_d\n",
    "            else:\n",
    "                delta = max(min_d, min(max_d, float(v_target)/float(r)))\n",
    "                delta = int(7 * round(delta / 7.0))\n",
    "                if delta < 7:\n",
    "                    delta = 7\n",
    "\n",
    "        prox = (ultima_med + pd.Timedelta(days=int(delta))) if pd.notna(ultima_med) else pd.Timestamp(next_monday())\n",
    "\n",
    "        out.append({\n",
    "            \"POZO\": pozo,\n",
    "            \"ZONA\": g[\"ZONA\"].iloc[-1],\n",
    "            \"BATERIA\": g[\"BATERIA\"].iloc[-1],\n",
    "            \"ZONA_NORM\": g[\"__ZONA_NORM\"].iloc[-1],\n",
    "            \"BATERIA_NORM\": g[\"__BATERIA_NORM\"].iloc[-1],\n",
    "            \"r_m3_d\": r,\n",
    "            \"ultima_medicion\": ultima_med,\n",
    "            \"ultima_exitosa\": ultima_exi,\n",
    "            \"delta_star_dias\": int(delta),\n",
    "            \"proxima_visita_base\": prox,\n",
    "            \"ceros_consec\": zeros_tail,\n",
    "            \"alerta\": alerta\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# ==========================\n",
    "# Coordenadas\n",
    "# ==========================\n",
    "def _to_float_maybe_comma(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if s == \"\": return np.nan\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def read_coords(xlsx_path):\n",
    "    try:\n",
    "        cdf = pd.read_excel(xlsx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[AVISO] No pude leer coordenadas: {xlsx_path}\\n{e}\\n\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    cols_map = {c.lower().strip(): c for c in cdf.columns}\n",
    "    c_pozo = cols_map.get(\"pozo\")\n",
    "    for k in [\"geo_latitude\",\"latitude\",\"lat\"]:\n",
    "        if k in cols_map:\n",
    "            c_lat = cols_map[k]; break\n",
    "    else:\n",
    "        c_lat = None\n",
    "    for k in [\"geo_longitude\",\"longitude\",\"lon\",\"long\"]:\n",
    "        if k in cols_map:\n",
    "            c_lon = cols_map[k]; break\n",
    "    else:\n",
    "        c_lon = None\n",
    "\n",
    "    if not (c_pozo and c_lat and c_lon):\n",
    "        print(f\"[AVISO] Coordenadas: columnas esperadas 'POZO','GEO_LATITUDE','GEO_LONGITUDE'. Columnas encontradas: {list(cdf.columns)}\")\n",
    "        return pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "\n",
    "    out = cdf[[c_pozo, c_lat, c_lon]].copy()\n",
    "    out.columns = [\"POZO\",\"LAT\",\"LON\"]\n",
    "    out[\"POZO\"] = out[\"POZO\"].astype(str).str.strip()\n",
    "    out[\"LAT\"] = out[\"LAT\"].apply(_to_float_maybe_comma)\n",
    "    out[\"LON\"] = out[\"LON\"].apply(_to_float_maybe_comma)\n",
    "    out = out.dropna(subset=[\"POZO\"])\n",
    "    out = out.drop_duplicates(subset=[\"POZO\"], keep=\"last\")\n",
    "    return out\n",
    "\n",
    "# ==========================\n",
    "# Candidatos y utilidades\n",
    "# ==========================\n",
    "def build_candidates_with_coords(freq, week_start, week_end, excl_pozos,\n",
    "                                 zonas_norm_incluidas, coords_df,\n",
    "                                 allowed_bats_by_zone_norm=None,\n",
    "                                 next_due_map=None):\n",
    "    F = freq.copy()\n",
    "\n",
    "    # due_date base (permitimos override con next_due_map)\n",
    "    F[\"due_date\"] = F[\"proxima_visita_base\"]\n",
    "    if next_due_map:\n",
    "        F[\"due_date\"] = F[\"POZO\"].map(next_due_map).fillna(F[\"due_date\"])\n",
    "\n",
    "    F[\"overdue_d\"] = (pd.Timestamp(week_start) - pd.to_datetime(F[\"due_date\"])).dt.days\n",
    "    F[\"is_overdue\"] = F[\"overdue_d\"] > 0\n",
    "\n",
    "    # prioridad\n",
    "    F[\"__v\"] = F[\"r_m3_d\"].astype(float)\n",
    "\n",
    "    # Filtro por ZONA (normalizada)\n",
    "    if \"ZONA_NORM\" in F.columns and zonas_norm_incluidas:\n",
    "        F = F[F[\"ZONA_NORM\"].isin(zonas_norm_incluidas)].copy()\n",
    "\n",
    "    # Sub-filtro por BATERÍA (si corresponde)\n",
    "    if allowed_bats_by_zone_norm:\n",
    "        mask = pd.Series(True, index=F.index)\n",
    "        for zn in zonas_norm_incluidas:\n",
    "            bats = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats is not None:\n",
    "                mask &= ~ (F[\"ZONA_NORM\"] == zn) | (F[\"BATERIA_NORM\"].isin(bats))\n",
    "        F = F[mask].copy()\n",
    "\n",
    "    # Exclusiones\n",
    "    if excl_pozos:\n",
    "        F = F[~F[\"POZO\"].isin(excl_pozos)].copy()\n",
    "\n",
    "    # Potencial mínimo y BATERÍA no vacía\n",
    "    F = F[F[\"r_m3_d\"].fillna(0) > RM3D_MIN].copy()\n",
    "    F = F[F[\"BATERIA\"].notna() & (F[\"BATERIA\"].astype(str).str.strip() != \"\")].copy()\n",
    "\n",
    "    # Excluir pozos con comentario no vacío en Frecuencias\n",
    "    if \"comentario\" in F.columns:\n",
    "        F[\"__comentario_txt\"] = F[\"comentario\"].astype(str).fillna(\"\").str.strip()\n",
    "        F = F[F[\"__comentario_txt\"] == \"\"].copy()\n",
    "        F.drop(columns=[\"__comentario_txt\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Merge coordenadas\n",
    "    coords_df = coords_df if coords_df is not None else pd.DataFrame(columns=[\"POZO\",\"LAT\",\"LON\"])\n",
    "    F = F.merge(coords_df, how=\"left\", on=\"POZO\")\n",
    "    F[\"has_coords\"] = F[\"LAT\"].notna() & F[\"LON\"].notna()\n",
    "\n",
    "    # Orden base\n",
    "    F = F.sort_values(by=[\"is_overdue\",\"__v\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    return F\n",
    "\n",
    "def _v_est_for_day(row, day_date):\n",
    "    r = row.get(\"r_m3_d\", np.nan)\n",
    "    u = row.get(\"ultima_medicion\", pd.NaT)\n",
    "    if pd.isna(u) or pd.isna(r) or r <= 0:\n",
    "        return 0.0\n",
    "    dd = max(0, (pd.Timestamp(day_date) - pd.Timestamp(u)).days)\n",
    "    return max(0.0, float(r) * float(dd))\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "            return np.nan\n",
    "        R = 6371.0088\n",
    "        p1 = math.radians(float(lat1)); p2 = math.radians(float(lat2))\n",
    "        dphi = math.radians(float(lat2) - float(lat1))\n",
    "        dlmb = math.radians(float(lon2) - float(lon1))\n",
    "        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "        return 2*R*math.asin(math.sqrt(a))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ==========================\n",
    "# NUEVA LÓGICA DE CLÚSTERES (según prompt)\n",
    "# ==========================\n",
    "def _bbox_filter(df, lat0, lon0, rad_km):\n",
    "    \"\"\"Bounding-box previo a haversine para acotar vecinos.\"\"\"\n",
    "    if pd.isna(lat0) or pd.isna(lon0) or df.empty:\n",
    "        return df.iloc[0:0]\n",
    "    dlat = rad_km / 110.574\n",
    "    dlon = rad_km / (111.320 * max(0.1, math.cos(math.radians(float(lat0)))))\n",
    "    return df[(df[\"LAT\"].between(lat0 - dlat, lat0 + dlat)) &\n",
    "              (df[\"LON\"].between(lon0 - dlon, lon0 + dlon))].copy()\n",
    "\n",
    "def _cluster_centroid(lat_list, lon_list):\n",
    "    if not lat_list or not lon_list:\n",
    "        return (np.nan, np.nan)\n",
    "    return float(np.mean(lat_list)), float(np.mean(lon_list))\n",
    "\n",
    "def _validate_cluster_by_centroid(lat_list, lon_list, radius_km):\n",
    "    c_lat, c_lon = _cluster_centroid(lat_list, lon_list)\n",
    "    if pd.isna(c_lat) or pd.isna(c_lon):\n",
    "        return False, (np.nan, np.nan), np.inf\n",
    "    dmax = 0.0\n",
    "    for la, lo in zip(lat_list, lon_list):\n",
    "        d = haversine_km(c_lat, c_lon, la, lo)\n",
    "        if pd.isna(d) or d > radius_km + 1e-9:\n",
    "            return False, (c_lat, c_lon), np.inf\n",
    "        dmax = max(dmax, d)\n",
    "    return True, (c_lat, c_lon), dmax\n",
    "\n",
    "def build_all_clusters(\n",
    "    cands: pd.DataFrame,\n",
    "    K: int,\n",
    "    radius_km: float,\n",
    "    score_mode: str = \"rm3d\",\n",
    "    top_seeds: int = 30\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve DF con:\n",
    "    ['ClusterID','POZOS','Centroide_LAT','Centroide_LON','Score','ZONA','BATERIAS']\n",
    "    - Exactamente K pozos por clúster\n",
    "    - Validación: todos a <= radius_km del CENTROIDE\n",
    "    - Overlap permitido en generación\n",
    "    - Semillas: mejores 'top_seeds' por __v\n",
    "    - Elimina duplicados exactos (mismo conjunto de pozos)\n",
    "    \"\"\"\n",
    "    if cands.empty:\n",
    "        return pd.DataFrame(columns=[\"ClusterID\",\"POZOS\",\"Centroide_LAT\",\"Centroide_LON\",\"Score\",\"ZONA\",\"BATERIAS\"])\n",
    "\n",
    "    # trabajar solo con pozos con coords\n",
    "    base = cands[cands[\"has_coords\"]].copy()\n",
    "    if base.empty:\n",
    "        return pd.DataFrame(columns=[\"ClusterID\",\"POZOS\",\"Centroide_LAT\",\"Centroide_LON\",\"Score\",\"ZONA\",\"BATERIAS\"])\n",
    "\n",
    "    base = base.sort_values([\"__v\",\"is_overdue\",\"due_date\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    seeds = base.head(max(1, int(top_seeds))).copy()\n",
    "\n",
    "    clusters = []\n",
    "    seen_sets = set()  # para deduplicar por conjunto de pozos\n",
    "    for _, seed in seeds.iterrows():\n",
    "        s_lat, s_lon = seed[\"LAT\"], seed[\"LON\"]\n",
    "        neigh = _bbox_filter(base, s_lat, s_lon, radius_km)\n",
    "        if neigh.empty:\n",
    "            continue\n",
    "        # Orden por valor y cercanía a la semilla\n",
    "        neigh = neigh.copy()\n",
    "        neigh[\"__dist_seed\"] = neigh.apply(lambda r: haversine_km(s_lat, s_lon, r[\"LAT\"], r[\"LON\"]), axis=1)\n",
    "        neigh = neigh[neigh[\"__dist_seed\"] <= radius_km]\n",
    "        neigh = neigh.sort_values([\"__v\",\"__dist_seed\"], ascending=[False, True])\n",
    "\n",
    "        # Tomar candidatos top K alrededor de la semilla (semilla incluida)\n",
    "        if seed[\"POZO\"] not in neigh[\"POZO\"].values:\n",
    "            # asegurar que la semilla esté\n",
    "            neigh = pd.concat([pd.DataFrame([seed]), neigh], ignore_index=True)\n",
    "            neigh = neigh.drop_duplicates(subset=[\"POZO\"], keep=\"first\")\n",
    "\n",
    "        if len(neigh) < K:\n",
    "            # no alcanza tamaño K dentro del radio de la semilla\n",
    "            continue\n",
    "\n",
    "        # Probar ventana de los top K mejor valuados dentro del radio\n",
    "        topk = neigh.head(K).copy()\n",
    "        pozos = tuple(topk[\"POZO\"].tolist())\n",
    "        lats  = topk[\"LAT\"].tolist()\n",
    "        lons  = topk[\"LON\"].tolist()\n",
    "\n",
    "        ok, (c_lat, c_lon), dmax = _validate_cluster_by_centroid(lats, lons, radius_km)\n",
    "        if not ok:\n",
    "            # Intentar ajustar: expandir lista ordenada y mover una ventana sobre los N mejores vecinos\n",
    "            N = min(len(neigh), K + 10)  # ventana corta para evitar combinatoria\n",
    "            window = neigh.head(N).copy()\n",
    "            found = False\n",
    "            # estrategia greedy: fijar semilla y tomar los K-1 mejores por __v que cumplan centroide\n",
    "            # probando reemplazos simples si no valida\n",
    "            for i in range(0, N-K+1):\n",
    "                cand = window.iloc[i:i+K]\n",
    "                lats2 = cand[\"LAT\"].tolist(); lons2 = cand[\"LON\"].tolist()\n",
    "                ok2, (c_lat2, c_lon2), _ = _validate_cluster_by_centroid(lats2, lons2, radius_km)\n",
    "                if ok2:\n",
    "                    topk = cand.copy()\n",
    "                    c_lat, c_lon = c_lat2, c_lon2\n",
    "                    pozos = tuple(topk[\"POZO\"].tolist())\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                continue  # no se pudo validar centroide\n",
    "\n",
    "        # dedupe exacto por set\n",
    "        key_set = frozenset(pozos)\n",
    "        if key_set in seen_sets:\n",
    "            continue\n",
    "        seen_sets.add(key_set)\n",
    "\n",
    "        # Score: rm3d o vest (hook)\n",
    "        if score_mode == \"vest\":\n",
    "            # si se usa vest, en generación no sabemos el día; dejamos rm3d como aproximación\n",
    "            score = float(topk[\"r_m3_d\"].fillna(0).sum())\n",
    "        else:\n",
    "            score = float(topk[\"r_m3_d\"].fillna(0).sum())\n",
    "\n",
    "        # ZONA/BATERIAS: mayoritaria (o homogénea si ya lo está)\n",
    "        zona_mode = topk[\"ZONA\"].mode()\n",
    "        zona_val = zona_mode.iloc[0] if not zona_mode.empty else \"\"\n",
    "        bats = tuple(sorted(set(str(x) for x in topk[\"BATERIA\"].fillna(\"\").astype(str))))\n",
    "\n",
    "        clusters.append({\n",
    "            \"ClusterID\": f\"C{len(seen_sets):05d}\",\n",
    "            \"POZOS\": pozos,\n",
    "            \"Centroide_LAT\": float(c_lat),\n",
    "            \"Centroide_LON\": float(c_lon),\n",
    "            \"Score\": score,\n",
    "            \"ZONA\": zona_val,\n",
    "            \"BATERIAS\": bats\n",
    "        })\n",
    "\n",
    "    cldf = pd.DataFrame(clusters)\n",
    "    if cldf.empty:\n",
    "        return cldf\n",
    "    cldf = cldf.sort_values(\"Score\", ascending=False).reset_index(drop=True)\n",
    "    return cldf\n",
    "\n",
    "\n",
    "def select_clusters_for_day(\n",
    "    clusters_df: pd.DataFrame,\n",
    "    used_today: set[str],\n",
    "    cap_pozos: int,\n",
    "    backfill_nearest: bool,\n",
    "    umbral_km_backfill: float,\n",
    "    clusters_por_dia_max: Optional[int] = None,\n",
    "    K: int = 5\n",
    ") -> list[dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Devuelve lista de dicts: {'POZOS', 'ClusterID', 'Centroide_LAT', 'Centroide_LON', 'Score'}\n",
    "    - Greedy por Score desc.\n",
    "    - No repetir pozos del día.\n",
    "    - Respetar clusters_por_dia_max y cap_pozos (multiplo de K).\n",
    "    - Si backfill_nearest=True: exigir distancia del centroide nuevo al centroide acumulado ≤ umbral.\n",
    "    \"\"\"\n",
    "    if clusters_df is None or clusters_df.empty:\n",
    "        return []\n",
    "\n",
    "    selected = []\n",
    "    pozos_usados = set(used_today)\n",
    "    cap_left = int(cap_pozos)\n",
    "    max_clusters = int(clusters_por_dia_max) if clusters_por_dia_max is not None else None\n",
    "\n",
    "    # centroide acumulado del día (promedio incremental)\n",
    "    c_lat_acc, c_lon_acc, n_acc = (np.nan, np.nan, 0)\n",
    "\n",
    "    def _update_centroid_acc(lat, lon):\n",
    "        nonlocal c_lat_acc, c_lon_acc, n_acc\n",
    "        if pd.isna(lat) or pd.isna(lon): \n",
    "            return\n",
    "        if n_acc == 0:\n",
    "            c_lat_acc, c_lon_acc, n_acc = float(lat), float(lon), 1\n",
    "        else:\n",
    "            c_lat_acc = (c_lat_acc*n_acc + float(lat)) / (n_acc + 1)\n",
    "            c_lon_acc = (c_lon_acc*n_acc + float(lon)) / (n_acc + 1)\n",
    "            n_acc += 1\n",
    "\n",
    "    for _, row in clusters_df.iterrows():\n",
    "        if cap_left < K:\n",
    "            break\n",
    "        if max_clusters is not None and len(selected) >= max_clusters:\n",
    "            break\n",
    "\n",
    "        pozos = set(row[\"POZOS\"])\n",
    "        if pozos & pozos_usados:\n",
    "            # contiene pozo ya tomado hoy\n",
    "            continue\n",
    "\n",
    "        if backfill_nearest and len(selected) >= 1 and not (pd.isna(c_lat_acc) or pd.isna(c_lon_acc)):\n",
    "            dcc = haversine_km(c_lat_acc, c_lon_acc, row[\"Centroide_LAT\"], row[\"Centroide_LON\"])\n",
    "            if pd.isna(dcc) or dcc > float(umbral_km_backfill) + 1e-9:\n",
    "                continue\n",
    "\n",
    "        selected.append({\n",
    "            \"POZOS\": list(row[\"POZOS\"]),\n",
    "            \"ClusterID\": row[\"ClusterID\"],\n",
    "            \"Centroide_LAT\": float(row[\"Centroide_LAT\"]),\n",
    "            \"Centroide_LON\": float(row[\"Centroide_LON\"]),\n",
    "            \"Score\": float(row[\"Score\"])\n",
    "        })\n",
    "        pozos_usados |= pozos\n",
    "        cap_left -= K\n",
    "        _update_centroid_acc(row[\"Centroide_LAT\"], row[\"Centroide_LON\"])\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ASIGNACIÓN SEMANAL ROUND-ROBIN (usando clústeres precomputados)\n",
    "# ==========================\n",
    "def assign_week_round_robin_by_zone(cand_all, team_ids, params, week_start, week_end, radius_km):\n",
    "    \"\"\"\n",
    "    Reparte por día/equipo en una zona, eligiendo clústeres precomputados (no pozos sueltos).\n",
    "    Reglas duras:\n",
    "    - Clúster tamaño exacto K\n",
    "    - Todos los pozos del clúster a ≤ radius_km del centroide (ya validado en build_all_clusters)\n",
    "    - No repetir POZO en el mismo día (entre equipos de la misma zona)\n",
    "    \"\"\"\n",
    "    dias   = int(params[\"dias_por_semana\"])\n",
    "    cap_pz = int(params[\"max_pozos_dia_equipo\"])\n",
    "    K      = int(params.get(\"max_pozos_por_cluster\", 4))\n",
    "    backfill_nearest = bool(params.get(\"backfill_nearest_cluster\", True))\n",
    "    umbral_backfill  = float(params.get(\"umbral_km_backfill\", 5.0))\n",
    "    clusters_por_dia_max = params.get(\"clusters_por_dia_max\", None)\n",
    "\n",
    "    rows = []\n",
    "    used_week = set()  # evita repetir el mismo pozo dentro de la semana\n",
    "\n",
    "    for d in range(dias):\n",
    "        day_date = pd.Timestamp(week_start) + pd.Timedelta(days=d)\n",
    "\n",
    "        # Ignorar vencimiento: usar todos los candidatos de la zona,\n",
    "        # menos los ya usados en la semana\n",
    "        pool_day = cand_all[~cand_all[\"POZO\"].isin(used_week)].copy()\n",
    "        if pool_day.empty:\n",
    "            continue\n",
    "\n",
    "        # Precomputar TODOS los clústeres del día (overlap permitido en generación)\n",
    "        clusters_df = build_all_clusters(\n",
    "            cands=pool_day,\n",
    "            K=K,\n",
    "            radius_km=radius_km,\n",
    "            score_mode=\"rm3d\",\n",
    "            top_seeds=int(params.get(\"top_semillas_eval\", 30))\n",
    "        )\n",
    "        if clusters_df.empty:\n",
    "            continue\n",
    "\n",
    "        used_today = set()  # no duplicar pozos en el mismo día entre equipos\n",
    "\n",
    "        # >>> orden fijo de equipos (sin rotación)\n",
    "        for eq in sorted(team_ids):\n",
    "            chosen = select_clusters_for_day(\n",
    "                clusters_df=clusters_df,\n",
    "                used_today=used_today,\n",
    "                cap_pozos=cap_pz,\n",
    "                backfill_nearest=backfill_nearest,\n",
    "                umbral_km_backfill=umbral_backfill,\n",
    "                clusters_por_dia_max=clusters_por_dia_max,\n",
    "                K=K\n",
    "            )\n",
    "            if not chosen:\n",
    "                continue\n",
    "\n",
    "            # materializar filas del plan\n",
    "            ord_idx = 1\n",
    "            for cluster in chosen:\n",
    "                pozos = cluster[\"POZOS\"]\n",
    "                c_lat = cluster[\"Centroide_LAT\"]\n",
    "                c_lon = cluster[\"Centroide_LON\"]\n",
    "                cid   = cluster[\"ClusterID\"]\n",
    "\n",
    "                info = pool_day[pool_day[\"POZO\"].isin(pozos)].copy().set_index(\"POZO\")\n",
    "\n",
    "                # asserts rápidos (tamaño y radio)\n",
    "                assert len(pozos) == K\n",
    "                for pz in pozos:\n",
    "                    dcent = haversine_km(c_lat, c_lon, info.at[pz, \"LAT\"], info.at[pz, \"LON\"])\n",
    "                    assert (not pd.isna(dcent)) and dcent <= radius_km + 1e-6\n",
    "\n",
    "                # ordenar por cercanía al centroide (opcional)\n",
    "                pozos_sorted = sorted(\n",
    "                    pozos,\n",
    "                    key=lambda p: haversine_km(c_lat, c_lon, info.at[p, \"LAT\"], info.at[p, \"LON\"])\n",
    "                )\n",
    "\n",
    "                for pz in pozos_sorted:\n",
    "                    rec = info.loc[pz]\n",
    "                    v_est = _v_est_for_day(\n",
    "                        {\"r_m3_d\": rec.get(\"r_m3_d\", np.nan),\n",
    "                         \"ultima_medicion\": rec.get(\"ultima_medicion\", pd.NaT)},\n",
    "                        day_date\n",
    "                    )\n",
    "                    rows.append({\n",
    "                        \"Plan_Fecha\": day_date.date(),\n",
    "                        \"Semana_ISO\": day_date.isocalendar()[1],\n",
    "                        \"Equipo\": int(eq),\n",
    "                        \"Dia_Idx\": d+1,\n",
    "                        \"Orden\": ord_idx,\n",
    "                        \"ZONA\": rec.get(\"ZONA\",\"\"),\n",
    "                        \"BATERIA\": rec.get(\"BATERIA\",\"\"),\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": float(rec.get(\"__v\", rec.get(\"r_m3_d\", np.nan))),\n",
    "                        \"Vol_Estimado_m3\": round(float(v_est), 2),\n",
    "                        \"Seed_POZO\": \"\",\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": round(\n",
    "                            float(haversine_km(c_lat, c_lon, rec.get(\"LAT\"), rec.get(\"LON\"))), 3\n",
    "                        ) if not (pd.isna(rec.get(\"LAT\")) or pd.isna(rec.get(\"LON\"))) else None,\n",
    "                        \"ultima_medicion\": rec.get(\"ultima_medicion\", pd.NaT),\n",
    "                        \"ClusterID\": cid,\n",
    "                        \"Centroide_LAT\": c_lat,\n",
    "                        \"Centroide_LON\": c_lon,\n",
    "                    })\n",
    "                    ord_idx += 1\n",
    "\n",
    "                # marcar usados: hoy y en la semana\n",
    "                used_today.update(pozos)\n",
    "                used_week.update(pozos)\n",
    "\n",
    "        # verificación de no-duplicación diaria (opcional)\n",
    "        if rows:\n",
    "            plan_day = pd.DataFrame(rows)\n",
    "            same_day = plan_day[plan_day[\"Plan_Fecha\"] == day_date.date()]\n",
    "            if not same_day.empty:\n",
    "                dup = same_day.groupby([\"Plan_Fecha\",\"POZO\"]).size().max()\n",
    "                assert int(dup) == 1, \"Un pozo se repite el mismo día.\"\n",
    "\n",
    "\n",
    "    cols = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "            \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "            \"Seed_POZO\",\"Dist_km_semilla\",\"Dist_km_centroid\",\"ultima_medicion\",\n",
    "            \"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\"]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "# (Se elimina la versión anterior _fill_day_star_clusters: ahora ya no se usa.)\n",
    "\n",
    "def ensure_annual_coverage_zone_locked(all_pozos_df, plan, params, start_date, equipo_to_zona,\n",
    "                                       allowed_bats_by_zone_norm=None, r_by_pozo=None):\n",
    "    cap_pz = params[\"max_pozos_dia_equipo\"]\n",
    "\n",
    "    keys = []\n",
    "    for w in range(params[\"semanas_plan\"]):\n",
    "        w_start = start_date + timedelta(weeks=w)\n",
    "        for d in range(params[\"dias_por_semana\"]):\n",
    "            f = w_start + timedelta(days=d)\n",
    "            for e in equipo_to_zona.keys():\n",
    "                keys.append((e, f))\n",
    "\n",
    "    if not plan.empty:\n",
    "        plan[\"__key\"] = plan[\"Equipo\"].astype(int).astype(str) + \"|\" + plan[\"Plan_Fecha\"].astype(str)\n",
    "        used_counts = plan.groupby(\"__key\")[\"POZO\"].count().to_dict()\n",
    "    else:\n",
    "        used_counts = {}\n",
    "\n",
    "    planned = set(plan[\"POZO\"].unique()) if not plan.empty else set()\n",
    "    missing_df = all_pozos_df[~all_pozos_df[\"POZO\"].isin(planned)].copy()\n",
    "    missing_df = missing_df[missing_df[\"BATERIA\"].notna() & (missing_df[\"BATERIA\"].astype(str).str.strip()!=\"\")].copy()\n",
    "\n",
    "    add = []\n",
    "    for _, row in missing_df.iterrows():\n",
    "        pz = row[\"POZO\"]; z = row[\"ZONA\"]\n",
    "        bat = row.get(\"BATERIA\", \"\")\n",
    "\n",
    "        if not isinstance(bat, str) or bat.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            zn = _norm(z)\n",
    "            bats_allowed = allowed_bats_by_zone_norm.get(zn)\n",
    "            if bats_allowed is not None:\n",
    "                if _norm(bat) not in bats_allowed:\n",
    "                    continue\n",
    "\n",
    "        if r_by_pozo is not None:\n",
    "            r_val = float(r_by_pozo.get(pz, np.nan))\n",
    "            if not (r_val > RM3D_MIN):\n",
    "                continue\n",
    "\n",
    "        target_teams = [e for e, zona in equipo_to_zona.items() if zona == z]\n",
    "        if not target_teams:\n",
    "            continue\n",
    "        placed = False\n",
    "        for e in target_teams:\n",
    "            for (ee, f) in keys:\n",
    "                if ee != e:\n",
    "                    continue\n",
    "                key = f\"{e}|{f}\"\n",
    "                cnt = used_counts.get(key, 0)\n",
    "                if cnt < cap_pz:\n",
    "                    add.append({\n",
    "                        \"Plan_Fecha\": f,\n",
    "                        \"Semana_ISO\": f.isocalendar()[1],\n",
    "                        \"Equipo\": int(e),\n",
    "                        \"Dia_Idx\": f.weekday()+1,\n",
    "                        \"Orden\": cnt+1,\n",
    "                        \"ZONA\": z,\n",
    "                        \"BATERIA\": bat,\n",
    "                        \"POZO\": pz,\n",
    "                        \"r_m3_d\": np.nan,\n",
    "                        \"Vol_Estimado_m3\": 0.0,\n",
    "                        \"Seed_POZO\": \"\",\n",
    "                        \"Dist_km_semilla\": None,\n",
    "                        \"Dist_km_centroid\": None,\n",
    "                        \"ultima_medicion\": pd.NaT,\n",
    "                        \"ClusterID\": \"\",\n",
    "                        \"Centroide_LAT\": np.nan,\n",
    "                        \"Centroide_LON\": np.nan,\n",
    "                    })\n",
    "                    used_counts[key] = cnt+1\n",
    "                    placed = True\n",
    "                    break\n",
    "            if placed:\n",
    "                break\n",
    "\n",
    "    if add:\n",
    "        plan = pd.concat([plan, pd.DataFrame(add)], ignore_index=True)                 .sort_values([\"Plan_Fecha\",\"Equipo\",\"Orden\"])\n",
    "    return plan\n",
    "\n",
    "def build_alertas_abm(freq_df: pd.DataFrame, norm_table: pd.DataFrame, dict_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = freq_df[[\"POZO\",\"ZONA\",\"BATERIA\",\"ultima_medicion\",\"ultima_exitosa\"]].copy()\n",
    "    meta_first = dict_df.groupby(\"oficial\")[[\"estado\",\"met_prod\",\"nivel_3\",\"nivel_5\"]].first()\n",
    "    base = base.merge(meta_first[[\"estado\",\"met_prod\"]], left_on=\"POZO\", right_index=True, how=\"left\")\n",
    "\n",
    "    out = base.copy()\n",
    "    for c in [\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "        out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "    out = out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ============================================\n",
    "# HARNES PARA JUPYTER\n",
    "# ============================================\n",
    "def run_pipeline_jupyter(\n",
    "    input_file,\n",
    "    nombres_pozo_file,\n",
    "    coords_file,\n",
    "    *,\n",
    "    semanas_plan=2,\n",
    "    equipos_activos=2,\n",
    "    dias_por_semana=5,\n",
    "    max_pozos_dia_equipo=10,\n",
    "    K_max_pozos_por_cluster=5,\n",
    "    clusters_por_dia_max=None,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=3.0,\n",
    "    rm3d_min=0.1,\n",
    "    zonas_incluir=None,\n",
    "    baterias_por_zona=None,      # {\"las heras cg - canadon escondida\": {\"swabing ce\",\"ce 04\"}}\n",
    "    pozos_excluir=None,\n",
    "    escribir_excel=False\n",
    "):\n",
    "    global INPUT_FILE, NOMBRES_POZO_FILE, COORDS_FILE, RADIUS_KM, RM3D_MIN, DEFAULTS\n",
    "    INPUT_FILE       = input_file\n",
    "    NOMBRES_POZO_FILE= nombres_pozo_file\n",
    "    COORDS_FILE      = coords_file\n",
    "    RADIUS_KM        = float(radius_km)\n",
    "    RM3D_MIN         = float(rm3d_min)\n",
    "\n",
    "    DEFAULTS = DEFAULTS.copy()\n",
    "    DEFAULTS.update({\n",
    "        \"equipos_activos\": int(equipos_activos),\n",
    "        \"dias_por_semana\": int(dias_por_semana),\n",
    "        \"semanas_plan\": int(semanas_plan),\n",
    "        \"max_pozos_dia_equipo\": int(max_pozos_dia_equipo),\n",
    "        \"max_pozos_por_cluster\": int(K_max_pozos_por_cluster),\n",
    "        \"clusters_por_dia_max\": clusters_por_dia_max,\n",
    "        \"backfill_nearest_cluster\": bool(backfill_nearest),\n",
    "        \"umbral_km_backfill\": float(umbral_km_backfill),\n",
    "    })\n",
    "\n",
    "    # 1) Lee historial (Excel del usuario)\n",
    "    df = read_historial(INPUT_FILE, SHEET_HIST)\n",
    "\n",
    "    # 2) Normalización por diccionario\n",
    "    key2off, dict_df = load_pozo_dictionary(NOMBRES_POZO_FILE)\n",
    "    df_norm, alert_table, norm_table = apply_pozo_normalization(df, key2off, dict_df)\n",
    "\n",
    "    # 3) Filtra inválidos\n",
    "    df = df_norm[df_norm[\"VALIDO_POZO\"] == True].copy()\n",
    "\n",
    "    # 4) Filtro por ZONA (si se pide explícito)\n",
    "    if zonas_incluir:\n",
    "        zonas_incluir = set(zonas_incluir)\n",
    "        znorm = {_norm(z) for z in zonas_incluir}\n",
    "        df = df[df[\"__ZONA_NORM\"].isin(znorm)].copy()\n",
    "        zonas_labels = zonas_incluir\n",
    "        zonas_norm   = znorm\n",
    "    else:\n",
    "        mask_valid = df[\"ZONA\"].notna() & (df[\"ZONA\"].astype(str).str.strip() != \"\")\n",
    "        zonas_labels = set(df.loc[mask_valid, \"ZONA\"].astype(str))\n",
    "        zonas_norm   = set(df.loc[mask_valid, \"__ZONA_NORM\"].astype(str))\n",
    "\n",
    "    # 5) Sub-filtro de baterías (si lo pasaste por parámetro)\n",
    "    if baterias_por_zona:\n",
    "        allowed_bats_by_zone_norm = {zn: set(baterias_por_zona[zn]) if baterias_por_zona[zn] is not None else None\n",
    "                                     for zn in baterias_por_zona}\n",
    "    else:\n",
    "        allowed_bats_by_zone_norm = {zn: None for zn in zonas_norm}\n",
    "\n",
    "    # 6) Exclusiones (si te pasan un set)\n",
    "    excl_total = set(pozos_excluir or [])\n",
    "\n",
    "    # 7) Frecuencias\n",
    "    params = DEFAULTS.copy()\n",
    "    freq = compute_frecuencias(df, params)\n",
    "\n",
    "    # Comentarios desde OBS cuando ultima_medicion != ultima_exitosa\n",
    "    df_obs = df[[\"POZO\", \"FECHA\", \"OBS_POZO\"]].copy() if \"OBS_POZO\" in df.columns else pd.DataFrame(columns=[\"POZO\",\"FECHA\",\"OBS_POZO\"])\n",
    "    df_obs[\"FECHA_DATE\"] = pd.to_datetime(df_obs[\"FECHA\"], errors=\"coerce\").dt.date\n",
    "    df_obs = (df_obs.dropna(subset=[\"FECHA_DATE\"])\n",
    "                    .sort_values([\"POZO\",\"FECHA_DATE\"])\n",
    "                    .drop_duplicates(subset=[\"POZO\",\"FECHA_DATE\"], keep=\"last\"))\n",
    "    obs_map = {(r.POZO, r.FECHA_DATE): (str(r.OBS_POZO).strip() if pd.notna(r.OBS_POZO) else \"\")\n",
    "               for r in df_obs.itertuples(index=False)}\n",
    "    freq[\"__UMED_DATE\"] = pd.to_datetime(freq[\"ultima_medicion\"], errors=\"coerce\").dt.date\n",
    "    freq[\"__UEXI_DATE\"] = pd.to_datetime(freq[\"ultima_exitosa\"], errors=\"coerce\").dt.date\n",
    "    freq[\"comentario\"] = [obs_map.get((pz, fmed), \"\") for pz, fmed in zip(freq[\"POZO\"], freq[\"__UMED_DATE\"])]\n",
    "    mask_both_valid = freq[\"__UMED_DATE\"].notna() & freq[\"__UEXI_DATE\"].notna()\n",
    "    mask_diff = mask_both_valid & (freq[\"__UMED_DATE\"] != freq[\"__UEXI_DATE\"])\n",
    "    freq.loc[~mask_diff, \"comentario\"] = \"\"\n",
    "    freq.drop(columns=[\"__UMED_DATE\",\"__UEXI_DATE\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # 8) Coordenadas\n",
    "    coords_df = read_coords(COORDS_FILE)\n",
    "\n",
    "    # 9) Mapas auxiliares\n",
    "    delta_by_pozo = freq.set_index(\"POZO\")[\"delta_star_dias\"].to_dict()\n",
    "    r_by_pozo     = freq.set_index(\"POZO\")[\"r_m3_d\"].to_dict()\n",
    "\n",
    "    # 10) Semanas a planificar\n",
    "    start = next_monday(date.today())\n",
    "    weeks = [(start + timedelta(weeks=i), start + timedelta(weeks=i, days=6)) for i in range(params[\"semanas_plan\"])]\n",
    "\n",
    "    # 11) Equipos -> ZONA (fijo)\n",
    "    zonas_list = sorted(zonas_labels)\n",
    "    if not zonas_list:\n",
    "        raise ValueError(\"No hay ZONAS válidas (todas vacías).\")\n",
    "\n",
    "    equipo_to_zona = {}\n",
    "    for i in range(1, params[\"equipos_activos\"]+1):\n",
    "        zona_asignada = zonas_list[min(i-1, len(zonas_list)-1)]\n",
    "        equipo_to_zona[i] = zona_asignada\n",
    "\n",
    "    # 12) Plan semanal por ZONA usando la versión V2 (clústeres)\n",
    "    plan_all = []\n",
    "    next_due = {row.POZO: row.proxima_visita_base for row in freq.itertuples()}\n",
    "    zone_to_teams = {}\n",
    "    for eq, zona_label in equipo_to_zona.items():\n",
    "        zone_to_teams.setdefault(zona_label, []).append(eq)\n",
    "\n",
    "    for (w_start, w_end) in weeks:\n",
    "        for zona_label, team_list in zone_to_teams.items():\n",
    "            zona_norm_label = _norm(zona_label)\n",
    "            cand_all = build_candidates_with_coords(\n",
    "                freq=freq,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                excl_pozos=excl_total,\n",
    "                zonas_norm_incluidas={zona_norm_label},\n",
    "                coords_df=coords_df,\n",
    "                allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "                next_due_map=next_due\n",
    "            )\n",
    "            if cand_all.empty:\n",
    "                continue\n",
    "\n",
    "            cand_zone = cand_all[[  # mantener las columnas necesarias\n",
    "                \"POZO\",\"ZONA\",\"BATERIA\",\"due_date\",\"is_overdue\",\"__v\",\n",
    "                \"LAT\",\"LON\",\"has_coords\",\"r_m3_d\",\"ultima_medicion\"\n",
    "            ]].copy()\n",
    "\n",
    "            plan_week_zone = assign_week_round_robin_by_zone(\n",
    "                cand_all=cand_zone,\n",
    "                team_ids=sorted(team_list),\n",
    "                params=params,\n",
    "                week_start=w_start,\n",
    "                week_end=w_end,\n",
    "                radius_km=RADIUS_KM\n",
    "            )\n",
    "\n",
    "            if not plan_week_zone.empty:\n",
    "                plan_all.append(plan_week_zone)\n",
    "                # actualizar next_due por pozo asignado\n",
    "                for pz, fcal in plan_week_zone[[\"POZO\",\"Plan_Fecha\"]].drop_duplicates().itertuples(index=False):\n",
    "                    dd = int(delta_by_pozo.get(pz, params[\"min_dias_freq\"]))\n",
    "                    next_due[pz] = pd.Timestamp(fcal) + pd.Timedelta(days=dd)\n",
    "\n",
    "    plan = (pd.concat(plan_all, ignore_index=True)\n",
    "            if plan_all else\n",
    "            pd.DataFrame(columns=[\n",
    "                \"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\"ZONA\",\"BATERIA\",\n",
    "                \"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\"Seed_POZO\",\"Dist_km_semilla\",\n",
    "                \"Dist_km_centroid\",\"ultima_medicion\",\"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\",\"Cluster_Score\"\n",
    "            ]))\n",
    "\n",
    "    # 13) Cobertura anual reforzada (opcional) — mantiene tu lógica original (no forma clúster)\n",
    "    if not freq.empty:\n",
    "        eligible_mask = (freq[\"ZONA\"].isin(zonas_labels)) & (freq[\"r_m3_d\"].fillna(0) > RM3D_MIN)\n",
    "        if \"comentario\" in freq.columns:\n",
    "            eligible_mask &= (freq[\"comentario\"].astype(str).fillna(\"\").str.strip() == \"\")\n",
    "        if allowed_bats_by_zone_norm:\n",
    "            for zn, bats in allowed_bats_by_zone_norm.items():\n",
    "                if bats is not None:\n",
    "                    eligible_mask &= (~(freq[\"ZONA_NORM\"] == zn)) | (freq[\"BATERIA_NORM\"].isin(bats))\n",
    "\n",
    "        all_pozos_in_zonas = freq.loc[eligible_mask, [\"POZO\",\"ZONA\",\"BATERIA\"]].drop_duplicates().copy()\n",
    "        all_pozos_in_zonas = all_pozos_in_zonas[\n",
    "            all_pozos_in_zonas[\"BATERIA\"].notna() & (all_pozos_in_zonas[\"BATERIA\"].astype(str).str.strip() != \"\")\n",
    "        ].copy()\n",
    "\n",
    "        # usa el filler original (sin clúster) SOLO para cubrir huecos anuales\n",
    "     #   plan = ensure_annual_coverage_zone_locked(\n",
    "      #      all_pozos_df=all_pozos_in_zonas,\n",
    "       #     plan=plan,\n",
    "        #    params=params,\n",
    "         #   start_date=start,\n",
    "          #  equipo_to_zona=equipo_to_zona,\n",
    "           # allowed_bats_by_zone_norm=allowed_bats_by_zone_norm,\n",
    "            #r_by_pozo=r_by_pozo\n",
    "       # )\n",
    "\n",
    "    # 14) Export opcional (agrego columnas nuevas de clúster)\n",
    "    out_xlsx = None\n",
    "    if escribir_excel:\n",
    "        out_xlsx = unique_output_path(INPUT_FILE)\n",
    "        coords_all = read_coords(COORDS_FILE)\n",
    "        with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "            # Frecuencias\n",
    "            freq_out = freq.copy()\n",
    "            for c in [\"proxima_visita_base\",\"ultima_medicion\",\"ultima_exitosa\"]:\n",
    "                freq_out[c] = pd.to_datetime(freq_out[c], errors=\"coerce\").dt.date\n",
    "            freq_out = freq_out.sort_values([\"ZONA\",\"BATERIA\",\"POZO\"])\n",
    "            cols_pref = [\"POZO\",\"ZONA\",\"BATERIA\",\"ZONA_NORM\",\"BATERIA_NORM\",\"r_m3_d\",\n",
    "                         \"ultima_medicion\",\"ultima_exitosa\",\"delta_star_dias\",\"comentario\",\n",
    "                         \"proxima_visita_base\",\"ceros_consec\",\"alerta\"]\n",
    "            cols_final = [c for c in cols_pref if c in freq_out.columns] + \\\n",
    "                         [c for c in freq_out.columns if c not in cols_pref]\n",
    "            freq_out = freq_out[cols_final]\n",
    "            freq_out.to_excel(writer, \"Frecuencias\", index=False)\n",
    "\n",
    "            # Plan por equipo + Km_al_siguiente\n",
    "            cols_plan = [\"Plan_Fecha\",\"Semana_ISO\",\"Equipo\",\"Dia_Idx\",\"Orden\",\n",
    "                         \"ZONA\",\"BATERIA\",\"POZO\",\"r_m3_d\",\"Vol_Estimado_m3\",\n",
    "                         \"ClusterID\",\"Centroide_LAT\",\"Centroide_LON\",\"Cluster_Score\",\n",
    "                         \"Dist_km_centroid\"]\n",
    "            for eq in range(1, params[\"equipos_activos\"]+1):\n",
    "                pe = plan.loc[plan[\"Equipo\"]==eq].copy()\n",
    "                if pe.empty:\n",
    "                    pe = pd.DataFrame(columns=cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"])\n",
    "                else:\n",
    "                    pe = pe.sort_values([\"Plan_Fecha\",\"Dia_Idx\",\"Orden\",\"POZO\"]).copy()\n",
    "                    pe = pe.merge(coords_all, how=\"left\", on=\"POZO\")\n",
    "                    pe[\"LAT_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LAT\"].shift(-1)\n",
    "                    pe[\"LON_next\"] = pe.groupby([\"Plan_Fecha\",\"Dia_Idx\"])[\"LON\"].shift(-1)\n",
    "                    def _leg_km(row):\n",
    "                        if (pd.isna(row.get(\"LAT\")) or pd.isna(row.get(\"LON\")) or\n",
    "                            pd.isna(row.get(\"LAT_next\")) or pd.isna(row.get(\"LON_next\"))):\n",
    "                            return None\n",
    "                        return round(float(haversine_km(row[\"LAT\"], row[\"LON\"],\n",
    "                                                        row[\"LAT_next\"], row[\"LON_next\"])), 3)\n",
    "                    pe[\"Km_al_siguiente\"] = pe.apply(_leg_km, axis=1)\n",
    "                    pe.drop(columns=[\"LAT\",\"LON\",\"LAT_next\",\"LON_next\"], inplace=True, errors=\"ignore\")\n",
    "                    pe[\"Ejecutado\"] = \"\"\n",
    "                    for c in cols_plan:\n",
    "                        if c not in pe.columns: pe[c] = \"\"\n",
    "                    pe = pe[cols_plan + [\"Km_al_siguiente\",\"Ejecutado\"]]\n",
    "                pe.to_excel(writer, f\"Plan_Equipo_{eq}\", index=False)\n",
    "\n",
    "            # Auxiliares\n",
    "            pd.DataFrame(list(params.items()), columns=[\"Parametro\",\"Valor\"]).to_excel(writer, \"Parametros_Usados\", index=False)\n",
    "\n",
    "    # ====== Asserts/chequeos mínimos ======\n",
    "    # ====== Asserts/chequeos mínimos ======\n",
    "    if not plan.empty:\n",
    "        K_chk = int(params.get(\"max_pozos_por_cluster\", 5))\n",
    "\n",
    "        # ✅ Validar SOLO clústeres reales (ClusterID no vacío)\n",
    "        mask_real = plan[\"ClusterID\"].notna() & (plan[\"ClusterID\"].astype(str).str.strip() != \"\")\n",
    "        gsize = (plan.loc[mask_real]\n",
    "                 .groupby([\"Plan_Fecha\",\"Equipo\",\"ClusterID\"])[\"POZO\"]\n",
    "                 .count())\n",
    "\n",
    "        if not gsize.empty:\n",
    "            assert (gsize % K_chk == 0).all(), \"Hay clústeres asignados que no cumplen tamaño K exacto.\"\n",
    "\n",
    "        # ✅ No duplicación diaria (ningún pozo se repite en el mismo día)\n",
    "        dupmax = plan.groupby([\"Plan_Fecha\",\"POZO\"]).size().max()\n",
    "        assert int(dupmax) == 1, \"Un pozo aparece más de una vez en el mismo día.\"\n",
    "\n",
    "        # ✅ Radio cumplido (tolerancia numérica)\n",
    "        if \"Dist_km_centroid\" in plan.columns and plan[\"Dist_km_centroid\"].notna().any():\n",
    "            assert float(plan[\"Dist_km_centroid\"].fillna(0).max()) <= float(RADIUS_KM) + 1e-6, \\\n",
    "                \"Distancia a centroide excede el radio.\"\n",
    "\n",
    "    return plan, freq, out_xlsx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# RUNNER (EDITÁ TUS RUTAS Y PARÁMETROS ACÁ)\n",
    "# ============================================\n",
    "\n",
    "INPUT_FILE = r\"C:\\Users\\ry16123\\Downloads\\CÑE   FLUG S.A 2025 2.xlsx\"\n",
    "NOMBRES_POZO_FILE = r\"C:\\Users\\ry16123\\export_org_estructural\\Nombres-Pozo.xlsx\"\n",
    "COORDS_FILE = r\"C:\\Users\\ry16123\\OneDrive - YPF\\Escritorio\\power BI\\GUADAL- POWER BI\\Inteligencia Artificial\\coordenadas1.xlsx\"\n",
    "\n",
    "plan, freq, out_xlsx = run_pipeline_jupyter(\n",
    "    input_file=INPUT_FILE,\n",
    "    nombres_pozo_file=NOMBRES_POZO_FILE,\n",
    "    coords_file=COORDS_FILE,\n",
    "    semanas_plan=2,                 # probá corto para iterar rápido\n",
    "    equipos_activos=2,              # cantidad de equipos\n",
    "    dias_por_semana=5,              # 5 ó 6\n",
    "    max_pozos_dia_equipo=4,\n",
    "    K_max_pozos_por_cluster=4,      # tamaño máximo de clúster\n",
    "    clusters_por_dia_max=4,\n",
    "    backfill_nearest=True,\n",
    "    umbral_km_backfill=5.0,\n",
    "    radius_km=4.0,\n",
    "    rm3d_min=0.01,\n",
    "    zonas_incluir=None,             # o lista como [\"Las Heras CG - Canadon Escondida\"]\n",
    "    baterias_por_zona=None,         # dict normalizado (keys en _norm) o None\n",
    "    pozos_excluir=set(),            # ej.: {\"BB-100\"}\n",
    "    escribir_excel=True            # poné True si querés exportar el Excel\n",
    ")\n",
    "\n",
    "# Mostrar un vistazo rápido\n",
    "display(freq.head(10))\n",
    "display(plan.head(30))\n",
    "print(\"Excel generado:\", out_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61884be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CursoML-UDEMY)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
