{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f0b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargadas 5 series | 9,058 muestras\n",
      "Eventos detectados en hojas: 5\n",
      "[OK] Guardé eventos detectados en aib_eventos_detectados.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:102: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:123: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return np.nan if n < 2 else (x[-1] - x[0]) / (n - 1)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:102: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:123: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return np.nan if n < 2 else (x[-1] - x[0]) / (n - 1)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:102: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:123: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return np.nan if n < 2 else (x[-1] - x[0]) / (n - 1)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:102: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:123: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return np.nan if n < 2 else (x[-1] - x[0]) / (n - 1)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:102: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\547717204.py:123: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return np.nan if n < 2 else (x[-1] - x[0]) / (n - 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5608\n",
      "PR-AUC : 0.0716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.942     0.945     0.943     11527\n",
      "           1      0.068     0.064     0.066       720\n",
      "\n",
      "    accuracy                          0.893     12247\n",
      "   macro avg      0.505     0.504     0.505     12247\n",
      "weighted avg      0.890     0.893     0.892     12247\n",
      "\n",
      "[OK] Guardé importancias proxy en aib_feature_importances.csv\n",
      "[OK] Guardé probabilidades por timestamp en aib_pred_probas.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "AIB pre-falla desde Excel multi-sheet\n",
    "- Cada hoja = un pozo (sheet name = well_id)\n",
    "- Columnas en cada hoja: Fecha, VIBR\n",
    "- Si alguna fila trae 'FALLA' en VIBR, se usa como evento y se remueve de la señal\n",
    "- Resampleo (30 min), features rolling, etiquetado pre-falla (72h), modelo y métricas\n",
    "\n",
    "Requisitos: pandas, numpy, scikit-learn\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "INPUT_XLSX = \"vibraciones_multi.xlsx\"  # <<< tu archivo Excel\n",
    "RESAMPLE_RULE = \"30min\"                # ej. \"15min\", \"1H\"\n",
    "FEATURE_WINDOW = \"12H\"\n",
    "FEATURE_MIN_SAMPLES = 6\n",
    "ALERTA_HORAS = 72\n",
    "COOLDOWN_HORAS = 6\n",
    "N_SPLITS = 4\n",
    "UMBRAL_ALERTA = 0.35\n",
    "SEED = 42\n",
    "\n",
    "OUT_PROBAS_CSV = \"aib_pred_probas.csv\"\n",
    "OUT_IMPORTANCES_CSV = \"aib_feature_importances.csv\"\n",
    "OUT_EVENTOS_DETECTADOS = \"aib_eventos_detectados.csv\"\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "def cargar_excel_multipozo(path_xlsx: str):\n",
    "    \"\"\"Lee todas las hojas del Excel. Cada hoja debe tener Fecha y VIBR.\n",
    "       El nombre de la hoja se usa como well_id. Detecta filas con 'FALLA'.\"\"\"\n",
    "    xls = pd.read_excel(path_xlsx, sheet_name=None, dtype=str)\n",
    "    frames = []\n",
    "    eventos = []\n",
    "\n",
    "    for sheet_name, df in xls.items():\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "\n",
    "        # Normalización básica\n",
    "        df = df.copy()\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "        colmap = {}\n",
    "        for c in df.columns:\n",
    "            cl = c.lower()\n",
    "            if cl in (\"fecha\", \"timestamp\", \"datetime\"):\n",
    "                colmap[c] = \"timestamp\"\n",
    "            elif cl in (\"vibr\", \"vibraciones\", \"valor\", \"value\"):\n",
    "                colmap[c] = \"vibr\"\n",
    "        df = df.rename(columns=colmap)\n",
    "\n",
    "        if \"timestamp\" not in df.columns or \"vibr\" not in df.columns:\n",
    "            raise ValueError(\n",
    "                f\"La hoja '{sheet_name}' no tiene columnas reconocibles de Fecha/VIBR.\"\n",
    "            )\n",
    "\n",
    "        # Parseo de tiempo (formato dd/mm/yyyy hh:mm es común)\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "        # Detectar FALLA\n",
    "        falla_mask = df[\"vibr\"].astype(str).str.contains(\"FALLA\", case=False, na=False)\n",
    "        if falla_mask.any():\n",
    "            for t in df.loc[falla_mask, \"timestamp\"]:\n",
    "                if pd.notna(t):\n",
    "                    eventos.append({\"well_id\": sheet_name, \"failure_time\": t})\n",
    "\n",
    "        # Filtrar solo filas con valor numérico de vibración\n",
    "        df_num = df.loc[~falla_mask].copy()\n",
    "        df_num[\"vibr\"] = pd.to_numeric(df_num[\"vibr\"], errors=\"coerce\")\n",
    "        df_num = df_num.dropna(subset=[\"timestamp\", \"vibr\"])\n",
    "\n",
    "        if df_num.empty:\n",
    "            continue\n",
    "\n",
    "        df_num.insert(0, \"well_id\", sheet_name)\n",
    "        frames.append(df_num[[\"well_id\", \"timestamp\", \"vibr\"]])\n",
    "\n",
    "    vib = pd.concat(frames, ignore_index=True).sort_values([\"well_id\", \"timestamp\"])\n",
    "    ev = pd.DataFrame(eventos)\n",
    "    if not ev.empty:\n",
    "        ev[\"failure_time\"] = pd.to_datetime(ev[\"failure_time\"])\n",
    "    return vib, ev\n",
    "\n",
    "\n",
    "def resamplear_y_features(vib: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Resamplea por pozo a RESAMPLE_RULE y arma features rolling sobre FEATURE_WINDOW.\"\"\"\n",
    "    feats = []\n",
    "    for well, g in vib.groupby(\"well_id\", sort=False):\n",
    "        g = g.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "        # Resampleo uniforme por tiempo (median + interpolación temporal)\n",
    "        gs = g[\"vibr\"].resample(RESAMPLE_RULE).median()\n",
    "        gs = gs.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "\n",
    "        r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
    "\n",
    "        # Features robustas\n",
    "        f = pd.DataFrame({\n",
    "            \"well_id\": well,\n",
    "            \"t_end\": gs.index,\n",
    "            \"vib_last\": gs.values,\n",
    "            \"vib_mean\": r.mean().values,\n",
    "            \"vib_std\": r.std().values,\n",
    "            \"vib_rms\": np.sqrt(r.apply(lambda x: np.mean(np.square(x)) if len(x)>0 else np.nan).values),\n",
    "            \"vib_p2p\": (r.max() - r.min()).values,\n",
    "            \"vib_iqr\": (r.quantile(0.75) - r.quantile(0.25)).values,\n",
    "            \"vib_med\": r.median().values,\n",
    "            \"vib_mad\": r.apply(lambda x: np.median(np.abs(x - np.median(x))) if len(x)>0 else np.nan).values,\n",
    "            \"vib_diff_mean\": r.apply(lambda x: np.mean(np.abs(np.diff(x))) if len(x)>1 else np.nan).values,\n",
    "        })\n",
    "\n",
    "        # Z-score robusto y pendiente aproximada\n",
    "        f[\"vib_rz\"] = (f[\"vib_last\"] - f[\"vib_med\"]) / f[\"vib_mad\"].replace(0, np.nan)\n",
    "        def slope_approx(x):\n",
    "            n = len(x)\n",
    "            return np.nan if n < 2 else (x[-1] - x[0]) / (n - 1)\n",
    "        f[\"vib_slope\"] = r.apply(slope_approx).values\n",
    "        f[\"vib_cv\"] = f[\"vib_std\"] / (f[\"vib_mean\"].abs() + 1e-9)\n",
    "\n",
    "        f = f.dropna(subset=[\"vib_mean\", \"vib_std\", \"vib_rms\", \"vib_p2p\"])\n",
    "        feats.append(f)\n",
    "\n",
    "    F = pd.concat(feats, ignore_index=True).sort_values([\"well_id\", \"t_end\"])\n",
    "    return F\n",
    "\n",
    "\n",
    "def etiquetar(F: pd.DataFrame, eventos: pd.DataFrame,\n",
    "              alerta_h=72, cooldown_h=6) -> pd.DataFrame:\n",
    "    \"\"\"y=1 si t_end ∈ [failure_time - alerta_h, failure_time); excluye cooldown post-falla.\"\"\"\n",
    "    F = F.copy()\n",
    "    F[\"y\"] = 0\n",
    "    F[\"min_dt_h\"] = np.inf\n",
    "\n",
    "    if eventos is None or eventos.empty:\n",
    "        print(\"Aviso: no hay eventos de falla detectados.\")\n",
    "        return F.dropna(subset=[\"vib_mean\"])\n",
    "\n",
    "    eventos = eventos.sort_values([\"well_id\", \"failure_time\"])\n",
    "    for well, ge in eventos.groupby(\"well_id\"):\n",
    "        mask = F[\"well_id\"] == well\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        t_end = F.loc[mask, \"t_end\"]\n",
    "\n",
    "        for _, row in ge.iterrows():\n",
    "            ft = row[\"failure_time\"]\n",
    "            dt_h = (ft - t_end).dt.total_seconds() / 3600.0\n",
    "\n",
    "            pos = mask & (dt_h >= 0) & (dt_h <= alerta_h)\n",
    "            F.loc[pos, \"y\"] = 1\n",
    "\n",
    "            cool = mask & (dt_h < 0) & (dt_h >= -cooldown_h)\n",
    "            F.loc[cool, \"y\"] = np.nan\n",
    "\n",
    "            F.loc[mask, \"min_dt_h\"] = np.minimum(F.loc[mask, \"min_dt_h\"].values,\n",
    "                                                 np.abs(dt_h).values)\n",
    "\n",
    "    F = F.dropna(subset=[\"y\"]).copy()\n",
    "    F[\"y\"] = F[\"y\"].astype(int)\n",
    "    return F\n",
    "\n",
    "\n",
    "def entrenar_y_evaluar(DS: pd.DataFrame,\n",
    "                       umbral=0.35, n_splits=4, seed=42):\n",
    "    feat_cols = [c for c in DS.columns if c not in {\n",
    "        \"well_id\", \"t_end\", \"y\", \"min_dt_h\", \"vib_med\", \"vib_mad\"\n",
    "    }]\n",
    "    groups = DS[\"well_id\"].astype(str).values\n",
    "\n",
    "    classes = np.unique(DS[\"y\"])\n",
    "    cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=DS[\"y\"])\n",
    "    class_weight = {int(k): float(v) for k, v in zip(classes, cw)}\n",
    "\n",
    "    gkf = GroupKFold(n_splits=max(2, min(n_splits, DS[\"well_id\"].nunique())))\n",
    "    y_true_all, y_pred_all, y_proba_all = [], [], []\n",
    "\n",
    "    for fold, (tr, te) in enumerate(gkf.split(DS[feat_cols], DS[\"y\"], groups)):\n",
    "        Xtr, Xte = DS.iloc[tr][feat_cols], DS.iloc[te][feat_cols]\n",
    "        ytr, yte = DS.iloc[tr][\"y\"], DS.iloc[te][\"y\"]\n",
    "\n",
    "        model = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.08, max_iter=500, min_samples_leaf=20, random_state=seed\n",
    "        )\n",
    "        sw = ytr.map(lambda yy: class_weight[int(yy)]).values\n",
    "        model.fit(Xtr, ytr, sample_weight=sw)\n",
    "\n",
    "        proba = model.predict_proba(Xte)[:, 1]\n",
    "        ypred = (proba >= umbral).astype(int)\n",
    "\n",
    "        y_true_all.extend(yte.tolist())\n",
    "        y_pred_all.extend(ypred.tolist())\n",
    "        y_proba_all.extend(proba.tolist())\n",
    "\n",
    "    print(\"ROC-AUC:\", round(roc_auc_score(y_true_all, y_proba_all), 4))\n",
    "    print(\"PR-AUC :\", round(average_precision_score(y_true_all, y_proba_all), 4))\n",
    "    print(classification_report(y_true_all, y_pred_all, digits=3))\n",
    "\n",
    "    # Modelo final para exportar probabilidades\n",
    "    model_full = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08, max_iter=500, min_samples_leaf=20, random_state=seed\n",
    "    )\n",
    "    sw_full = DS[\"y\"].map(lambda yy: class_weight[int(yy)]).values\n",
    "    model_full.fit(DS[feat_cols], DS[\"y\"], sample_weight=sw_full)\n",
    "\n",
    "    # Importancias proxy (correlación con y, rápida)\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        corrs = {c: np.corrcoef(DS[c].fillna(DS[c].median()), DS[\"y\"])[0, 1] for c in feat_cols}\n",
    "    imp = pd.DataFrame({\"feature\": list(corrs.keys()), \"corr_with_y\": list(corrs.values())}) \\\n",
    "           .sort_values(\"corr_with_y\", ascending=False)\n",
    "    imp.to_csv(OUT_IMPORTANCES_CSV, index=False)\n",
    "    print(f\"[OK] Guardé importancias proxy en {OUT_IMPORTANCES_CSV}\")\n",
    "\n",
    "    return model_full, feat_cols\n",
    "\n",
    "\n",
    "def main():\n",
    "    path = Path(INPUT_XLSX)\n",
    "    assert path.exists(), f\"No encontré el archivo: {path}\"\n",
    "\n",
    "    vib, ev = cargar_excel_multipozo(str(path))\n",
    "    print(f\"Cargadas {vib['well_id'].nunique()} series | {len(vib):,} muestras\")\n",
    "    print(f\"Eventos detectados en hojas: {0 if ev is None else len(ev)}\")\n",
    "    if ev is not None and not ev.empty:\n",
    "        ev.sort_values([\"well_id\", \"failure_time\"]).to_csv(OUT_EVENTOS_DETECTADOS, index=False)\n",
    "        print(f\"[OK] Guardé eventos detectados en {OUT_EVENTOS_DETECTADOS}\")\n",
    "\n",
    "    F = resamplear_y_features(vib)\n",
    "    DS = etiquetar(F, ev, alerta_h=ALERTA_HORAS, cooldown_h=COOLDOWN_HORAS)\n",
    "\n",
    "    if DS[\"y\"].sum() == 0:\n",
    "        print(\"No hay positivos etiquetados. Revisá ALERTA_HORAS o las marcas de FALLA.\")\n",
    "        return\n",
    "\n",
    "    model, feat_cols = entrenar_y_evaluar(DS, umbral=UMBRAL_ALERTA, n_splits=N_SPLITS, seed=SEED)\n",
    "\n",
    "    DS = DS.copy()\n",
    "    DS[\"proba\"] = model.predict_proba(DS[feat_cols])[:, 1]\n",
    "    DS.to_csv(OUT_PROBAS_CSV, index=False)\n",
    "    print(f\"[OK] Guardé probabilidades por timestamp en {OUT_PROBAS_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d34bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "   AIB - Pipeline completo a alertas   \n",
      "=======================================\n",
      "Excel: vibraciones_multi.xlsx\n",
      "Params: ALERTA_H=48h | FEAT_WIN=24H | RESAMPLE=30min | MIN_SAMP=6\n",
      "Regla: UMBRAL=0.7 | CONSEC=2 | COOLDOWN=6h\n",
      "\n",
      "Pozos: 5 | Muestras: 9,058\n",
      "Fallas detectadas: 5\n",
      "[OK] Guardé eventos detectados en aib_eventos_detectados.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:126: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(win, min_periods=min_samp)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:130: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(win, min_periods=min_samp).mean()) ** 0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:131: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:132: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:126: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(win, min_periods=min_samp)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:130: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(win, min_periods=min_samp).mean()) ** 0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:131: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:132: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:126: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(win, min_periods=min_samp)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:130: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(win, min_periods=min_samp).mean()) ** 0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:131: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:132: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:126: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(win, min_periods=min_samp)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:130: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(win, min_periods=min_samp).mean()) ** 0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:131: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:132: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:126: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(win, min_periods=min_samp)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:130: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(win, min_periods=min_samp).mean()) ** 0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:131: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(win, min_periods=min_samp).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\7026908.py:132: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(win, min_periods=min_samp).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MÉTRICAS (validación por pozo) ===\n",
      "ROC-AUC: 0.5535\n",
      "PR-AUC : 0.0465\n",
      "Reporte con umbral de referencia 0.50 (solo informativo):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.959     0.958     0.959     11767\n",
      "           1      0.006     0.006     0.006       480\n",
      "\n",
      "    accuracy                          0.921     12247\n",
      "   macro avg      0.483     0.482     0.483     12247\n",
      "weighted avg      0.922     0.921     0.922     12247\n",
      "\n",
      "[OK] Guardé importancias proxy en aib_feature_importances.csv\n",
      "[OK] Guardé probabilidades por timestamp en aib_pred_probas.csv\n",
      "[OK] Guardé alertas en alertas.csv (total: 40)\n",
      "\n",
      "=== COBERTURA POR EVENTO ===\n",
      "Fallas cubiertas con >=1 alerta previa: 5/5\n",
      "Cobertura evento: 100.0%\n",
      "Anticipo medio (horas) de la PRIMERA alerta por evento: 47.3h\n",
      "\n",
      "Listo. Archivos generados:\n",
      " - alertas.csv\n",
      " - aib_pred_probas.csv\n",
      " - aib_feature_importances.csv\n",
      " - aib_eventos_detectados.csv\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONA BASTANTE BIEN, DA LAS ALERTAS ANTES DE LA FALLA. \n",
    "#\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "AIB - Versión única (corregida, sin 'global') — de Excel multi-hoja a alertas.csv\n",
    "\n",
    "Qué hace:\n",
    "1) Lee 'vibraciones_multi.xlsx' (cada hoja = pozo, columnas: Fecha y VIBR).\n",
    "   - Filas con \"FALLA\" en VIBR marcan la fecha de la caída y NO se usan como señal.\n",
    "2) Resamplea a 30 minutos y calcula indicadores rolling 24 h.\n",
    "3) Etiqueta como \"pre-falla\" las ventanas dentro de las 48 h previas a cada falla.\n",
    "4) Entrena y evalúa un modelo (HistGradientBoosting) con validación por pozo.\n",
    "5) Genera probabilidades por tiempo y arma alertas con: umbral, 2 consecutivas, cooldown.\n",
    "6) Guarda:\n",
    "   - alertas.csv\n",
    "   - aib_pred_probas.csv\n",
    "   - aib_feature_importances.csv\n",
    "   - aib_eventos_detectados.csv\n",
    "\n",
    "Requisitos:\n",
    "    pip install pandas numpy scikit-learn openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ===================== DEFAULTS (podés cambiarlos acá o por CLI) =====================\n",
    "INPUT_XLSX = \"vibraciones_multi.xlsx\"\n",
    "DEFAULT_RESAMPLE_RULE = \"30min\"     # \"15min\", \"1H\", etc.\n",
    "DEFAULT_FEATURE_WINDOW = \"24H\"      # ventana de features (recomendado 24H)\n",
    "DEFAULT_FEATURE_MIN_SAMPLES = 6     # mínimo de puntos válidos dentro de la ventana\n",
    "DEFAULT_ALERTA_HORAS = 48           # horizonte pre-falla a detectar\n",
    "COOLDOWN_HORAS = 6                  # enfriamiento para etiquetado post-falla y para alertas\n",
    "N_SPLITS = 4                        # folds de validación (agrupando por pozo)\n",
    "SEED = 42\n",
    "\n",
    "# Regla de alerta\n",
    "DEFAULT_UMBRAL_ALERTA = 0.70        # umbral alto para bajar falsas\n",
    "DEFAULT_CONSECUTIVAS = 2            # exigir 2 lecturas seguidas >= umbral\n",
    "DEFAULT_COOLDOWN_ALERTA_H = 6       # no emitir otra alerta en la misma zona por X horas\n",
    "\n",
    "# Archivos de salida\n",
    "OUT_ALERTAS = \"alertas.csv\"\n",
    "OUT_PROBAS_CSV = \"aib_pred_probas.csv\"\n",
    "OUT_IMPORTANCES_CSV = \"aib_feature_importances.csv\"\n",
    "OUT_EVENTOS_DETECTADOS = \"aib_eventos_detectados.csv\"\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def cargar_excel_multipozo(path_xlsx: str):\n",
    "    \"\"\"Lee todas las hojas del Excel. Cada hoja debe tener Fecha y VIBR.\n",
    "       El nombre de la hoja se usa como well_id. Detecta filas con 'FALLA'.\"\"\"\n",
    "    xls = pd.read_excel(path_xlsx, sheet_name=None, dtype=str)\n",
    "    frames = []\n",
    "    eventos = []\n",
    "\n",
    "    for sheet_name, df in xls.items():\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "\n",
    "        df = df.copy()\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "        # Mapear nombres\n",
    "        colmap = {}\n",
    "        for c in df.columns:\n",
    "            cl = c.lower()\n",
    "            if cl in (\"fecha\", \"timestamp\", \"datetime\"):\n",
    "                colmap[c] = \"timestamp\"\n",
    "            elif (cl in (\"vibr\", \"vibraciones\", \"vibracion\", \"valor\", \"value\", \"vibr.\") or cl.startswith(\"vibr\")):\n",
    "                colmap[c] = \"vibr\"\n",
    "        if colmap:\n",
    "            df = df.rename(columns=colmap)\n",
    "        else:\n",
    "            # fallback: primera=fecha, segunda=vibr\n",
    "            if len(df.columns) >= 2:\n",
    "                df = df.rename(columns={df.columns[0]: \"timestamp\", df.columns[1]: \"vibr\"})\n",
    "\n",
    "        if \"timestamp\" not in df.columns or \"vibr\" not in df.columns:\n",
    "            raise ValueError(f\"La hoja '{sheet_name}' no tiene columnas reconocibles de Fecha/VIBR.\")\n",
    "\n",
    "        # Parsear tiempo dd/mm/yyyy hh:mm típico\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "        # Detectar FALLA\n",
    "        falla_mask = df[\"vibr\"].astype(str).str.contains(\"FALLA\", case=False, na=False)\n",
    "        if falla_mask.any():\n",
    "            for t in df.loc[falla_mask, \"timestamp\"]:\n",
    "                if pd.notna(t):\n",
    "                    eventos.append({\"well_id\": sheet_name, \"failure_time\": t})\n",
    "\n",
    "        # Filas numéricas\n",
    "        df_num = df.loc[~falla_mask].copy()\n",
    "        df_num[\"vibr\"] = pd.to_numeric(df_num[\"vibr\"], errors=\"coerce\")\n",
    "        df_num = df_num.dropna(subset=[\"timestamp\", \"vibr\"])\n",
    "        if df_num.empty:\n",
    "            continue\n",
    "\n",
    "        df_num.insert(0, \"well_id\", sheet_name)\n",
    "        frames.append(df_num[[\"well_id\", \"timestamp\", \"vibr\"]])\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"No se encontraron datos numéricos de vibración en el Excel.\")\n",
    "\n",
    "    vib = pd.concat(frames, ignore_index=True).sort_values([\"well_id\", \"timestamp\"])\n",
    "    ev = pd.DataFrame(eventos)\n",
    "    if not ev.empty:\n",
    "        ev[\"failure_time\"] = pd.to_datetime(ev[\"failure_time\"], errors=\"coerce\")\n",
    "    return vib, ev\n",
    "\n",
    "\n",
    "def features_por_pozo(g: pd.DataFrame,\n",
    "                      rule: str,\n",
    "                      win: str,\n",
    "                      min_samp: int) -> pd.DataFrame:\n",
    "    \"\"\"Resamplea por pozo y arma features rolling (parámetros explícitos, sin global).\"\"\"\n",
    "    g = g.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "    gs = g[\"vibr\"].resample(rule).median().interpolate(method=\"time\", limit_direction=\"both\")\n",
    "\n",
    "    r = gs.rolling(win, min_periods=min_samp)\n",
    "    mean = r.mean()\n",
    "    std = r.std()\n",
    "    p2p = r.max() - r.min()\n",
    "    rms = (gs.pow(2).rolling(win, min_periods=min_samp).mean()) ** 0.5\n",
    "    diff_abs_mean = gs.diff().abs().rolling(win, min_periods=min_samp).mean()\n",
    "    slope = gs.diff().rolling(win, min_periods=min_samp).mean()\n",
    "    cv = std / (mean.abs() + 1e-9)\n",
    "\n",
    "    F = pd.DataFrame({\n",
    "        \"t_end\": gs.index,\n",
    "        \"vib_last\": gs.values,\n",
    "        \"vib_mean\": mean.values,\n",
    "        \"vib_std\": std.values,\n",
    "        \"vib_rms\": rms.values,\n",
    "        \"vib_p2p\": p2p.values,\n",
    "        \"vib_diff_mean\": diff_abs_mean.values,\n",
    "        \"vib_slope\": slope.values,\n",
    "        \"vib_cv\": cv.values\n",
    "    }).dropna(subset=[\"vib_mean\", \"vib_std\", \"vib_rms\", \"vib_p2p\"])\n",
    "    return F\n",
    "\n",
    "\n",
    "def construir_dataset(vib: pd.DataFrame,\n",
    "                      rule: str,\n",
    "                      feature_window: str,\n",
    "                      min_samp: int) -> pd.DataFrame:\n",
    "    \"\"\"Construye el dataset de features para todos los pozos (parámetros explícitos).\"\"\"\n",
    "    feats = []\n",
    "    for well, g in vib.groupby(\"well_id\", sort=False):\n",
    "        F = features_por_pozo(g, rule=rule, win=feature_window, min_samp=min_samp)\n",
    "        if not F.empty:\n",
    "            F.insert(0, \"well_id\", well)\n",
    "            feats.append(F)\n",
    "    if not feats:\n",
    "        raise ValueError(\"No se pudieron construir features (¿pocos datos o NaNs?)\")\n",
    "    return pd.concat(feats, ignore_index=True).sort_values([\"well_id\", \"t_end\"])\n",
    "\n",
    "\n",
    "def etiquetar(F: pd.DataFrame, eventos: pd.DataFrame,\n",
    "              alerta_h: int, cooldown_h: int) -> pd.DataFrame:\n",
    "    \"\"\"Etiqueta y=1 si t_end cae en las 'alerta_h' horas previas a una falla.\"\"\"\n",
    "    F = F.copy()\n",
    "    F[\"y\"] = 0\n",
    "    F[\"min_dt_h\"] = np.inf\n",
    "\n",
    "    if eventos is None or eventos.empty:\n",
    "        print(\"Aviso: no hay eventos de falla detectados.\")\n",
    "        return F.dropna(subset=[\"vib_mean\"])\n",
    "\n",
    "    eventos = eventos.sort_values([\"well_id\", \"failure_time\"])\n",
    "    for well, ge in eventos.groupby(\"well_id\"):\n",
    "        mask = F[\"well_id\"] == well\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        t_end = F.loc[mask, \"t_end\"]\n",
    "\n",
    "        for _, row in ge.iterrows():\n",
    "            ft = row[\"failure_time\"]\n",
    "            dt_h = (ft - t_end).dt.total_seconds() / 3600.0\n",
    "\n",
    "            # Ventanas positivas (pre-falla)\n",
    "            pos = mask & (dt_h >= 0) & (dt_h <= alerta_h)\n",
    "            F.loc[pos, \"y\"] = 1\n",
    "\n",
    "            # Cooldown post-falla (excluir)\n",
    "            cool = mask & (dt_h < 0) & (dt_h >= -cooldown_h)\n",
    "            F.loc[cool, \"y\"] = np.nan\n",
    "\n",
    "            # Distancia temporal mínima a una falla (para info)\n",
    "            F.loc[mask, \"min_dt_h\"] = np.minimum(F.loc[mask, \"min_dt_h\"].values,\n",
    "                                                 np.abs(dt_h).values)\n",
    "\n",
    "    F = F.dropna(subset=[\"y\"]).copy()\n",
    "    F[\"y\"] = F[\"y\"].astype(int)\n",
    "    return F\n",
    "\n",
    "\n",
    "def entrenar_y_evaluar(DS: pd.DataFrame,\n",
    "                       n_splits: int,\n",
    "                       seed: int):\n",
    "    \"\"\"Entrena con validación por pozo y devuelve modelo final + columnas de features.\"\"\"\n",
    "    feat_cols = [c for c in DS.columns if c not in {\n",
    "        \"well_id\", \"t_end\", \"y\", \"min_dt_h\"\n",
    "    }]\n",
    "\n",
    "    groups = DS[\"well_id\"].astype(str).values\n",
    "    classes = np.unique(DS[\"y\"])\n",
    "    cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=DS[\"y\"])\n",
    "    class_weight = {int(k): float(v) for k, v in zip(classes, cw)}\n",
    "\n",
    "    gkf = GroupKFold(n_splits=max(2, min(n_splits, DS[\"well_id\"].nunique())))\n",
    "    y_true_all, y_pred_all, y_proba_all = [], [], []\n",
    "\n",
    "    for fold, (tr, te) in enumerate(gkf.split(DS[feat_cols], DS[\"y\"], groups)):\n",
    "        Xtr, Xte = DS.iloc[tr][feat_cols], DS.iloc[te][feat_cols]\n",
    "        ytr, yte = DS.iloc[tr][\"y\"], DS.iloc[te][\"y\"]\n",
    "\n",
    "        model = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.08, max_iter=500, min_samples_leaf=20, random_state=seed\n",
    "        )\n",
    "        sw = ytr.map(lambda yy: class_weight[int(yy)]).values\n",
    "        model.fit(Xtr, ytr, sample_weight=sw)\n",
    "\n",
    "        proba = model.predict_proba(Xte)[:, 1]\n",
    "        y_proba_all.extend(proba.tolist())\n",
    "\n",
    "        # Umbral de referencia solo para imprimir (no para operar)\n",
    "        umbral_ref = 0.50\n",
    "        ypred = (proba >= umbral_ref).astype(int)\n",
    "        y_true_all.extend(yte.tolist())\n",
    "        y_pred_all.extend(ypred.tolist())\n",
    "\n",
    "    print(\"\\n=== MÉTRICAS (validación por pozo) ===\")\n",
    "    try:\n",
    "        print(\"ROC-AUC:\", round(roc_auc_score(y_true_all, y_proba_all), 4))\n",
    "        print(\"PR-AUC :\", round(average_precision_score(y_true_all, y_proba_all), 4))\n",
    "    except Exception as e:\n",
    "        print(\"No se pudieron calcular AUCs:\", e)\n",
    "    print(\"Reporte con umbral de referencia 0.50 (solo informativo):\")\n",
    "    print(classification_report(y_true_all, y_pred_all, digits=3))\n",
    "\n",
    "    # Entrenamos el modelo final con TODO el dataset\n",
    "    model_full = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08, max_iter=500, min_samples_leaf=20, random_state=seed\n",
    "    )\n",
    "    sw_full = DS[\"y\"].map(lambda yy: class_weight[int(yy)]).values\n",
    "    model_full.fit(DS[feat_cols], DS[\"y\"], sample_weight=sw_full)\n",
    "\n",
    "    # Importancias \"proxy\" via correlación simple (rápida, orientativa)\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        corrs = {c: np.corrcoef(DS[c].fillna(DS[c].median()), DS[\"y\"])[0, 1] for c in feat_cols}\n",
    "    imp = pd.DataFrame({\"feature\": list(corrs.keys()), \"corr_with_y\": list(corrs.values())}) \\\n",
    "           .sort_values(\"corr_with_y\", ascending=False)\n",
    "    imp.to_csv(OUT_IMPORTANCES_CSV, index=False)\n",
    "    print(f\"[OK] Guardé importancias proxy en {OUT_IMPORTANCES_CSV}\")\n",
    "\n",
    "    return model_full, feat_cols\n",
    "\n",
    "\n",
    "def generar_alertas(df_probas: pd.DataFrame,\n",
    "                    umbral: float,\n",
    "                    consecutivas: int,\n",
    "                    cooldown_h: int) -> pd.DataFrame:\n",
    "    \"\"\"Regla operativa: umbral + N consecutivas + cooldown.\"\"\"\n",
    "    alertas = []\n",
    "    for well, g in df_probas.groupby(\"well_id\", sort=False):\n",
    "        g = g.sort_values(\"t_end\").reset_index(drop=True)\n",
    "        run = 0\n",
    "        last_alert = None\n",
    "        for _, row in g.iterrows():\n",
    "            if row[\"proba\"] >= umbral:\n",
    "                run += 1\n",
    "            else:\n",
    "                run = 0\n",
    "            if run >= consecutivas:\n",
    "                t = row[\"t_end\"]\n",
    "                if (last_alert is None) or ((t - last_alert).total_seconds() >= cooldown_h * 3600):\n",
    "                    alertas.append({\n",
    "                        \"well_id\": well,\n",
    "                        \"t_alerta\": t,\n",
    "                        \"proba\": float(row[\"proba\"]),\n",
    "                        \"y_en_esa_ventana\": int(row.get(\"y\", 0)),\n",
    "                        \"min_dt_h\": float(row.get(\"min_dt_h\", np.nan))\n",
    "                    })\n",
    "                    last_alert = t\n",
    "                run = 0\n",
    "    return pd.DataFrame(alertas).sort_values([\"well_id\", \"t_alerta\"])\n",
    "\n",
    "\n",
    "def cobertura_por_evento(alertas_df: pd.DataFrame, eventos_df: pd.DataFrame,\n",
    "                         alerta_horas: int):\n",
    "    \"\"\"Calcula en cuántas fallas hubo al menos una alerta previa y el anticipo medio.\"\"\"\n",
    "    if alertas_df.empty or eventos_df is None or eventos_df.empty:\n",
    "        return 0, 0, np.nan\n",
    "    cubiertas = 0\n",
    "    leadtimes = []\n",
    "    for _, e in eventos_df.iterrows():\n",
    "        well = e[\"well_id\"]; ft = e[\"failure_time\"]\n",
    "        a = alertas_df[(alertas_df[\"well_id\"] == well)]\n",
    "        a = a[(a[\"t_alerta\"] <= ft) & (a[\"t_alerta\"] >= ft - pd.Timedelta(hours=alerta_horas))]\n",
    "        if not a.empty:\n",
    "            cubiertas += 1\n",
    "            # Tomamos la alerta más temprana dentro de la ventana\n",
    "            lt_h = (ft - a[\"t_alerta\"].min()).total_seconds() / 3600.0\n",
    "            leadtimes.append(lt_h)\n",
    "    total = len(eventos_df)\n",
    "    cobertura = cubiertas / total if total else 0\n",
    "    lead_prom = float(np.mean(leadtimes)) if leadtimes else np.nan\n",
    "    return cubiertas, total, lead_prom\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"AIB - versión única (de Excel a alertas.csv)\")\n",
    "    parser.add_argument(\"--input\", default=INPUT_XLSX, help=\"Ruta del Excel multi-hoja\")\n",
    "    parser.add_argument(\"--umbral\", type=float, default=DEFAULT_UMBRAL_ALERTA, help=\"Umbral de alerta (proba)\")\n",
    "    parser.add_argument(\"--consec\", type=int, default=DEFAULT_CONSECUTIVAS, help=\"Lecturas consecutivas requeridas\")\n",
    "    parser.add_argument(\"--cooldown_h\", type=int, default=DEFAULT_COOLDOWN_ALERTA_H, help=\"Cooldown entre alertas (horas)\")\n",
    "    parser.add_argument(\"--alerta_h\", type=int, default=DEFAULT_ALERTA_HORAS, help=\"Ventana pre-falla (horas)\")\n",
    "    parser.add_argument(\"--feature_win\", default=DEFAULT_FEATURE_WINDOW, help=\"Ventana de features (ej. '24H')\")\n",
    "    parser.add_argument(\"--resample\", default=DEFAULT_RESAMPLE_RULE, help=\"Frecuencia de resampleo (ej. '30min')\")\n",
    "    parser.add_argument(\"--min_samp\", type=int, default=DEFAULT_FEATURE_MIN_SAMPLES, help=\"Mínimo de muestras en ventana\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Mensaje inicial\n",
    "    print(\"=======================================\")\n",
    "    print(\"   AIB - Pipeline completo a alertas   \")\n",
    "    print(\"=======================================\")\n",
    "    print(f\"Excel: {args.input}\")\n",
    "    print(f\"Params: ALERTA_H={args.alerta_h}h | FEAT_WIN={args.feature_win} | RESAMPLE={args.resample} | MIN_SAMP={args.min_samp}\")\n",
    "    print(f\"Regla: UMBRAL={args.umbral} | CONSEC={args.consec} | COOLDOWN={args.cooldown_h}h\")\n",
    "\n",
    "    # Carga de datos\n",
    "    path = Path(args.input)\n",
    "    assert path.exists(), f\"No encontré el archivo: {path}\"\n",
    "\n",
    "    vib, ev = cargar_excel_multipozo(str(path))\n",
    "    print(f\"\\nPozos: {vib['well_id'].nunique()} | Muestras: {len(vib):,}\")\n",
    "    print(f\"Fallas detectadas: {0 if ev is None else len(ev)}\")\n",
    "    if ev is not None and not ev.empty:\n",
    "        ev.sort_values([\"well_id\", \"failure_time\"]).to_csv(OUT_EVENTOS_DETECTADOS, index=False)\n",
    "        print(f\"[OK] Guardé eventos detectados en {OUT_EVENTOS_DETECTADOS}\")\n",
    "\n",
    "    # Construcción de features (parámetros explícitos)\n",
    "    F = construir_dataset(vib, rule=args.resample, feature_window=args.feature_win, min_samp=args.min_samp)\n",
    "    DS = etiquetar(F, ev, alerta_h=args.alerta_h, cooldown_h=COOLDOWN_HORAS)\n",
    "\n",
    "    if DS[\"y\"].sum() == 0:\n",
    "        print(\"No hay positivos etiquetados. Revisá ALERTA_HORAS o las marcas de FALLA en el Excel.\")\n",
    "        return\n",
    "\n",
    "    # Entrenar y evaluar\n",
    "    model, feat_cols = entrenar_y_evaluar(DS, n_splits=N_SPLITS, seed=SEED)\n",
    "\n",
    "    # Probabilidades por timestamp\n",
    "    DS = DS.copy()\n",
    "    DS[\"proba\"] = model.predict_proba(DS[feat_cols])[:, 1]\n",
    "    DS.to_csv(OUT_PROBAS_CSV, index=False)\n",
    "    print(f\"[OK] Guardé probabilidades por timestamp en {OUT_PROBAS_CSV}\")\n",
    "\n",
    "    # Generar alertas operativas\n",
    "    alertas_df = generar_alertas(DS, umbral=args.umbral,\n",
    "                                 consecutivas=args.consec,\n",
    "                                 cooldown_h=args.cooldown_h)\n",
    "    alertas_df.to_csv(OUT_ALERTAS, index=False)\n",
    "    print(f\"[OK] Guardé alertas en {OUT_ALERTAS} (total: {len(alertas_df)})\")\n",
    "\n",
    "    # Cobertura por evento\n",
    "    cubiertas, total, lead_prom = cobertura_por_evento(alertas_df, ev, alerta_horas=args.alerta_h)\n",
    "    print(\"\\n=== COBERTURA POR EVENTO ===\")\n",
    "    print(f\"Fallas cubiertas con >=1 alerta previa: {cubiertas}/{total}\")\n",
    "    if total:\n",
    "        print(f\"Cobertura evento: {100.0*cubiertas/total:.1f}%\")\n",
    "    if not np.isnan(lead_prom):\n",
    "        print(f\"Anticipo medio (horas) de la PRIMERA alerta por evento: {lead_prom:.1f}h\")\n",
    "\n",
    "    print(\"\\nListo. Archivos generados:\")\n",
    "    print(f\" - {OUT_ALERTAS}\")\n",
    "    print(f\" - {OUT_PROBAS_CSV}\")\n",
    "    print(f\" - {OUT_IMPORTANCES_CSV}\")\n",
    "    if ev is not None and not ev.empty:\n",
    "        print(f\" - {OUT_EVENTOS_DETECTADOS}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112d00a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:80: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:82: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean())**0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:83: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:84: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:80: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:82: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean())**0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:83: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:84: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:80: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:82: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean())**0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:83: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:84: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:80: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:82: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean())**0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:83: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:84: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:80: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:82: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rms = (gs.pow(2).rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean())**0.5\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:83: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  diff_abs_mean = gs.diff().abs().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
      "C:\\Users\\ry16123\\AppData\\Local\\Temp\\ipykernel_39268\\3207338825.py:84: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  slope = gs.diff().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5607\n",
      "PR-AUC : 0.0464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.959     0.957     0.958     11762\n",
      "           1      0.006     0.006     0.006       480\n",
      "\n",
      "    accuracy                          0.920     12242\n",
      "   macro avg      0.483     0.482     0.482     12242\n",
      "weighted avg      0.922     0.920     0.921     12242\n",
      "\n",
      "[OK] Guardé model_aib.pkl y model_aib_config.json\n"
     ]
    }
   ],
   "source": [
    "#TE ARMA EL SCRIP DEL ARCHIVO .PKL PARA LA PREDICCION.\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "AIB - ENTRENAR Y GUARDAR MODELO (simple y directo)\n",
    "- Lee 'vibraciones_multi.xlsx' (cada hoja = pozo; columnas: Fecha, VIBR)\n",
    "- Calcula features 24h, etiqueta 48h pre-falla y entrena\n",
    "- Guarda: model_aib.pkl (modelo) y model_aib_config.json (parámetros de preprocesamiento)\n",
    "\n",
    "Uso:\n",
    "    python aib_train_save.py\n",
    "\n",
    "Requisitos:\n",
    "    pip install pandas numpy scikit-learn openpyxl\n",
    "\"\"\"\n",
    "import json, pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ===== Parámetros base (no toques si no hace falta) =====\n",
    "INPUT_XLSX = \"vibraciones_multi.xlsx\"\n",
    "RESAMPLE_RULE = \"30min\"\n",
    "FEATURE_WINDOW = \"24H\"\n",
    "FEATURE_MIN_SAMPLES = 6\n",
    "ALERTA_HORAS = 48\n",
    "COOLDOWN_HORAS = 6\n",
    "N_SPLITS = 4\n",
    "SEED = 42\n",
    "# =======================================================\n",
    "\n",
    "def cargar_excel_multipozo(path_xlsx: str):\n",
    "    xls = pd.read_excel(path_xlsx, sheet_name=None, dtype=str)\n",
    "    frames, eventos = [], []\n",
    "    for sheet_name, df in xls.items():\n",
    "        if df is None or df.empty: \n",
    "            continue\n",
    "        df = df.copy()\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "        colmap = {}\n",
    "        for c in df.columns:\n",
    "            cl = c.lower()\n",
    "            if cl in (\"fecha\",\"timestamp\",\"datetime\"): colmap[c]=\"timestamp\"\n",
    "            elif (cl in (\"vibr\",\"vibraciones\",\"vibracion\",\"valor\",\"value\",\"vibr.\") or cl.startswith(\"vibr\")):\n",
    "                colmap[c]=\"vibr\"\n",
    "        if colmap:\n",
    "            df = df.rename(columns=colmap)\n",
    "        elif len(df.columns)>=2:\n",
    "            df = df.rename(columns={df.columns[0]:\"timestamp\", df.columns[1]:\"vibr\"})\n",
    "        if \"timestamp\" not in df.columns or \"vibr\" not in df.columns: \n",
    "            continue\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], dayfirst=True, errors=\"coerce\")\n",
    "        falla_mask = df[\"vibr\"].astype(str).str.contains(\"FALLA\", case=False, na=False)\n",
    "        if falla_mask.any():\n",
    "            for t in df.loc[falla_mask,\"timestamp\"]:\n",
    "                if pd.notna(t):\n",
    "                    eventos.append({\"well_id\": sheet_name, \"failure_time\": t})\n",
    "        df_num = df.loc[~falla_mask].copy()\n",
    "        df_num[\"vibr\"] = pd.to_numeric(df_num[\"vibr\"], errors=\"coerce\")\n",
    "        df_num = df_num.dropna(subset=[\"timestamp\",\"vibr\"])\n",
    "        if df_num.empty: \n",
    "            continue\n",
    "        df_num.insert(0,\"well_id\", sheet_name)\n",
    "        frames.append(df_num[[\"well_id\",\"timestamp\",\"vibr\"]])\n",
    "    if not frames:\n",
    "        raise ValueError(\"No se encontraron datos numéricos de vibración.\")\n",
    "    vib = pd.concat(frames, ignore_index=True).sort_values([\"well_id\",\"timestamp\"])\n",
    "    ev = pd.DataFrame(eventos)\n",
    "    if not ev.empty:\n",
    "        ev[\"failure_time\"] = pd.to_datetime(ev[\"failure_time\"])\n",
    "    return vib, ev\n",
    "\n",
    "def build_features(vib: pd.DataFrame) -> pd.DataFrame:\n",
    "    feats = []\n",
    "    for well, g in vib.groupby(\"well_id\", sort=False):\n",
    "        g = g.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "        gs = g[\"vibr\"].resample(RESAMPLE_RULE).median().interpolate(method=\"time\", limit_direction=\"both\")\n",
    "        r = gs.rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES)\n",
    "        mean = r.mean(); std = r.std(); p2p = r.max()-r.min()\n",
    "        rms = (gs.pow(2).rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean())**0.5\n",
    "        diff_abs_mean = gs.diff().abs().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
    "        slope = gs.diff().rolling(FEATURE_WINDOW, min_periods=FEATURE_MIN_SAMPLES).mean()\n",
    "        cv = std / (mean.abs() + 1e-9)\n",
    "        F = pd.DataFrame({\n",
    "            \"well_id\": well,\n",
    "            \"t_end\": gs.index,\n",
    "            \"vib_last\": gs.values,\n",
    "            \"vib_mean\": mean.values,\n",
    "            \"vib_std\": std.values,\n",
    "            \"vib_rms\": rms.values,\n",
    "            \"vib_p2p\": p2p.values,\n",
    "            \"vib_diff_mean\": diff_abs_mean.values,\n",
    "            \"vib_slope\": slope.values,\n",
    "            \"vib_cv\": cv.values\n",
    "        }).dropna()\n",
    "        feats.append(F)\n",
    "    return pd.concat(feats, ignore_index=True).sort_values([\"well_id\",\"t_end\"])\n",
    "\n",
    "def etiquetar(F: pd.DataFrame, eventos: pd.DataFrame) -> pd.DataFrame:\n",
    "    F = F.copy(); F[\"y\"]=0\n",
    "    if eventos is None or eventos.empty: \n",
    "        return F\n",
    "    for well, ge in eventos.groupby(\"well_id\"):\n",
    "        mask = F[\"well_id\"]==well\n",
    "        t_end = F.loc[mask,\"t_end\"]\n",
    "        for _, row in ge.iterrows():\n",
    "            ft = row[\"failure_time\"]\n",
    "            dt_h = (ft - t_end).dt.total_seconds()/3600.0\n",
    "            pos = mask & (dt_h>=0) & (dt_h<=ALERTA_HORAS)\n",
    "            cool= mask & (dt_h<0) & (dt_h>=-COOLDOWN_HORAS)\n",
    "            F.loc[pos,\"y\"]=1\n",
    "            F.loc[cool,\"y\"]=np.nan\n",
    "    F = F.dropna(subset=[\"y\"]).copy()\n",
    "    F[\"y\"]=F[\"y\"].astype(int)\n",
    "    return F\n",
    "\n",
    "def main():\n",
    "    path = Path(INPUT_XLSX); assert path.exists(), f\"No encontré {path}\"\n",
    "    vib, ev = cargar_excel_multipozo(str(path))\n",
    "    F = build_features(vib)\n",
    "    DS = etiquetar(F, ev)\n",
    "    feat_cols = [c for c in DS.columns if c not in {\"well_id\",\"t_end\",\"y\"}]\n",
    "    classes = np.unique(DS[\"y\"])\n",
    "    cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=DS[\"y\"])\n",
    "    class_weight = {int(k): float(v) for k, v in zip(classes, cw)}\n",
    "    y_true, y_pred, y_proba = [], [], []\n",
    "    gkf = GroupKFold(n_splits=max(2, min(N_SPLITS, DS[\"well_id\"].nunique())))\n",
    "    for tr, te in gkf.split(DS[feat_cols], DS[\"y\"], DS[\"well_id\"].astype(str).values):\n",
    "        Xtr, Xte = DS.iloc[tr][feat_cols], DS.iloc[te][feat_cols]\n",
    "        ytr, yte = DS.iloc[tr][\"y\"], DS.iloc[te][\"y\"]\n",
    "        sw = ytr.map(lambda yy: class_weight[int(yy)]).values\n",
    "        m = HistGradientBoostingClassifier(learning_rate=0.08, max_iter=500, min_samples_leaf=20, random_state=SEED)\n",
    "        m.fit(Xtr, ytr, sample_weight=sw)\n",
    "        p = m.predict_proba(Xte)[:,1]; y_proba.extend(p.tolist()); y_true.extend(yte.tolist())\n",
    "        y_pred.extend((p>=0.5).astype(int).tolist())\n",
    "    print(\"ROC-AUC:\", round(roc_auc_score(y_true,y_proba),4))\n",
    "    print(\"PR-AUC :\", round(average_precision_score(y_true,y_proba),4))\n",
    "    print(classification_report(y_true,y_pred,digits=3))\n",
    "    # Entrena final y guarda\n",
    "    m = HistGradientBoostingClassifier(learning_rate=0.08, max_iter=500, min_samples_leaf=20, random_state=SEED)\n",
    "    sw_full = DS[\"y\"].map(lambda yy: class_weight[int(yy)]).values\n",
    "    m.fit(DS[feat_cols], DS[\"y\"], sample_weight=sw_full)\n",
    "    with open(\"model_aib.pkl\",\"wb\") as f:\n",
    "        pickle.dump({\"model\": m, \"features\": feat_cols}, f)\n",
    "    with open(\"model_aib_config.json\",\"w\") as f:\n",
    "        json.dump({\n",
    "            \"RESAMPLE_RULE\": RESAMPLE_RULE,\n",
    "            \"FEATURE_WINDOW\": FEATURE_WINDOW,\n",
    "            \"FEATURE_MIN_SAMPLES\": FEATURE_MIN_SAMPLES\n",
    "        }, f, indent=2)\n",
    "    print(\"[OK] Guardé model_aib.pkl y model_aib_config.json\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e210f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CursoML-UDEMY)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
